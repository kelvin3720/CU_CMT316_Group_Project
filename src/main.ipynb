{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d182dc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb147de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# For Docker image tensorflow/tensorflow:2.14.0-gpu-juptyer\n",
    "!pip install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a959c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 22:09:57.337685: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61904ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available, using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 22:09:58.554066: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 22:09:58.558643: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 22:09:58.558683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# The device_name will be used in model.fit()\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpu_devices:\n",
    "    print(\"GPU available, using GPU\")\n",
    "    tf.config.experimental.set_visible_devices(gpu_devices[0], \"GPU\")\n",
    "    device_name = \"/GPU:0\"\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    device_name = \"/CPU:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3f7e8",
   "metadata": {},
   "source": [
    "### Function for loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c7661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file(file_path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Load a text file and return an array of lines from the file.\n",
    "\n",
    "    Args:\n",
    "        file_path: str: The path to the file to load.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: An array of lines from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "    return [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4751e373",
   "metadata": {},
   "source": [
    "### Load the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819ff3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_path: str = \"../dataset/train_text.txt\"\n",
    "train_label_path: str = \"../dataset/train_labels.txt\"\n",
    "\n",
    "test_text_path: str = \"../dataset/test_text.txt\"\n",
    "test_label_path: str = \"../dataset/test_labels.txt\"\n",
    "\n",
    "validationt_text_path: str = \"../dataset/val_text.txt\"\n",
    "validationt_label_path: str = \"../dataset/val_labels.txt\"\n",
    "\n",
    "train_text: list[str] = load_text_file(train_text_path)\n",
    "train_label: list[str] = load_text_file(train_label_path)\n",
    "\n",
    "test_text: list[str] = load_text_file(test_text_path)\n",
    "test_label: list[str] = load_text_file(test_label_path)\n",
    "\n",
    "validation_text: list[str] = load_text_file(validationt_text_path)\n",
    "validation_label: list[str] = load_text_file(validationt_label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd336c",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da2e83",
   "metadata": {},
   "source": [
    "#### Download the NLTK resources and declere global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc75d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stopwords\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "nltk.download(\"omw-1.4\", quiet=True)\n",
    "nltk.download(\"vader_lexicon\", quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Declare a dict of emojis and their corresponding sentiment\n",
    "# 0: Negative; 1: Neutral; 2: Positive\n",
    "emoji_dict = {\n",
    "    \"😊\": 2,\n",
    "    \"😂\": 2,\n",
    "    \"😭\": 0,\n",
    "    \"😍\": 2,\n",
    "    \"😘\": 2,\n",
    "    \"😁\": 2,\n",
    "    \"😩\": 0,\n",
    "    \"😏\": 2,\n",
    "    \"😉\": 2,\n",
    "    \"😎\": 2,\n",
    "    \"😢\": 0,\n",
    "    \"😅\": 2,\n",
    "    \"😱\": 0,\n",
    "    \"😆\": 2,\n",
    "    \"😋\": 2,\n",
    "    \"😷\": 0,\n",
    "    \"😔\": 0,\n",
    "    \"😒\": 0,\n",
    "    \"😡\": 0,\n",
    "    \"😪\": 0,\n",
    "    \"😤\": 0,\n",
    "    \"😝\": 2,\n",
    "    \"😓\": 0,\n",
    "    \"😖\": 0,\n",
    "    \"😣\": 0,\n",
    "    \"😞\": 0,\n",
    "    \"😐\": 1,\n",
    "    \"😕\": 0,\n",
    "    \"😫\": 0,\n",
    "    \"😨\": 0,\n",
    "    \"😌\": 2,\n",
    "    \"😜\": 2,\n",
    "    \"😑\": 1,\n",
    "    \"😬\": 0,\n",
    "    \"😈\": 0,\n",
    "    \"😯\": 0,\n",
    "    \"😳\": 0,\n",
    "    \"😇\": 2,\n",
    "    \"😷\": 0,\n",
    "    \"😴\": 0,\n",
    "    \"😲\": 0,\n",
    "    \"😵\": 0,\n",
    "    \"😦\": 0,\n",
    "    \"😢\": 0,\n",
    "    \"😮\": 0,\n",
    "    \"😟\": 0,\n",
    "    \"😥\": 0,\n",
    "    \"😧\": 0,\n",
    "    \"😰\": 0,\n",
    "    \"😓\": 0,\n",
    "    \"😩\": 0,\n",
    "    \"😿\": 0,\n",
    "    \"😾\": 0,\n",
    "    \"🙀\": 0,\n",
    "    \"🙅\": 0,\n",
    "    \"🙆\": 0,\n",
    "    \"🙇\": 0,\n",
    "    \"🙈\": 0,\n",
    "    \"🙉\": 0,\n",
    "    \"🙊\": 0,\n",
    "    \"🙋\": 0,\n",
    "    \"🙌\": 0,\n",
    "    \"🙍\": 0,\n",
    "    \"🙎\": 0,\n",
    "    \"🙏\": 0,\n",
    "    \":)\": 2,\n",
    "    \":(\": 0,\n",
    "    \"❤️\": 2,\n",
    "    \"👍\": 2,\n",
    "    \"✌🏼️\": 2,\n",
    "    \"☹️\": 0,\n",
    "    \"🙃\": 0,\n",
    "    \"👎\": 0,\n",
    "    \"💙\": 2,\n",
    "    \"💗\": 2,\n",
    "    \"🎉\": 2,\n",
    "    \"😄\": 2,\n",
    "    \"🤗\": 2,\n",
    "    \":D\": 2,\n",
    "    \"🎄\": 2,\n",
    "    \"🎁\": 2,\n",
    "    \":/\": 0,\n",
    "    \"?!\": 0,\n",
    "    \":P\": 2,\n",
    "    \":p\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4ecc5",
   "metadata": {},
   "source": [
    "### Functions for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14f5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text: list[str], data: str) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Process text data:\n",
    "    - Remove '@user'\n",
    "    - Remove hashtags\n",
    "    - Remove '-'\n",
    "    - Remove URLs\n",
    "    - Replace emojis with their corresponding sentiment.\n",
    "    - Replace punctuation marks.\n",
    "    - Tokenize the text.\n",
    "    - Normalize the text with nltk.\n",
    "    - Lowercase the text.\n",
    "    # Length of the line is added after vectorization.\n",
    "\n",
    "    Args:\n",
    "        text: list[str]: A list of text data.\n",
    "        data: str: The type of data (train, test, validation).\n",
    "\n",
    "    Returns:\n",
    "        list[list[str]]: A list of list of processed text data.\n",
    "    \"\"\"\n",
    "    processed_text = []\n",
    "    for line in text:\n",
    "        # Remove '@user'\n",
    "        line = line.replace(\"@user\", \" \")\n",
    "        # Remove hashtags\n",
    "        line = line.replace(\"#\", \" \")\n",
    "        # Remove '-'\n",
    "        line = line.replace(\"-\", \" \")\n",
    "        # Remove URLs (http, https, www)\n",
    "        line = \" \".join([word for word in line.split() if \"http\" not in word])\n",
    "        line = \" \".join([word for word in line.split() if \"www\" not in word])\n",
    "        # Replace emojis with their corresponding sentiment\n",
    "        line = replace_emojis(line)\n",
    "        # Replace punctuation marks\n",
    "        line = punctuation_replacement(line)\n",
    "        # Tokenize the text.\n",
    "        tokens = nltk.word_tokenize(line)\n",
    "        # Normalize the text using WordNetLemmatizer and tokenize the text\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        # Lowercase the text\n",
    "        tokens = [str(word).lower() for word in tokens]\n",
    "        processed_text.append(tokens)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def vectorize_text(\n",
    "    input: list[list[str]], vocabulary: list[str]\n",
    ") -> ndarray[ndarray[float]]:\n",
    "    \"\"\"\n",
    "    Vectorize the text data.\n",
    "\n",
    "    Args:\n",
    "        input: list[list[str]]: A list of list of text data (Full *_text).\n",
    "        vocabulary: list[str]: The list of most common words.\n",
    "\n",
    "    Returns:\n",
    "        ndarray[ndarray[float]]: A numpy array of vectorized text data.\n",
    "    \"\"\"\n",
    "    vectorized_text = np.zeros((len(input), len(vocabulary)))\n",
    "    for i, line in enumerate(input):\n",
    "        for word in line:\n",
    "            if word in vocabulary:\n",
    "                vectorized_text[i, vocabulary.index(word)] += 1\n",
    "    return vectorized_text\n",
    "\n",
    "\n",
    "def map_emoji_sentiment(input: int) -> str:\n",
    "    \"\"\"\n",
    "    Map the emoji sentiment to a string.\n",
    "\n",
    "    Args:\n",
    "        input: int: The emoji sentiment.\n",
    "\n",
    "    Returns:\n",
    "        str: The string sentiment.\n",
    "    \"\"\"\n",
    "    if input == 0:\n",
    "        return \" bad \"\n",
    "    elif input == 1:\n",
    "        return \" neutral \"\n",
    "    elif input == 2:\n",
    "        return \" good \"\n",
    "    else:\n",
    "        return \" neutral \"\n",
    "\n",
    "\n",
    "def replace_emojis(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace emojis with their corresponding sentiment.\n",
    "    If the emoji is 0, replace it with 'bad'.\n",
    "    If the emoji is 1, replace it with 'neutral'.\n",
    "    If the emoji is 2, replace it with 'good'.\n",
    "    If the emoji is not in the emoji_dict, replace it with 'neutral'.\n",
    "\n",
    "    Args:\n",
    "        input: str: The input text data (line).\n",
    "\n",
    "    Returns:\n",
    "        str: The text data with emojis replaced with their corresponding sentiment.\n",
    "    \"\"\"\n",
    "    for emoji in emoji_dict:\n",
    "        if emoji in input:\n",
    "            input = input.replace(emoji, map_emoji_sentiment(emoji_dict[emoji]))\n",
    "    return input\n",
    "\n",
    "\n",
    "def get_sentiment_score(line: list[str]) -> list[float]:\n",
    "    \"\"\"\n",
    "    Get the sentiment score of the input text data from SentimentIntensityAnalyzer.\n",
    "\n",
    "    Args:\n",
    "        line: list[str]: The input line.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: The compound score of 10 words in the sentence which has\n",
    "        the most significant score (far from 0). If the sentence has less than\n",
    "        10 words, the value of the remaining elements will be 0.\n",
    "        After that, the score for the whole line is added to the list.\n",
    "    \"\"\"\n",
    "    scores: list[float] = []\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    for string in line:\n",
    "        score = analyzer.polarity_scores(string)[\"compound\"]\n",
    "        scores.append(score)\n",
    "    line_score = analyzer.polarity_scores(\" \".join(line))[\"compound\"]\n",
    "\n",
    "    # Get the 10 most significant scores and add the line score\n",
    "    if len(scores) > 10:\n",
    "        scores.sort(key=lambda x: abs(x), reverse=True)\n",
    "        result = scores[:10]\n",
    "        result.append(line_score)\n",
    "    else:\n",
    "        result = scores\n",
    "        result += [0] * (10 - len(scores))\n",
    "        result.append(line_score)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def learning_rate_scheduler(epoch: int) -> float:\n",
    "    \"\"\"\n",
    "    Learning rate scheduler, to decrease the learning rate when epoch increases.\n",
    "\n",
    "    Args:\n",
    "        epoch: int: The current epoch.\n",
    "\n",
    "    Returns:\n",
    "        float: The new learning rate.\n",
    "    \"\"\"\n",
    "    if epoch < 10:\n",
    "        return 0.0005\n",
    "    elif epoch < 20:\n",
    "        return 0.0003\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "\n",
    "def punctuation_replacement(line: Union[str, list[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Check if there are repeated (>= 2) punctuation marks ['.' '!', '?'] in the line.\n",
    "    If there are, no matter how many times the punctuation mark is repeated,\n",
    "    replace it with ['MultiDot', 'MultiExclamation', 'MultiQuestion']\n",
    "    respectively.\n",
    "\n",
    "    Replace ['.' '!', '?'] with ['Dot', 'Exclamation', 'Question'] respectively.\n",
    "    If they are not repeated in the line, keep them as they are.\n",
    "\n",
    "    Args:\n",
    "        line: Union[str, list[str]]: The input line, which can be a string or a list of words.\n",
    "\n",
    "    Returns:\n",
    "        str: The line with punctuation marks replaced.\n",
    "    \"\"\"\n",
    "    # Split the line into words if it is a string\n",
    "    if type(line) is str:\n",
    "        line = line.split()\n",
    "    # Replace punctuation marks\n",
    "    for_append = []\n",
    "    for i, word in enumerate(line):\n",
    "        if word.count(\".\") >= 2:\n",
    "            line[i] = line[i].replace(\".\", \"\")\n",
    "            for_append.append(\"MultiDot\")\n",
    "        elif word.count(\"!\") >= 2:\n",
    "            line[i] = line[i].replace(\"!\", \"\")\n",
    "            for_append.append(\"MultiExclamation\")\n",
    "        elif word.count(\"?\") >= 2:\n",
    "            line[i] = line[i].replace(\"?\", \"\")\n",
    "            for_append.append(\"MultiQuestion\")\n",
    "        elif word.count(\".\") == 1:\n",
    "            line[i] = line[i].replace(\".\", \"\")\n",
    "            for_append.append(\"Dot\")\n",
    "        elif word.count(\"!\") == 1:\n",
    "            line[i] = line[i].replace(\"!\", \"\")\n",
    "            for_append.append(\"Exclamation\")\n",
    "        elif word.count(\"?\") == 1:\n",
    "            line[i] = line[i].replace(\"?\", \"\")\n",
    "            for_append.append(\"Question\")\n",
    "\n",
    "    line += for_append\n",
    "\n",
    "    # Join back the line\n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed5bf3",
   "metadata": {},
   "source": [
    "### Process the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba10fa",
   "metadata": {},
   "source": [
    "#### Process all text data\n",
    "\n",
    "See function docstring from text_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1634a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text: list[list[str]] = text_processing(train_text, \"train\")\n",
    "test_text: list[list[str]] = text_processing(test_text, \"test\")\n",
    "validation_text: list[list[str]] = text_processing(validation_text, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5734a099",
   "metadata": {},
   "source": [
    "#### Get the length of each input line\n",
    "\n",
    "Will be added as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0677b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_len: list[int] = [len(line) for line in train_text]\n",
    "test_text_len: list[int] = [len(line) for line in test_text]\n",
    "validation_text_len: list[int] = [len(line) for line in validation_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d2450",
   "metadata": {},
   "source": [
    "#### Remove empty lines after processing\n",
    "\n",
    "As there may exist lines with 0 words after removing words like stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6fd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index of lists in train_text and validation_text that are empty\n",
    "empty_index_train: list[int] = [i for i, x in enumerate(train_text) if not x]\n",
    "\n",
    "# Remove empty lists from train_text and validation_text, and corresponding labels\n",
    "train_text: list[list[str]] = [\n",
    "    train_text[i] for i in range(len(train_text)) if i not in empty_index_train\n",
    "]\n",
    "train_label: list[list[str]] = [\n",
    "    train_label[i] for i in range(len(train_label)) if i not in empty_index_train\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde05ecd",
   "metadata": {},
   "source": [
    "#### Find the most common words in the training data\n",
    "\n",
    "Will be used for vectorizing the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "680dad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency: dict[str, int] = {}\n",
    "for line in train_text:\n",
    "    for word in line:\n",
    "        if word in word_frequency:\n",
    "            word_frequency[word] += 1\n",
    "        else:\n",
    "            word_frequency[word] = 1\n",
    "\n",
    "vocabulary: list[str] = [\n",
    "    word\n",
    "    for word, _ in sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)[\n",
    "        :10000\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d1eb8",
   "metadata": {},
   "source": [
    "#### Get the sentiment score of the text data\n",
    "\n",
    "Will be used as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf84bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment_score: ndarray[ndarray[float]] = np.array(\n",
    "    [get_sentiment_score(line) for line in train_text]\n",
    ")\n",
    "test_sentiment_score: ndarray[ndarray[float]] = np.array(\n",
    "    [get_sentiment_score(line) for line in test_text]\n",
    ")\n",
    "validation_sentiment_score: ndarray[ndarray[float]] = np.array(\n",
    "    [get_sentiment_score(line) for line in validation_text]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41216d7",
   "metadata": {},
   "source": [
    "##### Convert the labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e846af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label: list[int] = [int(label) for label in train_label]\n",
    "test_label: list[int] = [int(label) for label in test_label]\n",
    "validation_label: list[int] = [int(label) for label in validation_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e8593",
   "metadata": {},
   "source": [
    "### Vectorize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c26c2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "train_vectorized: ndarray[ndarray[float]] = vectorize_text(train_text, vocabulary)\n",
    "test_vectorized: ndarray[ndarray[float]] = vectorize_text(test_text, vocabulary)\n",
    "validation_vectorized: ndarray[ndarray[float]] = vectorize_text(\n",
    "    validation_text, vocabulary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b0aaf",
   "metadata": {},
   "source": [
    "#### Remove entries with all 0 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28e7c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data size: 45615\n",
      "Processed training data size: 45614\n"
     ]
    }
   ],
   "source": [
    "# Find the entries with all zeros in the vectorized data\n",
    "zero_index_train: ndarray[int] = np.where(~train_vectorized.any(axis=1))[0]\n",
    "\n",
    "print(\"Original training data size:\", len(train_vectorized))\n",
    "\n",
    "# Remove entries with all zeros in the vectorized data, and corresponding labels\n",
    "train_vectorized: ndarray[ndarray[float]] = np.delete(\n",
    "    train_vectorized, zero_index_train, axis=0\n",
    ")\n",
    "train_label: list[int] = [\n",
    "    train_label[i] for i in range(len(train_label)) if i not in zero_index_train\n",
    "]\n",
    "\n",
    "# Remove entries with all zeros in the sentiment score data\n",
    "train_sentiment_score: ndarray[ndarray[float]] = np.delete(\n",
    "    train_sentiment_score, zero_index_train, axis=0\n",
    ")\n",
    "\n",
    "# Convert the list of text lengths to numpy array\n",
    "train_text_len: ndarray[int] = np.array(train_text_len)\n",
    "\n",
    "# Remove entries with all zeros in the text length data\n",
    "train_text_len: ndarray[int] = np.delete(train_text_len, zero_index_train)\n",
    "\n",
    "print(\"Processed training data size:\", len(train_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00348677",
   "metadata": {},
   "source": [
    "#### Add remaining feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52144176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the length of the text data to the vectorized data\n",
    "train_vectorized: ndarray[ndarray[float]] = np.column_stack(\n",
    "    (train_vectorized, train_text_len)\n",
    ")\n",
    "test_vectorized: ndarray[ndarray[float]] = np.column_stack(\n",
    "    (test_vectorized, test_text_len)\n",
    ")\n",
    "validation_vectorized: ndarray[ndarray[float]] = np.column_stack(\n",
    "    (validation_vectorized, validation_text_len)\n",
    ")\n",
    "\n",
    "# Add sentiment score to each entry in the vectorized data\n",
    "train_vectorized: ndarray[ndarray[float]] = np.concatenate(\n",
    "    (train_vectorized, train_sentiment_score), axis=1\n",
    ")\n",
    "test_vectorized: ndarray[ndarray[float]] = np.concatenate(\n",
    "    (test_vectorized, test_sentiment_score), axis=1\n",
    ")\n",
    "validation_vectorized: ndarray[ndarray[float]] = np.concatenate(\n",
    "    (validation_vectorized, validation_sentiment_score), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e326d3a",
   "metadata": {},
   "source": [
    "#### Convert labels to one-hot encoding\n",
    "\n",
    "For fitting into the neural network and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72bea674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 22:14:20.788160: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 22:14:20.788272: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 22:14:20.788309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 22:14:20.886268: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 22:14:20.886317: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 22:14:20.886324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-14 22:14:20.886347: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 22:14:20.886368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_label_one_hot: ndarray[ndarray[float]] = tf.one_hot(train_label, 3)\n",
    "validation_label_one_hot: ndarray[ndarray[float]] = tf.one_hot(validation_label, 3)\n",
    "test_label_one_hot: ndarray[ndarray[float]] = tf.one_hot(test_label, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435cdbc",
   "metadata": {},
   "source": [
    "#### Final shape of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "711ac065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (45614, 10012)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18faae",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bdb1ad",
   "metadata": {},
   "source": [
    "#### Setup the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32fea4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Input layer\n",
    "input_layer = tf.keras.layers.Input(shape=(train_vectorized.shape[1],))\n",
    "\n",
    "dropout_rate = 0.7\n",
    "activation_function = \"sigmoid\"\n",
    "\n",
    "#tf.random.set_seed(2024)\n",
    "\n",
    "# Define the model\n",
    "neural_network = tf.keras.models.Sequential(\n",
    "    [\n",
    "        input_layer,\n",
    "        tf.keras.layers.Dense(2048, activation=activation_function),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(512, activation=activation_function),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(128, activation=activation_function),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, mode=\"min\", verbose=1\n",
    ")\n",
    "\n",
    "# Add parameters to Adam optimizer if needed\n",
    "modified_adam = tf.keras.optimizers.Adam()\n",
    "\n",
    "neural_network.compile(\n",
    "    optimizer=modified_adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "rate_scheduler = tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff0a3c4",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e30804f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 22:14:21.807168: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826749472 exceeds 10% of free system memory.\n",
      "2024-04-14 22:14:22.504406: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826749472 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713132863.741550   70147 service.cc:145] XLA service 0x7f559c0052f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1713132863.741600   70147 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-04-14 22:14:23.764652: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-14 22:14:23.863655: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/90\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.3281 - loss: 1.5560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713132867.314119   70147 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4100 - loss: 1.2077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713132872.464395   70288 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 456 bytes spill stores, 408 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132873.347396   70291 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 252 bytes spill stores, 252 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132873.654714   70284 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 464 bytes spill stores, 412 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132874.925652   70377 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132875.287040   70374 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 524 bytes spill stores, 312 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132875.320948   70372 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 28 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132875.348190   70373 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132875.362770   70371 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 480 bytes spill stores, 376 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132875.786798   70366 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 516 bytes spill stores, 308 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132875.941258   70372 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132876.712527   70370 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132876.752794   70376 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 28 bytes spill stores, 20 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 113ms/step - accuracy: 0.4101 - loss: 1.2066 - val_accuracy: 0.4345 - val_loss: 1.0187 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4349 - loss: 1.0316 - val_accuracy: 0.4345 - val_loss: 1.0180 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4425 - loss: 1.0259 - val_accuracy: 0.4345 - val_loss: 1.0186 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4418 - loss: 1.0256 - val_accuracy: 0.4345 - val_loss: 1.0137 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4588 - loss: 1.0156 - val_accuracy: 0.4875 - val_loss: 0.9983 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4914 - loss: 0.9872 - val_accuracy: 0.6065 - val_loss: 0.8302 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5917 - loss: 0.8712 - val_accuracy: 0.6250 - val_loss: 0.7875 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6140 - loss: 0.8297 - val_accuracy: 0.6455 - val_loss: 0.7656 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6274 - loss: 0.8035 - val_accuracy: 0.6680 - val_loss: 0.7420 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6466 - loss: 0.7721 - val_accuracy: 0.6655 - val_loss: 0.7260 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6635 - loss: 0.7444 - val_accuracy: 0.6805 - val_loss: 0.7139 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6687 - loss: 0.7297 - val_accuracy: 0.6860 - val_loss: 0.7065 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6831 - loss: 0.7159 - val_accuracy: 0.6885 - val_loss: 0.7031 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6879 - loss: 0.7052 - val_accuracy: 0.6965 - val_loss: 0.7009 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6917 - loss: 0.6947 - val_accuracy: 0.6915 - val_loss: 0.6993 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6994 - loss: 0.6841 - val_accuracy: 0.6935 - val_loss: 0.6965 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6984 - loss: 0.6781 - val_accuracy: 0.6975 - val_loss: 0.6936 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7048 - loss: 0.6730 - val_accuracy: 0.6975 - val_loss: 0.6940 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7076 - loss: 0.6623 - val_accuracy: 0.7020 - val_loss: 0.6910 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7168 - loss: 0.6544 - val_accuracy: 0.7020 - val_loss: 0.6955 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7159 - loss: 0.6549 - val_accuracy: 0.7045 - val_loss: 0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7162 - loss: 0.6456 - val_accuracy: 0.7040 - val_loss: 0.6902 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7219 - loss: 0.6453 - val_accuracy: 0.7055 - val_loss: 0.6902 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7221 - loss: 0.6408 - val_accuracy: 0.7015 - val_loss: 0.6899 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7212 - loss: 0.6389 - val_accuracy: 0.7060 - val_loss: 0.6918 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7187 - loss: 0.6444 - val_accuracy: 0.7085 - val_loss: 0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7230 - loss: 0.6349 - val_accuracy: 0.7070 - val_loss: 0.6904 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7281 - loss: 0.6314 - val_accuracy: 0.7045 - val_loss: 0.6900 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7230 - loss: 0.6321 - val_accuracy: 0.7090 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
      "Epoch 29: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device(device_name):\n",
    "    history = neural_network.fit(\n",
    "        train_vectorized,\n",
    "        train_label_one_hot,\n",
    "        validation_data=(validation_vectorized, validation_label_one_hot),\n",
    "        epochs=200,\n",
    "        batch_size=512,\n",
    "        callbacks=[early_stopping, rate_scheduler],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa720ba6",
   "metadata": {},
   "source": [
    "#### Evaluate the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff0da235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713132905.608733   71360 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 252 bytes spill stores, 252 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6433 - loss: 0.8177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713132907.968152   71431 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713132908.500706   71428 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 512 bytes spill stores, 392 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6429 - loss: 0.8183\n",
      "Test loss: 0.826744794845581\n",
      "Test accuracy: 0.6382285952568054\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = neural_network.evaluate(test_vectorized, test_label_one_hot)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04851f07",
   "metadata": {},
   "source": [
    "#### Plot graphs about loss and accuracy during epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e422f370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABsV0lEQVR4nO3dd3hUVeLG8e/MJJn0RkglhNA7SBXFRhFkLQgWEBUb7qrY0FWxITZ2dcW2rv50RXRFZXVtuyCKKDaagpEeek8hhPQ2mbm/P4YMxCSQZCaZlPfzPPNkcufOuWfOjuTd067JMAwDERERkVbE7O0KiIiIiDQ2BSARERFpdRSAREREpNVRABIREZFWRwFIREREWh0FIBEREWl1FIBERESk1fHxdgWaIofDwaFDhwgJCcFkMnm7OiIiIlILhmGQn59PfHw8ZvPJ+3gUgKpx6NAhEhMTvV0NERERqYf9+/fTrl27k56jAFSNkJAQwNmAoaGhHi3bZrPx1Vdfcf755+Pr6+vRslsDtZ/71IbuUfu5T23oHrVfzfLy8khMTHT9HT8ZBaBqVAx7hYaGNkgACgwMJDQ0VF/celD7uU9t6B61n/vUhu5R+51abaavaBK0iIiItDoKQCIiItLqKACJiIhIq6MAJCIiIq2OApCIiIi0OgpAIiIi0uooAImIiEirowAkIiIirY4CkIiIiLQ6CkAiIiLS6igAiYiISKujACQiIiKtjgKQiIiI1JrDYXCkoBSHw/B2Vdyiu8GLiIjISZXbHazZnc2STel8tSmD9LwSrD5mOrQJokNUIB2igugYFUSHNkEkRwXRNsRaqzuye5MCkIiIiFRRYrPzw/YsvtyUztdbMsgpslV6vbTcQWpGPqkZ+VXeG+RnoUNUEB2igkg+Foo6RDl/RgT6NolwpAAkIiIiAOSV2Ph2ayZfbkpneephisrsrtcig/wY1SOasb1jGZrchsP5pew+UsieLOdj95EidmcVcPBoMYVldjYdymPTobwq1wj19yG5bTCXDUjgmmEdGvHTVaYAJCIi0oodzi9l6eYMvtyUzoqdWdjsx+f2xIf5c36vWMb2jmVQUgQ+luNTh4OsPnSICoJulcsrLbezP7vYGYqyCiuFpEO5JeSVlPPb/hzO7dq2sT5itRSARERE3GQYBsU2OwUl5eSXlpNfUk5BSTkFpTbyS479Xup85JeU42M20S4igMTIQNpFBNAuIrBRh4b2Zxfx5aZ0vtyUzi97j2KcMJ+5c3QwY3rFMKZXLH0SwupcJ6uPhc7RwXSODq7yWnGZnb3ZzjDUsW3V1xuTApCIiEg1ysodZOSVkJZbQlpuMYdySkjPLeZQbglHC8tcYaYi2NjdXBUV5GehXURFIKocjtpFBBAWUHNAMgyDvOJysgpLycov5UhhGUcKSskqKCOroJQjBWUcKTz+e35JeaX392sXxvm9YhnTK7ba4OIpAX4WuseG0j02tMGuUVsKQCIi0uqU2x1k5Jc6A03OiQHn2PPcErIKSiv1jNSG2QTBVh9C/H0J8fch2OpD8LGfIf7O48FWH0psdg7mFHPgaDH7s4vIzC+lsMxe46RigBCrDwkRASSE+5ObZeajt9eSXWRzhZsTh65qU88hyZGM7RXL+b1iiQ8PqNsHbQEUgEREpFU4lFPMx+sO8GnKIXYdLqA2HTZ+PmbiwvyJC/MnPiyA2DB/4sIDiAryc4aZY+Em1N8ZdAJ8LfUaxiqx2TmUU8z+o8UcOFrEgaPHw9GBo8XOXpvScram57M1PR8wQ9aRKuWE+PsQFWylTZAfbYL9nM+DrURVPA/yo02wldgwf4KtrTsCtO5PLyIiLVqJzc7SzRn8+5f9/Lgjq1KPjq/FREyoM9jEhfsTeyzkxIX5Ex/u/BkZ5Nco83L8fS10bBtc47yY4jI7B3OK2H+0mL1ZBaz7bSNnDOxLTFjgsZDjR2SQH/6+lgava0uhACQiIi2KYRhsOJjLh78c4LOUg+SdMN9laHIklw9K5OwuUUQFWzGbvb8fTW0E+FnoHB1C5+gQbB0jiMjawLgBCfj6+nq7as2WApCIiLQIWQWlfPrrQT785UCleTTxYf5cNrAdEwe2I6lNkBdrKE2JApCIiDQqm91R58nFJytreephPvxlP99szaT82MQeq4+ZMb1iuXxQO87oFIWlmfT0SONRABIRkQZRYrOzI7OA7Zn5bMsoYHuG8+f+o0WYsfDUxuVEBlkJD/QlMsiP8EA/IoN8iQj0IyLQ79gx52sRQX6EWH1c83G2ZeTz4S/7+eTXQ2QVlLqu2S8xnMsHtuOifvGEBWh4SGqmACQiIm4psdnZdbjwWNA5Hnb2ZRfVuNLKjonDBWUcLiir9XV8zCbCA/0I8DOzP7vYdTwq2I9LT0vg8kGJdI0JcffjSCuhACQiIrWWnlvCz3uyjwWdfLZnFLDnSGGNQSc80Jeu0SF0iQmma4zzZ1KEP19/vYz+pw8nv9TgaFGZ81Fo42hRGdmFZVWOFZXZKXcYrt4eH7OJEd2juXxQIud2a4vvCbdoEKkNBSAREalRRl4Jq3YdYdWuI6zceYQ9R4qqPS/U3+dYwAmh6wlhp22wtcoycpvNRrgVesaF1noVU4nNTk6RjezCMnKLbXSJCSYq2Or255PWSwFIRERcMvNLWLUr2xl6dh5hV1ZhpdfNJugZH0rv+LBKYSc6pGrQ8SR/XwuxYRZiw/wb7BrSuigAiYi0YlkFpazelc3KXVms2pXNjsyCSq+bTM6emmEd23B6xzYMTo7U5GJpERSARERakfwSGz9uz2LlsWGtbRkFVc7p4Qo8kQxNbkNYoAKPtDwKQCIiLVxusY2vN2fwxcY0vt+WRZndUen17rEhnH6sh2dociQRQX5eqqm0GgWZ4GMF/zCvVUEBSESkBcopKuOrzRl8sSGNH3dkVbpTeHJUEGd3iXIGno5tiFTgaR7KCuHwVkxpG+mUuRLTpmIIT4SQWAiJA79Ab9ewZoYBWdtg6yJI/QIO/AzjnoUh07xWJQUgEZEW4khBKV9tzmDxhjRW7jzi2hUZoEt0MOP6xDGuTxxdY4Ib5QafUk/lpZC1HTK3QOZm58/DW+DoHsD5h7s3wMH3K7/PP8wZhCoCkesRC6Hxzp/BMWBppCFNhx32r4HURbB1MWTvrPx61vbGqUcNFIBERJqxw/mlfLkpncUb0li160il/Xi6x4Ywrk8cF/SOpYs2CGx67OVwdPfxkJO5GTK3wpEdYNirf09QNI623TiUYyM+1Iy5IAPy08BWBCW5zsfhrSe5qAmCoiCsHbTtDtE9ILqn83lYO+esd3eUFcHObyB1MWxbAkVHjr9m8YPks6HbOOh2gTOUeZECkIhIM5ORV8KSjc7Qs2ZPdqX7avVOCOWC3s7Q07FtsPcq2VSVFUFBOgS1BWsjh0JbCez5wRkODvwMh7eBvbT6c/3DnMEkuge07XEsqPSAoCjsNhtrFy8mZtw4zL6+zuGl0jzIT3eGobw058/8dMg/dOznsdcc5VB42Pk49Gvla1pDK4ei6O7On0FtTx6MCjKdYWfrYtj1LZSXnPA5wqHrGGfo6Tyy8dv8JBSARESaOLvD4LcDOSxPPcx3qZmsP5hbKfT0SwxnXO9YLugdR/s2TXgeSIWyQiz2UjAcpz63tuw2KMg4RQhIc/aQAJgskDgEOo2ATiMhvj+YLZ6rT4WibNj+lXPuy85voOx3q+58A4+Fjp7HQ050D+fQVW17Y0wmZ2DyD4O23Wo+z+Fw9sjkp0HOXmdvU0Xv05HtzhB1YI3zcaLANsd7iSrCkTUEdix1hp4DPwMnfCHD20O3P0D3cdB+WOMNudWRApCISBOUVVDK99sOszz1MD9sP8zRIlul1wcmRXBB71jG9o6lXUQTDT1lhXA49fgclkznwzfvIBcCrJ/mHBbxCXCuCPL1dz6v+OljBd8A8PE//tPH33m8JKdyyCk8TKU/widjsTp7XvatdD6+fcrZU9Hx3GOBaIRzcnF9Ze929vJsXews/8ThrJB45/BP55EQ0wvC2oO5kW7jYTZDcFvnI64v9Ljo+GvlZc6htxP+dyJzs/OzFB1x9lzt+aHmsuNPOx56onu6P5TWCBSARESaALvDIGV/Dt+lZrJ822E2/K6XJ8Tfh7O7tOWcrm05p1tbYkKb0I7I5aXOP54nTtrNrJi0e4pQYi9zPmoYCaoTs88Jk4BjnWHDNSH4hInA1lBn3XZ96+yV2fW9M1Bt/tT5AGjT5XgY6jAcrCcZTnQ4nMNJqcdWOGVurvx6TG/nEFD3cRDXv2mGAx8/iOnpfJyorMi5eut3IZbCw5B0pvMzdRvn9fk89dEkAtArr7zCs88+S3p6Ov369ePll19myJAh1Z577rnn8t1331U5Pm7cOBYtWgSAYRjMmjWLN954g5ycHM4880xeffVVunTp0qCfQ0SkLg7nH+vl2ebs5cn5XS9Pr/hQzu3WlnO7RXNaYjg+nrjhZ8FhOLjWORekvuylkLXjhOGTk03abfu7IZ6e2MI78uXX3zBm5Dn4Uu6cG1Ne7AxStmLnHBLbsd/Li6t/3T+sasgJbFP73pTIZOdj0A3OyciH1jnD0M5v4MAvziGhI9thzf+B2RcSh0Kn85yBKK6/M7Tt+eH4su6C9ONlmyyQdAZ0/4OztyeiQ/3b2tv8Ap3Dg/H9vV0Tj/N6AFq4cCEzZszgtddeY+jQobzwwguMGTOG1NRUoqOjq5z/8ccfU1ZW5vr9yJEj9OvXj8svv9x17JlnnuGll17i7bffJjk5mUceeYQxY8awefNm/P2b0P9rEpFWpaisnJT9OazceYTlqc5enhOF+vtwVte2nNvV2dMT7alenqwdx5ci719NrYeK6sIadizgdK88eTe4bdVzbTbsFn9nYKnlzVAblMXHOR8ocQic+wAU5zjDzc5vYMcy53yZvT86H988AQGRzgB04nwev2DoPMoZejqPgsBIr30cqR2vB6C5c+cybdo0rr/+egBee+01Fi1axLx583jggQeqnB8ZWflL9cEHHxAYGOgKQIZh8MILL/Dwww9zySWXAPDOO+8QExPDp59+yqRJkxr4E4mIOKXnlvDL3mx+2XOUdfuOsulQHnZH5fDRIL08DodzYmrqYucja1vl19t2dw4D1ZfZAhHJJ6wW6uEcAmmKQzv1ERDunB9TMUcme9ex3qFvYdd3UJztPB4S5+zh6fYHSD7LOTdJmg2vBqCysjLWrl3LzJkzXcfMZjOjRo1i5cqVtSrjzTffZNKkSQQFBQGwe/du0tPTGTVqlOucsLAwhg4dysqVK6sNQKWlpZSWHh+AzsvLA8Bms2Gz2aqc746K8jxdbmuh9nOf2tA9NbWf3WGQmpHPun05rN2bw6/7cziYU1Ll/TGhVgYlRXBW5zac3SWKtiHH/2gaDjs2Rw1DSaesWDGm3d9h3vYFph1fYSo8fLxcsw9G0nCMrhfg6DLGud+Lp5XXfkit2X0HQxKh/1Tnw27DlP4bhtkXYvuA6VhgNYBG+jzNrv0aUV3axKsBKCsrC7vdTkxMTKXjMTExbN16so2cnNasWcPGjRt58803XcfS09NdZfy+zIrXfm/OnDnMnj27yvGvvvqKwMCGWV2xdOnSBim3tVD7uU9t6J7/LlnKnnwTu/NN7M6HPQUmSu2Ve0BMGCQEQXKI4XpEWsuBQkg/wM/V/5NUa362PGLzUojNXUfbvI34GMenB9gsgWSE9iU9bAAZoX0ptwRCJpC5Hljv3oU9pPl/Bw969erNv/08r6ioqNbnen0IzB1vvvkmffr0qXHCdG3NnDmTGTNmuH7Py8sjMTGR888/n9BQN7qJq2Gz2Vi6dCmjR4/GtymMfTczaj/3qQ3r72BOMe+t3seidXtIKzbxu9EsgqwWTksMZ0D7cAa2D6dvuzCCrSf8M2s4IGMjpt8PSdWRKT8N0/YvMR1Yg+mEvXSM0HY4uo7F6HoBtB9GjMWPmJOU4y36DrpH7VezihGc2vBqAIqKisJisZCRkVHpeEZGBrGxsSd9b2FhIR988AGPP/54peMV78vIyCAuLq5Smf3796+2LKvVitVadezW19e3wb5cDVl2a6D2c1+zbcO8NMBotGW3DofBjzuyeGflXr7ZmnEs9Dh7ehIjAxjYPoKBHSIZlBRB15gQLObfzYPJSzu+3Hrnt1CU5dkKxvY9ttpoHKbYPlia0TycZvsdbCLUflXVpT28GoD8/PwYOHAgy5YtY/z48QA4HA6WLVvG9OnTT/reDz/8kNLSUq6++upKx5OTk4mNjWXZsmWuwJOXl8fq1au55ZZbGuJjiEhjyD3o3LAu5T3AgHZDoPcE6DkeQuNO9e66X67IxkfrDvDuqr3szip0HT+jYySdLYe5efx5tGtTzbb+ZUWwb4Uz7Oz8puqeMH7BzmXUFjf++fUNci7J7jrWvQ37RFoxrw+BzZgxg6lTpzJo0CCGDBnCCy+8QGFhoWtV2LXXXktCQgJz5syp9L4333yT8ePH06ZNm0rHTSYTd911F08++SRdunRxLYOPj493hSwRaUZKcuHHF2DVP064x5Dp+Jb9S2Y6N6rrdSn0vMR5o0c3bDqUy79W7uXTlIOU2JzDSyFWHyYObMfVpyeRFGFl8eLFxzciNAzI2Hh8D5m9K393fyeTc5fcik312g12bjonIl7l9QB05ZVXcvjwYR599FHS09Pp378/S5YscU1i3rdvH+bfbWyVmprKjz/+yFdffVVtmffddx+FhYXcfPPN5OTkMHz4cJYsWaI9gESak/Iy+GUefPfX48uO258B5z8BoQnOHXs3fuwMQRXb9C/+M3Q8B3pPhO4XOpcz10JpuZ0lG9N5Z+Ve1u496jrePTaEa4YlMb5/AkHH5vLYbDasthxMG/4Ne753hp7CzMoFhiYcDzwdz9WeMCJNkNcDEMD06dNrHPJavnx5lWPdunXDMGreyMtkMvH4449XmR8kIs2AYcCmT2DZ7GO3UgCiusKo2c49VyrmuJx+i/ORs895/sb/QNpvx3ti/nuXc0O63hOh29hq70J9KKeYBav3svDn/WQVOFdQ+ZhNjO0dy3WDohgYchTT0RT4+RM4uhuyd+OTvZuxuftg4wkF+QY6e6E6jXSGnqguLWdPHJEWqkkEIBERAPb8BEsfcd6qASA4Bs6dCaddU/OcmfD2cOadzseRnc5eoY3/cd63aNsXzoePP3QdA70mYHQ5n5/2FvHOit2kbN1GIhmcbcqgZ2A2w9vk08knE98De2Fb9ZOVK2KNEdsXU+djgSdxqDbBE2lmFIBExPsOp8LXjzl3LQbnJN8z74Rht538JpS/16YTnPNn5yNjM2w6Foayd8Hmz2DzZxThT5SjLc+bMgmynjBXxwEc/l15gW2cOx5HJrt+locm8tWvexl98ZVagSPSjCkAiYj35KfD8jmw7h3nHjkmCwycCuc8ACH138Emr8TG6iNt+KngUlaUD8e3dCMXWVZyoWUV7UxZdDfvB8AwmTGFtoPIDlWCDhHJ4F91HzDDZsO2IbvedRORpkEBSEQaX2k+rHjZ+bAd27m1+4Uwcha07Vrn4kpsdtbtO8qKHUf4cUcWGw7mVrrnlsmUDNH9ONrpQcZEpNErohxr286YwttrRZZIK6UAJCKNoyQXMrc670a+4iWouFdVu8Ew+glIGlbrouwOg40Hc/lpZxYrdhzh5z3ZlJY7Kp2THBXEGZ3acGbnKIZ1bENEUEXQ6eWhDyQizZkCkIh4VlkRZKVC5hbnJoCZW5zBJ+9A5fMiOzp7fHpeUqsVU4ZhsHLXEd5fs5/vUjPJK6l88822IVbO7NSGMzpHcWbnKBLCAzz5qUSkhVEAEpH6KS+DIztOCDnHAs/RPThvjV2NkHiI7g7dxsGAqbUafsottvGftQdYsHovOw8f35E5xOrD0I5tOLNzG4Z3jqJzdDAmLT0XkVpSABKR2rGXw46vnauq0tc7w4+jvPpzAyIhphdE93A+2vZwBp+AiFpfbsOBXN5dtZfPfju+I3OQn4XxpyUwYUA7+rULw8diPkUpIiLVUwASkZPL3AIpC+C3hVV3PPYLOR5yonsefx7Utl4bARaX2fnv+kMsWLWX3w7kuo53iwnh6tPbM/60BEL8tfRcRNynACQiVRVlO3t6Ut6DQ+uOHw9sA32vdG7+F93DecsHDww77TpcwILV+/ho7QFyi20A+FpMjOsTx9WnJzEoKULDWyLiUQpAIuJkL4dd3zp7e7YuArvz1hCYfaDLGDhtCnQe7bFl4za7g683Z/Du6r38tOOI63i7iACuGtqeKwYlEhWs3ZVFpGEoAIm0doe3OUPP+oWQn3b8eExv6D8F+lwOwW09drn03BLeX7OPD37eR0aecydmkwlGdIvm6tOTOLtrWyxm9faISMNSABJphXzKCzGvmw8bFsKBn4+/EBAJfa+A/ldBXD+PXtMwDN5bs4/Z/91M2bE9e9oE+XHl4EQmD2lPYmSgR68nInIyCkAirUl+BpYvH2Tsps+wbHDOtcFkgS7nO0NP17ENsjNyfomNmR9v4H/rnT1MA9qHM/WMDoztHYvVx+Lx64mInIoCkEhrUXAY3r4Ic1YqAEbb7phOu9o5qTk4usEuu+lQLrctWMeeI0X4mE3cN7YbNw3viFnDXCLiRQpAIq1BUTa8cwlkpWKExPND3DSGXTYdX7+Guw/W74e84sP8efmqAQxMqv1eQCIiDUUBSKSlKz7qDD+ZmyA4lvKrP+HoqlSPLF+vye+HvEZ0j+a5y/udcD8uERHvUgASaclK8uDdic6dm4PawtTPIbwjkNpgl9SQl4g0BwpAIi1VaQEsuAwOrnWu7rr2c2jbDWy2BrmcYRgsWL2Px/+nIS8RafoUgERaorIieO9K2L8a/MPg2k8hpmeDXU5DXiLS3CgAibQ0tmL4YDLs/RGsoXDNJx7f0+dEGvISkeZIAUikJSkvhYVXw67l4BcMV/8HEgY2yKU05CUizZkCkEhLUV4GH14HO74G30C46t+QOKRBLqUhLxFp7hSARFoCezn850ZIXQw+/jD5fehwZoNcSkNeItISKACJNHcOO3xyM2z5HCx+MGkBdDzXY8WX2x38diCHH7Zn8eP2LH7dn4PdYWjIS0SaNQUgkebM4YDPboON/wGzD1zxDnQe5VaRhmGw50gRP2w/zA/bs1i18wj5peWVzhnVI4ZnL+urIS8RabYUgESaK4cD/ncn/Pa+84aml70F3S6oV1FHC8v4aaezh+eH7VkczCmu9HpYgC9ndm7D8M5tOatLlO7cLiLNngKQSGPa8j/44W8QlgjRPSG6h/MR2QksdfjP0TDgiz/DunfAZIaJb0DPi2v99nIHrNqVzYrdR/lxexYbD+ViGMdf97WYGJgUwVld2jK8cxS9E8KwaI6PiLQgCkAijSUvDT69FUpz4dCvzjk7FSx+ENX1eCBqe+xneBKYzZXLMQz48kH4+Z+ACca/Cr0n1qoKB3OKefTTDfywzULZ6l8qvdY1JtjVwzMkOZIgq/55EJGWS//CiTQGw4BF9zjDT1w/6HMFHN4CmVsgcyvYCiFjo/NxIt9AaNv9WG9Rd2co2rUcVv3D+frFL0G/SbWqQmFpOTfO/5mt6fmAiahgP4Z3jnL28nSJIibU36MfWUSkKVMAEmkMmz+F1EXOicrjX4WYXsdfczggd9+xMHTCIysVbEVwaJ3z8Xt/eA4GXFuryxuGwZ8/+o2t6flEBfsxNbmIP14+Gj8/TWIWkdZJAUikoRVlw+I/O5+fdU/l8APOIa6IDs7HiZOY7eVwdDdkbq4cjPIOwshZMPimWlfhlW93sHhDOr4WE69M7k/6xhWYTJrTIyKtlwKQSENbMhMKDzuHss66p/bvs/hAVBfno+cl9b780s0Z/O2rbQA8fklvBrQPZ/HGU7xJRKSFM5/6FBGpt+1LYf0HgAkueQV8rI16+R2Z+dy9MAWAa05PYvKQ9o16fRGRpkoBSKShlOTBf+9yPj/9Vmg3qFEvn1tkY9o7aykoLWdIciSPXtSzUa8vItKUKQCJNJRlsyHvgHMp+4iHGvXSdofBHR/8yu6sQhLCA3h1ygB8LfrPXUSkgv5FFGkIe1cc26cH51J1v6BGvfwzX27lu22H8fc18/q1A2kT3LhDbyIiTZ0CkIin2Yrhs+nO5wOu9eiNSWvjs5SD/N93uwB49rJ+9IoPa9Tri4g0BwpAIp62/C+QvROCY2H0E4166Q0Hcrnvo/UA3HJuJy7qF9+o1xcRaS4UgEQ86dCvsOJl5/ML50JAeKNd+nB+KTf/6xdKyx2c160t957frdGuLSLS3CgAiXiK3Qaf3Q6GHXpNgO5/aLRLl5U7uHXBWtJyS+jYNogXJ5+mm5eKiJyEApCIp/z0ImRsgIAIuOCZRr307P9u4uc9Rwmx+vDGtYMI9fdt1OuLiDQ3CkAinnA4Fb77q/P52L9CcNtGu/SC1XtZsHofJhO8OLk/ndoGN9q1RUSaKwUgEXc57M5VX/Yy6HI+9L2i0S69Znc2sz7bBMC953djRPeYRru2iEhz5vUA9Morr9ChQwf8/f0ZOnQoa9asOen5OTk53HbbbcTFxWG1WunatSuLFy92vf7YY49hMpkqPbp3797QH0Nas5//CQfWgF8wXPg8NNJNRg/mFHPLu2spdxhc2DeOW8/t1CjXFRFpCbx6M9SFCxcyY8YMXnvtNYYOHcoLL7zAmDFjSE1NJTo6usr5ZWVljB49mujoaD766CMSEhLYu3cv4eHhlc7r1asXX3/9tet3Hx/d81UayNG98PVs5/PRsyGsXaNctrjMzh//9QtHCsvoGRfKM5f11d3dRUTqwKvJYO7cuUybNo3rr78egNdee41FixYxb948HnjggSrnz5s3j+zsbFasWIGvr3OSZ4cOHaqc5+PjQ2xsbIPWXQTDgP/eCbZCSDoTBt7QSJc1eODj9Ww8mEdkkB+vXzuQQD+FfBGRuvDav5plZWWsXbuWmTNnuo6ZzWZGjRrFypUrq33P559/zrBhw7jtttv47LPPaNu2LVdddRX3338/FovFdd727duJj4/H39+fYcOGMWfOHNq3r/ku2KWlpZSWlrp+z8vLA8Bms2Gz2dz9qJVUlOfpcluLptR+pt/ex2fXtxg+/pRf8BzY7c5HA3vjx918lnIIH7OJl67sS0ywb53aoym1YXOk9nOf2tA9ar+a1aVNTIZhGA1YlxodOnSIhIQEVqxYwbBhw1zH77vvPr777jtWr15d5T3du3dnz549TJkyhVtvvZUdO3Zw6623cscddzBr1iwAvvjiCwoKCujWrRtpaWnMnj2bgwcPsnHjRkJCQqqty2OPPcbs2bOrHH/vvfcIDAz00CeWlsRqy2HElgfwsxexKf5KdsQ0zp4/G4+a+OdWMwYmLku2c1asV/7zFRFpkoqKirjqqqvIzc0lNDT0pOc2qwDUtWtXSkpK2L17t6vHZ+7cuTz77LOkpaVVe52cnBySkpKYO3cuN954Y7XnVNcDlJiYSFZW1ikbsK5sNhtLly5l9OjRrmE8qb2m0n6Wj67DnPo/HLH9sF//JZgbvjN19e5sbnxnHaXlDq4YmMCTl/Ss17yfptKGzZXaz31qQ/eo/WqWl5dHVFRUrQKQ14bAoqKisFgsZGRkVDqekZFR4/yduLg4fH19Kw139ejRg/T0dMrKyvDz86vynvDwcLp27cqOHTtqrIvVasVqrXq3bF9f3wb7cjVk2a2BV9tv82eQ+j8w+2Ae/wpma0CDX/LXfUf547u/UlruYFSPGJ6a0Bdfi3uLOPUddI/az31qQ/eo/aqqS3t4bRm8n58fAwcOZNmyZa5jDoeDZcuWVeoROtGZZ57Jjh07cDgcrmPbtm0jLi6u2vADUFBQwM6dO4mLi/PsB5DWqSgbFt3rfD78bojt0+CX3Hwoj6nz1lBYZufMzm34+1WnuR1+RERaO6/+KzpjxgzeeOMN3n77bbZs2cItt9xCYWGha1XYtddeW2mS9C233EJ2djZ33nkn27ZtY9GiRTz99NPcdtttrnPuvfdevvvuO/bs2cOKFSu49NJLsVgsTJ48udE/n7RAS2ZCYSZEdYOz/9zgl9uRWcA1b64mr6ScgUkRvHHtIPx9Lad+o4iInJRX185eeeWVHD58mEcffZT09HT69+/PkiVLiIlx7ma7b98+zObjGS0xMZEvv/ySu+++m759+5KQkMCdd97J/fff7zrnwIEDTJ48mSNHjtC2bVuGDx/OqlWraNu28W5NIC3Uho9g/QdgMsMlfwefqsOmnrQ/u4ir/7maI4Vl9IoPZd51g7XcXUTEQ7z+r+n06dOZPn16ta8tX768yrFhw4axatWqGsv74IMPPFU1keNy9sH/Zjifn/1nSBzSoJfLyCthyj9Xk55XQufoYN65YQhhARrrFxHxFE0kEDkVhx0+/iOU5kK7wXD2fQ16uSMFpUz552r2ZRfRPjKQBTcNpU1ww/Y2iYi0NgpAIqfy41zYt8J5r68Jb4Cl4TpOc4ttXDtvDTsyC4gN9WfBTUOJCfVvsOuJiLRWCkAiJ3NgLXw7x/l83N8gMrnBLlVUVs4N839m06E82gT58e5NQ0mM1EacIiINQQFIpCal+fCfG8GwQ68J0G9Sg12qxGZn2ju/sHbvUUL9ffjXjUPpHB3cYNcTEWntFIBEavLFA3B0N4QlwoXPQwPdbd1mdzD9vXX8tOMIgX4W5t8whJ7xnt2BXEREKlMAEqnOpk8g5V3nkvdL/w8CwhvkMnaHwd0LU/h6SyZWHzP/nDqIAe0jGuRaIiJynAKQyO/lHoD/3ul8PnwGdDizQS7jcBg8+PEG/rc+DV+LideuHsgZnaIa5FoiIlKZApDIiSqWvJfkQsJAOPeBBrmMYRg8sWgzC3/Zj9kEL046jfO6RzfItUREpCoFIJET/fQi7P0RfIOOLXlvmM0H5y7dxls/7QHgmcv6Ma6P7lUnItKYFIBEKhxcB98+5Xw+7hlo06lBLvPadzt5+ZsdADx+SS8uG9iuQa4jIiI1UwASASgtgP/cBI5y6Dke+k9pkMssWL2Xv3yxFYD7xnbj2mEdGuQ6IiJycgpAIgBfzoTsnRCa0GBL3pdtyeCRTzcCcOu5nbj13M4ev4aIiNSOApDI5s9g3TuAybnkPTDS45dYfyCH6e/9isOAywe2489junn8GiIiUnsKQNK65R6Ez+9wPh9+FySf5fFL7M8u4ob5v1Bss3NWlyientAHUwNtqigiIrWjACStl8MBn/4JSnIgrj+c+6DHL5FbZOP6+T+TVVBK99gQ/jFlAL4W/WcnIuJt+pdYWq+VL8Pu78E3ECa+CT5+Hi2+tNzOzf/6xXVn97euH0yIf8MsqxcRkbpRAJLW6VAKLHvC+XzsXyDKsxOSHQ6D+z5az+rd2QRbfXjr+sHEhQV49BoiIlJ/CkDS+pQVHlvyboMeF8GAaz1+ieeWpvJZyiF8zCb+MWUAPeJ0c1MRkaZEAUhany8fgiPbISQOLnrJ40ve31u9j1e+3QnA0xP6cHbXth4tX0RE3KcAJK3L1kWw9i2cS95f8/iS929TM3nkM+deP3eM7MIVgxI9Wr6IiHiGApC0Htm74NNbnM/PuB06nuvR4jcezOW2BeuwOwwmDEjg7lFdPFq+iIh4jgKQtA5lRbDwmmN3eR8EIx72aPEHc4q5fv7PFJXZObNzG/4yoa/2+hERacIUgKTlMwz47x2QsRGC2sIV74CP1WPF5xbbuP6tNRzOL6VbTAivXj0QPx/9pyUi0pTpX2lp+Va/Bhs+BJMFLn8bwhI8VnRZuYM//Wst2zIKiAm18tb1gwnVXj8iIk2eApC0bHt+dK76AhjzFHQ402NFG4bBA/9Zz8pdRwjyszDvusHEh2uvHxGR5kABSFquvEPw4XVg2KHP5TD0Tx4t/vml2/j414NYzCb+cfVAesWHebR8ERFpOApA0jKVl8K/r4XCwxDTGy560aP7/fz75/289M0OAJ4a35tztNePiEizogAkLdMX98OBn8E/DK78F/gFeazo77YdZuYnGwC4fURnJg1p77GyRUSkcSgAScuz7p3jmx1OfBMiO3qs6M2H8rj13bXYHQaXnpbAjNFdPVa2iIg0HgUgaVkOroVF9zqfn/cQdBntsaKLy+zcumAthWV2hnVsw18naq8fEZHmSgFIWo7CLFh4LdhLods4OOsejxb/7Jep7DlSRGyoP69prx8RkWZN/4JLy2Avh4+uh7wD0Kaz8z5fZs99vdfszuatFbsBmDOxD2GB2utHRKQ5UwCSlmHZY7D7e/ANgisXOCc/e0hxmZ37PvoNw4DLB7bjvG7RHitbRES8QwFImr+NH8OKl53Px/8Dort7tPgTh74evrCnR8sWERHvUACS5i1jM3w23fn8zDuh13iPFl9l6CtAQ18iIi2BApA0X8U5sPBqsBVC8jkw4lHPFq+hLxGRFksBSJonwwGf/BGyd0JYIlz2Flh8PHoJDX2JiLRcCkDSLJl/fA62LQGL1bnTc1Abj5avoS8RkZbNs/+XWaQRxOSmYP71eecvFz4P8ad5tHwNfYmItHzqAZLmJXsXA/a+hgkDBt0Ip03x+CU09CUi0vKpB0iaFcvnt2G2F+FIGIx57F88Xr6GvkREWgf1AEnzYSvBfPBnAOzjXwMfP48Wr6EvEZHWQwFImo/cAwCUm60Q1t7jxWvoS0Sk9VAAkuYjdx8ARX5R4OG7sGvoS0SkdVEAkuYjZz9wLAB5kIa+RERaH68HoFdeeYUOHTrg7+/P0KFDWbNmzUnPz8nJ4bbbbiMuLg6r1UrXrl1ZvHixW2VKM5Hj7AEq9vPsnj8a+hIRaX28GoAWLlzIjBkzmDVrFuvWraNfv36MGTOGzMzMas8vKytj9OjR7Nmzh48++ojU1FTeeOMNEhIS6l2mNCO5FT1AbT1WpIa+RERaJ68ug587dy7Tpk3j+uuvB+C1115j0aJFzJs3jwceeKDK+fPmzSM7O5sVK1bg6+v8Q9WhQwe3ygQoLS2ltLTU9XteXh4ANpsNm83m9uc8UUV5ni63NbAc3YsZKPJr45H2Ky6z8+cPnUNfEwfEM7xjRKv430XfQfeo/dynNnSP2q9mdWkTk2EYRl0K79ChAzfccAPXXXcd7dvXfyVOWVkZgYGBfPTRR4wfP951fOrUqeTk5PDZZ59Vec+4ceOIjIwkMDCQzz77jLZt23LVVVdx//33Y7FY6lUmwGOPPcbs2bOrHH/vvfcIDAys92cUzxq98S4Cbdl833UWR4M6uV3ex3vMfJdmJszP4IF+dgK1K5aISLNWVFTEVVddRW5uLqGhoSc9t87/5N91113Mnz+fxx9/nPPOO48bb7yRSy+9FKvVWqdysrKysNvtxMTEVDoeExPD1q1bq33Prl27+Oabb5gyZQqLFy9mx44d3HrrrdhsNmbNmlWvMgFmzpzJjBkzXL/n5eWRmJjI+eeff8oGrCubzcbSpUsZPXq0qxdLasFuwyclB3D2ALnbfj/vOcr3q5x7Cj135QDO6eq5YbWmTt9B96j93Kc2dI/ar2YVIzi1Ua8AdNddd7Fu3Trmz5/P7bffzq233spVV13FDTfcwIABA+paZK05HA6io6N5/fXXsVgsDBw4kIMHD/Lss88ya9asepdrtVqrDXC+vr4N9uVqyLJbpIKDYDgwLFZKfULdar/iMjsPfrrJteprVK94D1e2edB30D1qP/epDd2j9quqLu1R70nQAwYM4KWXXuLQoUPMmjWLf/7znwwePJj+/fszb948TjWyFhUVhcViISMjo9LxjIwMYmNjq31PXFwcXbt2xWKxuI716NGD9PR0ysrK6lWmNBPHVoAR1g5M7s3d16ovERGp918Sm83Gv//9by6++GLuueceBg0axD//+U8mTpzIgw8+yJQpJ79JpZ+fHwMHDmTZsmWuYw6Hg2XLljFs2LBq33PmmWeyY8cOHA6H69i2bduIi4vDz8+vXmVKM3FsDyAjLNGtYrTqS0REoB5DYOvWreOtt97i/fffx2w2c+211/L888/TvXt31zmXXnopgwcPPmVZM2bMYOrUqQwaNIghQ4bwwgsvUFhY6FrBde2115KQkMCcOXMAuOWWW/j73//OnXfeye2338727dt5+umnueOOO2pdpjRTx5bA42YAenrxFm14KCIidQ9AgwcPZvTo0bz66quMHz++2vG25ORkJk2adMqyrrzySg4fPsyjjz5Keno6/fv3Z8mSJa5JzPv27cNsPt5JlZiYyJdffsndd99N3759SUhI4M477+T++++vdZnSTB0bAjPCEqH2c9wqKbHZ2XgwF4A7R3XxVM1ERKQZqnMA2rVrF0lJSSc9JygoiLfeeqtW5U2fPp3p06dX+9ry5curHBs2bBirVq2qd5nSTFUEoPD6B6DtGQWUOwzCA31JCA/wYOVERKS5qfMcoMzMTFavXl3l+OrVq/nll188UimRKlyToOs/BLbpkLP3p1d8KCYP30xVRESalzoHoNtuu439+/dXOX7w4EFuu+02j1RKpBKHHfIOAu5Ngt6c5uw66hUf5pFqiYhI81XnALR58+Zq9/o57bTT2Lx5s0cqJVJJfho4ysHsA8H1385g0yFnAOoZ59nNLUVEpPmpcwCyWq1V9tkBSEtLw8dH9xKQBnBsCTyhCWC2nPzcGjgcBltcPUAKQCIirV2dA9D555/PzJkzyc3NdR3LycnhwQcfZPTo0R6tnAhwfAl8eP3vPbfnSCFFZXasPmaSo4I8VDEREWmu6txl87e//Y2zzz6bpKQkTjvtNABSUlKIiYnhX//6l8crKELOXudPNwJQxfyf7nGh+Fjc20laRESavzoHoISEBNavX8+CBQv47bffCAgI4Prrr2fy5Mm6J4k0jBz3e4Aq5v9o+EtERKAeAQic+/zcfPPNnq6LSPU8sgReE6BFROS4es9a3rx5M/v27aOsrKzS8YsvvtjtSolU4poD5MYSePUAiYjICeq1E/Sll17Khg0bMJlMrru+V2wsZ7fbPVtDad0cDreHwDLzSsgqKMVsgu6xCkAiIlKPVWB33nknycnJZGZmEhgYyKZNm/j+++8ZNGhQtbeuEHFL4WGwl4LJ7FwGXw+bjk2A7tg2mAC/+i2jFxGRlqXOPUArV67km2++ISoqCrPZjNlsZvjw4cyZM4c77riDX3/9tSHqKa1VxfBXSDxYfMFhq3MRGv4SEZHfq3MPkN1uJyQkBICoqCgOHToEQFJSEqmpqZ6tnYhrCbz79wDTBGgREalQ5x6g3r1789tvv5GcnMzQoUN55pln8PPz4/XXX6djx44NUUdpzTywBP54D5DuASYiIk51DkAPP/wwhYWFADz++ONceOGFnHXWWbRp04aFCxd6vILSyrm5BD6/xMaeI0UA9NQQmIiIHFPnADRmzBjX886dO7N161ays7OJiIhwrQQT8Rg3l8BvTc8HIC7Mn8ggP0/VSkREmrk6zQGy2Wz4+PiwcePGSscjIyMVfqRhVPQA1XMIbNNBzf8REZGq6hSAfH19ad++vfb6kcZhGMfnAIXVLwBt1h3gRUSkGnVeBfbQQw/x4IMPkp2d3RD1ETmuKBtszvlmhLWrVxGuW2BoArSIiJygznOA/v73v7Njxw7i4+NJSkoiKCio0uvr1q3zWOWklcs9NvwVHAO+/nV+e1m5g20ZzjlA6gESEZET1TkAjR8/vgGqIVINN5fA78gswGY3CPH3oV1EgAcrJiIizV2dA9CsWbMaoh4iVbm5BP7EDRA1SV9ERE5U5zlAIo0m170eoOMToDX/R0REKqtzD5DZbD7p/5vWCjHxGNcS+Pr2AGkFmIiIVK/OAeiTTz6p9LvNZuPXX3/l7bffZvbs2R6rmIg7S+AdDoMtrhVgCkAiIlJZnQPQJZdcUuXYZZddRq9evVi4cCE33nijRyom4s4miAeOFpNfWo6fxUzn6GAPV0xERJo7j80BOv3001m2bJmnipPWriQXSp2TmOszBFYxAbprbDC+Fk11ExGRyjzyl6G4uJiXXnqJhIQETxQncnz4K7AN+AWd/NxquCZAx2kCtIiIVFXnIbDf3/TUMAzy8/MJDAzk3Xff9WjlpBVzewn8sQCUoPk/IiJSVZ0D0PPPP18pAJnNZtq2bcvQoUOJiIjwaOWkFXN3CXzFBGjdBFVERKpR5wB03XXXNUA1RH7HjQnQRwpKSc8rwWSC7gpAIiJSjTrPAXrrrbf48MMPqxz/8MMPefvttz1SKRF3hsAqhr86tAki2FrnjC8iIq1AnQPQnDlziIqKqnI8Ojqap59+2iOVEnGnB6hiArT2/xERkZrUOQDt27eP5OTkKseTkpLYt2+fRyolcnwOUP17gDT/R0REalLnABQdHc369eurHP/tt99o06aNRyolrVxZIRQdcT6vxxDY5mN7AOkWGCIiUpM6B6DJkydzxx138O2332K327Hb7XzzzTfceeedTJo0qSHqKK1NxR5A1jAICK/TW4vKytmVVQjoJqgiIlKzOs8QfeKJJ9izZw8jR47Ex8f5dofDwbXXXqs5QOIZbiyB35KWj2FA2xArbUOsHq6YiIi0FHUOQH5+fixcuJAnn3ySlJQUAgIC6NOnD0lJSQ1RP2mNcvY6f9Zj/o9rB2gNf4mIyEnUe41wly5d6NKliyfrIuLkugt8/ef/aAK0iIicTJ3nAE2cOJG//vWvVY4/88wzXH755R6plLRy7iyBr7gFhub/iIjISdQ5AH3//feMGzeuyvELLriA77//3iOVklaunkvgy+0OtqbnAxoCExGRk6tzACooKMDPz6/KcV9fX/Ly8jxSKWnlcuo3CXpXViGl5Q6CrT60jwxsgIqJiEhLUecA1KdPHxYuXFjl+AcffEDPnj09UilpxWwlUJDufB5WtwC06dj8nx5xIZjNplOcLSIirVmdJ0E/8sgjTJgwgZ07dzJixAgAli1bxnvvvcdHH33k8QpKK5N30PnTNwgCI+v01k0HtQO0iIjUTp17gC666CI+/fRTduzYwa233so999zDwYMH+eabb+jcuXO9KvHKK6/QoUMH/P39GTp0KGvWrKnx3Pnz52MymSo9/P39K51z3XXXVTln7Nix9aqbNLITl8Cb6taLc3wJvCZAi4jIydVrGfwf/vAH/vCHPwCQl5fH+++/z7333svatWux2+11KmvhwoXMmDGD1157jaFDh/LCCy8wZswYUlNTiY6OrvY9oaGhpKamun43VfOHcuzYsbz11luu361WbYrXLNRzCbxhGMfvAaYJ0CIicgr13gfo+++/58033+Q///kP8fHxTJgwgVdeeaXO5cydO5dp06Zx/fXXA/Daa6+xaNEi5s2bxwMPPFDte0wmE7GxsSct12q1nvKcCqWlpZSWlrp+r5jMbbPZsNlstSqjtirK83S5LYU5ew8WwB7aDkc1bVRT+x3KKSa32IaP2USHSH+170noO+getZ/71IbuUfvVrC5tUqcAlJ6ezvz583nzzTfJy8vjiiuuoLS0lE8//bReE6DLyspYu3YtM2fOdB0zm82MGjWKlStX1vi+goICkpKScDgcDBgwgKeffppevXpVOmf58uVER0cTERHBiBEjePLJJ2u8WeucOXOYPXt2leNfffUVgYENs5po6dKlDVJuczdgzyoSga3phexYvLjG837ffhuyTYCFGH8Hy75a0rCVbCH0HXSP2s99akP3qP2qKioqqvW5JsMwjNqceNFFF/H999/zhz/8gSlTpjB27FgsFgu+vr789ttv9QpAhw4dIiEhgRUrVjBs2DDX8fvuu4/vvvuO1atXV3nPypUr2b59O3379iU3N5e//e1vfP/992zatIl27doBzhVpgYGBJCcns3PnTh588EGCg4NZuXIlFoulSpnV9QAlJiaSlZVFaKhnh1NsNhtLly5l9OjR+Pr6erTslsDyzoWY96+i/NI3MHpeWuX1mtrvpW928PK3u7j0tHiemdC7Mavc7Og76B61n/vUhu5R+9UsLy+PqKgocnNzT/n3u9Y9QF988QV33HEHt9xyi1dvgTFs2LBKYemMM86gR48e/N///R9PPPEEQKW70vfp04e+ffvSqVMnli9fzsiRI6uUabVaq50j5Ovr22BfroYsu1nLPQCAT2QynKR9ft9+WzOcd4DvkxCudq0lfQfdo/Zzn9rQPWq/qurSHrVeBfbjjz+Sn5/PwIEDGTp0KH//+9/JysqqVwUrREVFYbFYyMjIqHQ8IyOj1vN3fH19Oe2009ixY0eN53Ts2JGoqKiTniNNgN0G+Yecz+u4CeJmTYAWEZE6qHUAOv3003njjTdIS0vjj3/8Ix988AHx8fE4HA6WLl1Kfn5+nS/u5+fHwIEDWbZsmeuYw+Fg2bJllXp5TsZut7Nhwwbi4uJqPOfAgQMcOXLkpOdIE5B3EAwHWKwQ1LbWb8spKuNgTjGgACQiIrVT532AgoKCuOGGG/jxxx/ZsGED99xzD3/5y1+Ijo7m4osvrnMFZsyYwRtvvMHbb7/Nli1buOWWWygsLHStCrv22msrTZJ+/PHH+eqrr9i1axfr1q3j6quvZu/evdx0002Ac4L0n//8Z1atWsWePXtYtmwZl1xyCZ07d2bMmDF1rp80ItcS+HZgrv1Xs6L3p31kIKH+6g4WEZFTq3MAOlG3bt145plnOHDgAO+//369yrjyyiv529/+xqOPPkr//v1JSUlhyZIlxMTEALBv3z7S0tJc5x89epRp06bRo0cPxo0bR15eHitWrHBNwrZYLKxfv56LL76Yrl27cuONNzJw4EB++OEH7QXU1NXzLvCu/X+0A7SIiNRSvfcBOpHFYmH8+PGMHz++Xu+fPn0606dPr/a15cuXV/r9+eef5/nnn6+xrICAAL788st61UO8rJ53gT++A7QCkIiI1I5bPUAiHlXvHiDnTVA1/0dERGpLAUiajooAVIe7wJfY7Ow87FwCr3uAiYhIbSkASdPhGgKrfQBKTc/H7jBoE+RHTKjmeImISO0oAEnT4LC7NkGsyxygivk/PeNDq70proiISHUUgKRpyE8HRzmYfSCk9vs1af6PiIjUhwKQNA0V839CE8Bc9X5tNdESeBERqQ8FIGka6jH/x+4w2Jrm3IFcE6BFRKQuFICkacjZ6/xZhwC0O6uQYpudAF8LyVFBDVQxERFpiRSApGlw3Qaj7hOgu8eFYDFrArSIiNSeApA0DfUYAquYAK0doEVEpK4UgKRpcO0CXYceINcEaM3/ERGRulEAEu8zjON7ANVyCMwwDFcAUg+QiIjUlQKQeF9BJpSXgMnsXAZfCxn5pRwpLMNiNtEtNqSBKygiIi2NApB4X8X8n5A48PGr1Vu2HFv+3qltEP6+td83SEREBBSApCmoxxL4zdr/R0RE3KAAJN5XjyXwW9K0A7SIiNSfApB4n2sFWH16gBSARESk7hSAxPtcewDVrgeouBz2Hy0GdBNUERGpHwUg8b6cum2CeLDI+TMhPIDwwNpNmhYRETmRApB4l2EcHwILq10AOlDovO2Fen9ERKS+FIDEu4qPgq3Q+TysXa3ecrAiAGkCtIiI1JMCkHhXxRL44Bjw9a/VWyoCkCZAi4hIfSkAiXfVcQl8abmDNOf8Zw2BiYhIvSkAiXfVcQn8jswCHIaJsAAfEsIDGrBiIiLSkikAiXfVcQl8xf4/PeNCMZlMDVUrERFp4RSAxLvquAR+S7ozAPXQDVBFRMQNCkDiXXVcAn/8FhgKQCIiUn8KQOJduRVzgE49BFZud7juAt9DAUhERNygACTeU5LrfECtVoFtOpRHYZmdAItBp7bBDVw5ERFpyRSAxHsq5v8ERIL11IFm9e4jAHQKNbCYNQFaRETqTwFIvKeOS+BX78oGnAFIRETEHQpA4j11WAJvdxis2e0MQF0UgERExE0KQOI9rh6gpFOeuiUtj/zScoKtPiQENXC9RESkxVMAEu9xLYE/dQ/Qql3O+T8Dk8LR9B8REXGXApB4Tx2GwFYfG/4amhzRkDUSEZFWQgFIvKeWk6AdJ8z/GdIhsqFrJSIirYACkHhHWSEUOYe1TjUEtjU9n9xiG0F+FnppA0QREfEABSDxjoo9gKxhEBB+0lMr9v8Z2CESH4u+siIi4j79NRHvqMP8n4oJ0Kd31PCXiIh4hgKQeEfOXufPOsz/GZrcpqFrJSIirYQCkHhHxRDYKeb/bM8s4GiRjQBfC33bhTVCxUREpDVQABLvqOUQWMXw16AOEfhq/o+IiHiI/qKId9RyCXzFBOihyZr/IyIinqMAJN5RiyEwwzBcN0Ad2lHzf0RExHOaRAB65ZVX6NChA/7+/gwdOpQ1a9bUeO78+fMxmUyVHv7+/pXOMQyDRx99lLi4OAICAhg1ahTbt29v6I8htWUrgYJ05/OT3AdsR2YBRwrL8Pc1a/6PiIh4lNcD0MKFC5kxYwazZs1i3bp19OvXjzFjxpCZmVnje0JDQ0lLS3M99u7dW+n1Z555hpdeeonXXnuN1atXExQUxJgxYygpKWnojyO1kXfQ+dM3EAJrHtpadWz114D2EVh9LI1RMxERaSV8vF2BuXPnMm3aNK6//noAXnvtNRYtWsS8efN44IEHqn2PyWQiNja22tcMw+CFF17g4Ycf5pJLLgHgnXfeISYmhk8//ZRJkyZVeU9paSmlpaWu3/Py8gCw2WzYbDa3Pt/vVZTn6XKbE1PWLnwAIyyR8vLyGs9btSMLgEFJ4VXarTW3n7vUhu5R+7lPbegetV/N6tImXg1AZWVlrF27lpkzZ7qOmc1mRo0axcqVK2t8X0FBAUlJSTgcDgYMGMDTTz9Nr169ANi9ezfp6emMGjXKdX5YWBhDhw5l5cqV1QagOXPmMHv27CrHv/rqKwIDA935iDVaunRpg5TbHLTPWs5pQGaZlVWLF1d7jmHA96kWwISRkcrixamVXm/N7ecpakP3qP3cpzZ0j9qvqqKiolqf69UAlJWVhd1uJyYmptLxmJgYtm7dWu17unXrxrx58+jbty+5ubn87W9/44wzzmDTpk20a9eO9PR0Vxm/L7Pitd+bOXMmM2bMcP2el5dHYmIi559/PqGhoe58xCpsNhtLly5l9OjR+Pr6erTs5sK8/DfYD1GdBzDugnHVnrPrcCH5q37Cz8fMHyeOwerrHAJT+7lPbegetZ/71IbuUfvVrGIEpza8PgRWV8OGDWPYsGGu38844wx69OjB//3f//HEE0/Uq0yr1YrVaq1y3NfXt8G+XA1ZdpOXfwAAS2QHLDW0wdr9zi/xaYnhBAf6V3m9Vbefh6gN3aP2c5/a0D1qv6rq0h5enQQdFRWFxWIhIyOj0vGMjIwa5/j8nq+vL6eddho7duwAcL3PnTKlgdViCbxr/x8tfxcRkQbg1QDk5+fHwIEDWbZsmeuYw+Fg2bJllXp5TsZut7Nhwwbi4uIASE5OJjY2tlKZeXl5rF69utZlSgNzbYJY/RJ4wzB0A1QREWlQXh8CmzFjBlOnTmXQoEEMGTKEF154gcLCQteqsGuvvZaEhATmzJkDwOOPP87pp59O586dycnJ4dlnn2Xv3r3cdNNNgHOF2F133cWTTz5Jly5dSE5O5pFHHiE+Pp7x48d762NKBbsN8g85n9dwG4y9R4rIyCvFz2JmQPuIRqyciIi0Fl4PQFdeeSWHDx/m0UcfJT09nf79+7NkyRLXJOZ9+/ZhNh/vqDp69CjTpk0jPT2diIgIBg4cyIoVK+jZs6frnPvuu4/CwkJuvvlmcnJyGD58OEuWLKmyYaJ4Qd5BMBxgsUJQdLWnVAx/9UsMw99X+/+IiIjneT0AAUyfPp3p06dX+9ry5csr/f7888/z/PPPn7Q8k8nE448/zuOPP+6pKoqnuOb/tANz9SOwq47d/uJ0zf8REZEG4vWdoKWVOcVd4J33/6q4AaoCkIiINAwFIGlcp7gL/IGjxRzKLcHHbGJAUnjj1UtERFoVBSBpXK4hsOoD0MpdFfN/wgn0axIjtCIi0gIpAEnjyjl249oaeoBWH5v/MzRZy99FRKThKABJ4zrFHCBtgCgiIo1BAUgaj8MOuc7bYFTXA3TgaBEHjhZjMZsYlKT9f0REpOEoAEnjSV8PjnLwC4GQuCovVwx/9UkII8iq+T8iItJwFICk8ez8xvkz+WwwV93g8Pjwl+b/iIhIw1IAksaz41gA6jyi2pe1AaKIiDQWBSBpHKX5sH+V83mnqgEoLbeYfdlFmE1o/o+IiDQ4BSBpHHt+dM7/iUiGyI5VXq6Y/9M7IYwQf9/Grp2IiLQyCkDSOHYsc/6spvcHTpj/o/1/RESkESgASeOomADdeWS1L2v+j4iINCYFIGl4R/dA9k4w+0CHs6q8nJlXwu6sQkwmGNRBPUAiItLwFICk4VUMf7UbAv6hVV5etdvZ+9MzLpSwAM3/ERGRhqcAJA1v56mWvzvn/2j4S0REGosCkDQsuw12f+98XtME6F2aAC0iIo1LAUga1sG1UJoHAZEQ17/Ky4fzS9l52Dn/Z4gCkIiINBIFIGlYFfN/Op570ttfdI8NJTzQrxErJiIirZkCkDSsnccCUA3L3ys2QNTwl4iINCYFIGk4RdlwcJ3zecfzqj2logfodN0AVUREGpECkDScXcsBA9r2gLCEKi8fKShlW0YBAEOStQJMREQajwKQNJxT7P685tj+P91iQogM0vwfERFpPApA0jAM43gA6lTT8Nex+T8a/hIRkUamACQN43Aq5B0EixWSzqz2lFWu/X80/CUiIo1LAUgaRkXvT9IZ4BtQ5eWjhWVsTc8H1AMkIiKNTwFIGsYplr+v2eMc/uocHUxUsLWxaiUiIgIoAElDsJXAnp+cz2u8/YX2/xEREe9RABLP27cSyoshOBaie1Z7im6AKiIi3qQAJJ7nWv01AkymKi/nFtnYkp4HaP6PiIh4hwKQeN4p9v/5eU82hgEdo4KIDvFvxIqJiIg4KQCJZ+WnQ8ZGwFTj7S9cy981/CUiIl6iACSetfNb58+4fhBUfcCp2ABR9/8SERFvUQASzzrF8ve8EhubDuUC2gBRRES8RwFIPMfhON4DVMPy91/2ZOMwoEObQGLDNP9HRES8QwFIPCd9PRRlgV8wtBtS7SnH9/9R74+IiHiPApB4TsXwV4ezwKf6u7uv0g1QRUSkCVAAEs+pGP6qYf7P+2v2seFADqAVYCIi4l0+3q6AtBClBbBvlfP57+b/2B0GTy3awryfdgMwaXAiCeFVb5AqIiLSWBSAxDP2/AgOG4QnQWRH1+H8Ehu3v/8ry1MPA3DP6K5MH9HZW7UUEREBFIDEU05c/n7s9hf7jhRx49s/sz2zAH9fM3Ov6M+4PnFerKSIiIiTApB4xo5jAejY8Nea3dn86d21ZBeWERNq5Y1rB9G3Xbj36iciTZphGJSXl2O3271dlSbPZrPh4+NDSUlJq2svi8WCj48PpmruM1lXCkDivqN7IHsnmCyQfDYf/rKfBz/ZgM1u0CchjDeuHaQ9f0SkRmVlZaSlpVFUVOTtqjQLhmEQGxvL/v37PRIEmpvAwEDi4uLw86t+tXFtKQCJ+47d/NRoN5i/fHuI//tuFwDj+sTy3OX9CfCzeLN2ItKEORwOdu/ejcViIT4+Hj8/v1b5R70uHA4HBQUFBAcHYza3nsXchmFQVlbG4cOH2b17N126dHHr8zeJAPTKK6/w7LPPkp6eTr9+/Xj55ZcZMqT6jfRO9MEHHzB58mQuueQSPv30U9fx6667jrfffrvSuWPGjGHJkiWerrqAKwB9lt/dFX7uGNGZu0Z1xWzWP2QiUrOysjIcDgeJiYkEBgZ6uzrNgsPhoKysDH9//1YVgAACAgLw9fVl7969rjaoL6+33MKFC5kxYwazZs1i3bp19OvXjzFjxpCZmXnS9+3Zs4d7772Xs846q9rXx44dS1pamuvx/vvvN0T1xV6OY+d3ALyV0RE/HzMvTurPjPO7KfyISK21tj/kUn+e+q54vQdo7ty5TJs2jeuvvx6A1157jUWLFjFv3jweeOCBat9jt9uZMmUKs2fP5ocffiAnJ6fKOVarldjY2FrVobS0lNLSUtfveXl5gHOimc1mq+MnOrmK8jxdrrds/2UZPcvyOGoEkxbYjQVTBtI/MbzBPl9Laz9vUBu6R+3nvhPb0G63YxgGDocDh8Ph5Zo1D4ZhuH62xjZzOBwYhoHNZsNiqTzFoi7/XXo1AJWVlbF27VpmzpzpOmY2mxk1ahQrV66s8X2PP/440dHR3Hjjjfzwww/VnrN8+XKio6OJiIhgxIgRPPnkk7RpU/3uw3PmzGH27NlVjn/11VcN1iW7dOnSBim3Mf1y2ET0no/p6QPrTL24pVsphzas4NCGhr92S2g/b1Mbukft576lS5fi4+NDbGwsBQUFlJWVebtKzUp+fr63q+AVZWVlFBcX8/3331NeXl7ptbpMpPdqAMrKysJutxMTE1PpeExMDFu3bq32PT/++CNvvvkmKSkpNZY7duxYJkyYQHJyMjt37uTBBx/kggsuYOXKlVXSIsDMmTOZMWOG6/e8vDwSExM5//zzCQ0Nrd+Hq4HNZmPp0qWMHj0aX19fj5bdWBwOgxe+2cG/duzmEz9n2hk25krOHjSuwa/dEtrP29SG7lH7ue/ENrTb7ezfv5/g4GC35nO0JoZhkJ+fT0hISKucMF5SUkJAQABnn312le9MxQhObXh9CKwu8vPzueaaa3jjjTeIioqq8bxJkya5nvfp04e+ffvSqVMnli9fzsiRVe9TZbVasVqtVY77+vo22D9wDVl2QyoqK+eeD9fzxcZ0wiign9k56Tmw5xhoxM/TXNuvKVEbukft5z5fX1/MZjMmkwmz2ax5QLVUMexV0W6tTcV3prr/Buvy36RXA1BUVBQWi4WMjIxKxzMyMqqdv7Nz50727NnDRRdd5DpW8UXw8fEhNTWVTp06VXlfx44diYqKYseOHdUGIKmqxGbnwNEi9mcXs/9oEfuznc83HsrlwNFifC0mXju9APNaB0R1g7B23q6yiEirZ7PZFMxryavR0c/Pj4EDB7Js2TLXMYfDwbJlyxg2bFiV87t3786GDRtISUlxPS6++GLOO+88UlJSSExMrPY6Bw4c4MiRI8TF6TYMFcrtDvZnF7FiZxb//nk/z32Vyl0f/MrEV1cw+Kmv6f7IEkbN/Z7r5//Mo59t4o0fdrNkUzoHjhYTGeTHe9NOZ5jjV2dhNdz9XUSkPgzDoKis3CuPignGtbVkyRKGDx9OeHg4bdq04cILL2Tnzp2u1w8cOMDkyZOJjIwkKCiIQYMGsXr1atfr//3vfxk8eDD+/v5ERUVx6aWXul4zmUyVtngBCA8PZ/78+YBzNbTJZGLhwoWcc845+Pv7s2DBAo4cOcLkyZNJSEggMDCQPn36VFkJ7XA4eOaZZ+jcuTNWq5X27dvz1FNPATBixAimT59e6fzDhw/j5+dX6e91c+f1IbAZM2YwdepUBg0axJAhQ3jhhRcoLCx0rQq79tprSUhIYM6cOfj7+9O7d+9K7w8PDwdwHS8oKGD27NlMnDiR2NhYdu7cyX333Ufnzp0ZM2ZMo362pmZ7Rj5/+yqVzWl5HMopwe44+X/owVYf2kUEkBgZSGJEIImRASRGBDKoQwThAb7w8bfOEzspAImI5xTb7PR89EuvXHvz42MI9Kv9n8bCwkJmzJhB3759KSgo4NFHH+XSSy8lJSWFoqIizjnnHBISEvj888+JjY1l3bp1rpGLRYsWcemll/LQQw/xzjvvUFZWxuLFi+tc5wceeIDnnnuO0047DX9/f0pKShg4cCD3338/oaGhLFq0iGuuuYZOnTq59tibOXMmb7zxBs8//zzDhw8nLS3NNff2pptuYvr06Tz33HOu6SHvvvsuCQkJjBgxos71a6q8HoCuvPJKDh8+zKOPPkp6ejr9+/dnyZIlronR+/btq9MYp8ViYf369bz99tvk5OQQHx/P+eefzxNPPFHtPJ/WoKzcwT+W7+CVb3dgsx8PPX4WM+0iAmgXGUhiNUEnPNC35gl2h1Mh7wBYrJB0RiN9EhGRpmXixImVfp83bx5t27Zl8+bNrFixgsOHD/Pzzz8TGRkJQOfOnV3nPvXUU0yaNKnSKuR+/frVuQ533XUXEyZMqHTs3nvvdT2//fbb+fLLL/n3v//NkCFDyM/P58UXX+Tvf/87U6dOBaBTp04MHz4cgAkTJjB9+nQ+++wzrrjiCgDmz5/Pdddd16ImXXs9AAFMnz69SndbheXLl5/0vRVdgRUCAgL48kvv/D+HpmjdvqM88J/1bMsoAGBk92huPrsjSW2CiA6x1n+zwmO7P5M0DPy0e6uIeE6Ar4XNj3unxz7At2637tm+fTuPPvooq1evJisry9W7s2/fPlJSUjjttNNc4ef3UlJSmDZtmtt1HjRoUKXf7XY7Tz/9NP/+9785ePAgZWVllJaWurZ12bJlC6WlpTXOifX39+eaa65h3rx5XHHFFaxbt46NGzfy+eefu13XpqRJBCDxvMLScp79MpW3V+7BMKBNkB+PXdyLC/vGeSbB/+7u7yIinmIymeo0DOVNF110EUlJSbzxxhvEx8fjcDjo3bs3ZWVlBAQEnPS9p3rdZDJVmZNU3UZ/QUFBlX5/9tlnefHFF3nhhRfo06cPQUFB3HXXXa59lk51XXAOg/Xv358DBw7w1ltvMWLECJKSkk75vuak9a2fawWWp2Zy/vPfM3+FM/xMGJDA1zPO4aJ+8Z4JP+WlsOdH53PN/xGRVurIkSOkpqby8MMPM3LkSHr06MHRo0ddr/ft25eUlBSys7OrfX/fvn1POqm4bdu2pKWluX7fvn17rTb6++mnn7jkkku4+uqr6devHx07dmTbtm2u17t06UJAQMBJr92nTx8GDRrEG2+8wXvvvccNN9xwyus2N80jYkutZBeW8cT/NvPJrwcBaBcRwNOX9uHsrm09e6F9K6G8GIJjIKaXZ8sWEWkmIiIiaNOmDa+//jpxcXHs27ev0i2cJk+ezNNPP8348eOZM2cOcXFx/Prrr8THxzNs2DBmzZrFyJEj6dSpE5MmTaK8vJzFixdz//33A87VWH//+98ZNmwYdrud+++/v1ZL3Lt06cJHH33EihUriIiIYO7cuWRkZNCzZ0/AOcR1//33c9999+Hn58eZZ57J4cOH2bRpEzfeeKOrnIrJ0EFBQZVWp7UU6gFqAQzD4LOUg4ya+x2f/HoQkwluODOZL+862/PhByoPf7WgCXEiInVhNpv54IMPWLt2Lb179+buu+/m2Wefdb3u5+fHV199RXR0NOPGjaNPnz785S9/cd2R4Nxzz+XDDz/k888/p3///owYMYI1a9a43v/cc8+RmJjIWWedxVVXXcW9995bq9szPfzwwwwYMIAxY8Zw7rnnEhsby/jx4yud88gjj3DPPffw6KOP0qNHD6688soqNyGfPHkyPj4+TJ48uUXu0q0eoGbuUE4xD3+6kW+2Or+43WJC+MvEPpzWPqLhLrpTy99FRABGjRrF5s2bKx07cd5OUlISH330UY3vnzBhQpUVXBXi4+OrLOrJycnB4XCQl5dHhw4dqt23KDIyssr+Qb9nNpt56KGHeOihh2o8Jysri5KSkkq9Qi2JAlAz5XAYvLt6L3/9YiuFZXb8LGamj+jMn87phJ9PA3bs5WdAxrG7nXY8t+GuIyIiXmGz2Thy5AgPP/wwp59+OgMGDPB2lRqEAlAztCMzn/v/s4G1e52T7QYmRfCXCX3oEhPS8Bffdaz3J64fBDfA8JqIiHjVTz/9xHnnnUfXrl1P2nvV3CkANSPldgevLt/Jy9/soMzuIMjPwn1ju3PN6Un138+nrrT8XUSkRTv33HPrfEuQ5kgBqDHt+Qnz9mV0P7Qd8/LfwFL7oSqb3cGSjekYRwqZboIOMUGc2y2a0JJfYHnDVbmKHUudPzX/R0REmjEFoMa0fzWWn56jG0BG3d7qC1wEx/8XywXW1Hh6w/ILgcShXrq4iIiI+xSAGlN8f+yDprF37x6SkjpgqcU9zvJKbCzdnEFeSTlWHzOjekQTHeLl5Yhdx4CPn3frICIi4gYFoMbUaQSO9mexYfFiEseMw3KKDa1S9udw4/yfOVJYRruIAOZfP4To6OBGqqyIiEjLpQDURC3bksH0936l2GanV3wob10/2Ps9PyIiIi2EAlAT9P6afTz0yQYcBpzVJYpXrx5IsFX/U4mIiHiKboXRhBiGwdyl25j5sTP8TBzQjnnXDVb4ERFpgTp06MALL7zg7Wq0WvrL2kTY7A4e/HgDH649AMDtIzozY3RXz9y9XURERCpRAGoCCkvLuXXBOr7bdhizCZ4Y35spQ5O8XS0REZFq2e12TCYT5lqsZm6qmm/NW4jM/BKufH0l3207jL+vmdevGaTwIyKtm2FAWaF3HrXcAfn1118nPj4eh8NR6fgll1zCDTfcwM6dO7nkkkuIiYkhODiYwYMH8/XXX9e7SebOnUufPn0ICgoiKSmJe+65h4KCgkrn/PTTT5x77rkEBgYSERHBmDFjOHrUecskh8PBM888Q+fOnbFarbRv356nnnoKgOXLl2MymcjJyXGVlZKSgslkYs+ePQDMnz+f8PBwPv/8c3r27InVamXfvn38/PPPjB49mqioKMLCwjjnnHNYt25dpXrl5OTwxz/+kZiYGPz9/enduzf/+9//KCwsJDQ0tMrtNj799FOCgoLIz8+vd3vVhnqAvGjn4QKue2sN+7OLiQzy482pgxr2Lu4iIs2BrQiejvfOtR88BH5Bpzzt8ssv5/bbb+fbb79l5EjnzvjZ2dksWbKExYsXU1BQwLhx43jqqaewWq288847XHTRRaSmptK+ffs6V8tsNvPSSy+RnJzMjh07uPXWW7n//vt59dVXAWdgGTlyJDfccAMvvvgiPj4+fPvtt9jtdgBmzpzJG2+8wfPPP8/w4cNJS0tj69atdapDUVERf/3rX/nnP/9JmzZtiI6OZteuXUydOpWXX34ZwzB47rnnGDduHNu3byckJASHw8EFF1xAfn4+7777Lp06dWLz5s1YLBaCgoKYNGkSb731FpdddpnrOhW/h4Q07P0tFYC85Nd9Ofxxwa8cLbKR1CaQ+dcPITnq1P/RiYiI90VERHDBBRfw3nvvuQLQRx99RFRUFOeddx5ms5l+/fq5zn/iiSf45JNP+Pzzz5k+fXqdr3fXXXe5nrdv356HHnqIe+65xxWAnnnmGQYNGsQ//vEP13m9evUCID8/nxdffJG///3vTJ06FYBOnToxfPjwOtXBZrPxj3/8o9LnGjGi8n0hX3/9dcLDw/nuu++48MIL+frrr1mzZg1btmyha9euAHTs2NF1/k033cQZZ5xBWloacXFxZGZmsnjxYrd6y2pLAcgL1mebuO+tXygtd9C3XRjzrhtMVLDV29USEWkafAOdPTHeunYtTZkyhWnTpvGPf/wDq9XKggULmDRpEmazmYKCAh577DEWLVpEWloa5eXlFBcXs2/fvnpV6+uvv2bOnDls3bqVvLw8ysvLKSkpoaioiMDAQFJSUrj88surfe+WLVsoLS11BbX68vPzo2/fvpWOZWRk8PDDD7N8+XIyMzOx2+0UFRW5PmdKSgrt2rVzhZ/fGzJkCL169eLtt9/mgQce4N133yUpKYmzzz7brbrWhuYANbIFq/cxL9VMabmD87q15YObT1f4ERE5kcnkHIbyxqMOK28vuugiDMNg0aJF7N+/nx9++IEpU6YAcO+99/LJJ5/w9NNP88MPP5CSkkKfPn0oKyurc3Ps2bOHCy+8kL59+/Kf//yHn3/+mWeffRbAVV5AQECN7z/Za4BrIvOJd4C32WzVlvP7lclTp04lJSWFF198kRUrVpCSkkKbNm1qVa8KN910E/Pnzwecw1/XX399o6yAVgBqRM8v3cZj/9uKgYkrBibwxrWDCPRTJ5yISHPk7+/PhAkTWLBgAe+//z7dunVjwIABgHNC8nXXXcell15Knz59iI2NdU0orqu1a9ficDh47rnnOP300+natSvp6emVzunbty/Lli2r9v1dunQhICCgxtfbtm0LQFpamutYSkpKrer2008/cccddzBu3Dh69eqF1WolKyurUr0OHDjAtm3baizj6quvZu/evbz00kts3rzZNUzX0BSAGlGPuBDMJrignZ0nL+mJj0XNLyLSnE2ZMoVFixYxb948V+8POEPHxx9/TEpKCr/99htXXXVVlRVjtdW5c2dsNhsvv/wyu3bt4l//+hdvvfVWpXNmzpzJzz//zK233sr69evZunUrr776KllZWfj7+3P//fdz33338c4777Bz505WrVrFm2++6So/MTGRxx57jO3bt7No0SKee+65WtWtS5cu/Otf/2LLli2sXr2aKVOmVOr1Oeecczj77LOZOHEiS5cuZffu3XzxxRcsWbLEdU5ERAQTJkzgz3/+M+effz7t2rWrVzvVlf4CN6KxveNYNP0MxiYa2uBQRKQFGDFiBJGRkaSmpnLVVVe5js+dO5eIiAjOOOMMLrroIsaMGePqHaqrfv36MXfuXP7617/Su3dv3nvvPR555JFK53Tt2pWvvvqK3377jSFDhjBs2DA+++wzfHycowyPPPII99xzD48++ig9evTgyiuvJDMzEwBfX1/ef/99tm7dSt++ffnrX//Kk08+Wau6vfnmmxw9epQBAwZwzTXXcMcddxAdHV3pnP/85z8MHjyYyZMn07NnT+677z7X6rQKN954I2VlZdxwww31aqP6MBlGLTc9aEXy8vIICwsjNzeX0NBQj5Zts9lYvHgx48aNw/cUd4OXqtR+7lMbukft574T29But7N7926Sk5Px99cNn2vD4XCQl5dHaGhos96I8ET/+te/uPvuuzl06BB+fn4nPbekpKTG70xd/n5rAoqIiIh4RVFREWlpafzlL3/hj3/84ynDjye1jOgoIiLSTC1YsIDg4OBqHxV7+bRUzzzzDN27dyc2NpaZM2c26rXVAyQiIuJFF198MUOHDq32tZY+zPrYY4/x2GOPeeXaCkAiIiJeFBIS0uC3fZCqNAQmIiJep/U4Ulue+q4oAImIiNdUDPEUFRV5uSbSXFR8V9wdHtQQmIiIeI3FYiE8PNy1J01gYKD2STsFh8NBWVkZJSUlLWYZfG0YhkFRURGZmZmEh4djsVjcKk8BSEREvCo2NhbAFYLk5AzDoLi4uNp7c7UG4eHhru+MOxSARETEq0wmE3FxcURHR1d7E06pzGaz8f3333P22We3+FViv+fr6+t2z08FBSAREWkSLBaLx/64tWQWi4Xy8nL8/f1bXQDypNYzeCgiIiJyjAKQiIiItDoKQCIiItLqaA5QNSo2WcrLy/N42TabjaKiIvLy8jR2Ww9qP/epDd2j9nOf2tA9ar+aVfzdrs1miQpA1cjPzwcgMTHRyzURERGRusrPzycsLOyk55gM7T9ehcPh4NChQ4SEhHh8j4W8vDwSExPZv38/oaGhHi27NVD7uU9t6B61n/vUhu5R+9XMMAzy8/OJj48/5SaR6gGqhtlspl27dg16jdDQUH1x3aD2c5/a0D1qP/epDd2j9qveqXp+KmgStIiIiLQ6CkAiIiLS6igANTKr1cqsWbOwWq3erkqzpPZzn9rQPWo/96kN3aP28wxNghYREZFWRz1AIiIi0uooAImIiEirowAkIiIirY4CkIiIiLQ6CkCN6JVXXqFDhw74+/szdOhQ1qxZ4+0qNRuPPfYYJpOp0qN79+7erlaT9f3333PRRRcRHx+PyWTi008/rfS6YRg8+uijxMXFERAQwKhRo9i+fbt3KttEnaoNr7vuuirfybFjx3qnsk3QnDlzGDx4MCEhIURHRzN+/HhSU1MrnVNSUsJtt91GmzZtCA4OZuLEiWRkZHipxk1Lbdrv3HPPrfId/NOf/uSlGjc/CkCNZOHChcyYMYNZs2axbt06+vXrx5gxY8jMzPR21ZqNXr16kZaW5nr8+OOP3q5Sk1VYWEi/fv145ZVXqn39mWee4aWXXuK1115j9erVBAUFMWbMGEpKShq5pk3XqdoQYOzYsZW+k++//34j1rBp++6777jttttYtWoVS5cuxWazcf7551NYWOg65+677+a///0vH374Id999x2HDh1iwoQJXqx101Gb9gOYNm1ape/gM88846UaN0OGNIohQ4YYt912m+t3u91uxMfHG3PmzPFirZqPWbNmGf369fN2NZolwPjkk09cvzscDiM2NtZ49tlnXcdycnIMq9VqvP/++16oYdP3+zY0DMOYOnWqcckll3ilPs1RZmamARjfffedYRjO75yvr6/x4Ycfus7ZsmWLARgrV670VjWbrN+3n2EYxjnnnGPceeed3qtUM6ceoEZQVlbG2rVrGTVqlOuY2Wxm1KhRrFy50os1a162b99OfHw8HTt2ZMqUKezbt8/bVWqWdu/eTXp6eqXvY1hYGEOHDtX3sY6WL19OdHQ03bp145ZbbuHIkSPerlKTlZubC0BkZCQAa9euxWazVfoedu/enfbt2+t7WI3ft1+FBQsWEBUVRe/evZk5cyZFRUXeqF6zpJuhNoKsrCzsdjsxMTGVjsfExLB161Yv1ap5GTp0KPPnz6dbt26kpaUxe/ZszjrrLDZu3EhISIi3q9espKenA1T7fax4TU5t7NixTJgwgeTkZHbu3MmDDz7IBRdcwMqVK7FYLN6uXpPicDi46667OPPMM+nduzfg/B76+fkRHh5e6Vx9D6uqrv0ArrrqKpKSkoiPj2f9+vXcf//9pKam8vHHH3uxts2HApA0CxdccIHred++fRk6dChJSUn8+9//5sYbb/RizaS1mjRpkut5nz596Nu3L506dWL58uWMHDnSizVrem677TY2btyoeXv1VFP73Xzzza7nffr0IS4ujpEjR7Jz5046derU2NVsdjQE1giioqKwWCxVVjdkZGQQGxvrpVo1b+Hh4XTt2pUdO3Z4uyrNTsV3Tt9Hz+rYsSNRUVH6Tv7O9OnT+d///se3335Lu3btXMdjY2MpKysjJyen0vn6HlZWU/tVZ+jQoQD6DtaSAlAj8PPzY+DAgSxbtsx1zOFwsGzZMoYNG+bFmjVfBQUF7Ny5k7i4OG9XpdlJTk4mNja20vcxLy+P1atX6/vohgMHDnDkyBF9J48xDIPp06fzySef8M0335CcnFzp9YEDB+Lr61vpe5iamsq+ffv0PeTU7VedlJQUAH0Ha0lDYI1kxowZTJ06lUGDBjFkyBBeeOEFCgsLuf76671dtWbh3nvv5aKLLiIpKYlDhw4xa9YsLBYLkydP9nbVmqSCgoJK/y9w9+7dpKSkEBkZSfv27bnrrrt48skn6dKlC8nJyTzyyCPEx8czfvx471W6iTlZG0ZGRjJ79mwmTpxIbGwsO3fu5L777qNz586MGTPGi7VuOm677Tbee+89PvvsM0JCQlzzesLCwggICCAsLIwbb7yRGTNmEBkZSWhoKLfffjvDhg3j9NNP93Ltve9U7bdz507ee+89xo0bR5s2bVi/fj133303Z599Nn379vVy7ZsJby9Da01efvllo3379oafn58xZMgQY9WqVd6uUrNx5ZVXGnFxcYafn5+RkJBgXHnllcaOHTu8Xa0m69tvvzWAKo+pU6cahuFcCv/II48YMTExhtVqNUaOHGmkpqZ6t9JNzMnasKioyDj//PONtm3bGr6+vkZSUpIxbdo0Iz093dvVbjKqazvAeOutt1znFBcXG7feeqsRERFhBAYGGpdeeqmRlpbmvUo3Iadqv3379hlnn322ERkZaVitVqNz587Gn//8ZyM3N9e7FW9GTIZhGI0ZuERERES8TXOAREREpNVRABIREZFWRwFIREREWh0FIBEREWl1FIBERESk1VEAEhERkVZHAUhERERaHQUgERERaXUUgEREasFkMvHpp596uxoi4iEKQCLS5F133XWYTKYqj7Fjx3q7aiLSTOlmqCLSLIwdO5a33nqr0jGr1eql2ohIc6ceIBFpFqxWK7GxsZUeERERgHN46tVXX+WCCy4gICCAjh078tFHH1V6/4YNGxgxYgQBAQG0adOGm2++mYKCgkrnzJs3j169emG1WomLi2P69OmVXs/KyuLSSy8lMDCQLl268PnnnzfshxaRBqMAJCItwiOPPMLEiRP57bffmDJlCpMmTWLLli0AFBYWMmbMGCIiIvj555/58MMP+frrrysFnFdffZXbbruNm2++mQ0bNvD555/TuXPnSteYPXs2V1xxBevXr2fcuHFMmTKF7OzsRv2cIuIh3r4dvYjIqUydOtWwWCxGUFBQpcdTTz1lGIZhAMaf/vSnSu8ZOnSoccsttxiGYRivv/66ERERYRQUFLheX7RokWE2m4309HTDMAwjPj7eeOihh2qsA2A8/PDDrt8LCgoMwPjiiy889jlFpPFoDpCINAvnnXcer776aqVjkZGRrufDhg2r9NqwYcNISUkBYMuWLfTr14+goCDX62eeeSYOh4PU1FRMJhOHDh1i5MiRJ61D3759Xc+DgoIIDQ0lMzOzvh9JRLxIAUhEmoWgoKAqQ1KeEhAQUKvzfH19K/1uMplwOBwNUSURaWCaAyQiLcKqVauq/N6jRw8AevTowW+//UZhYaHr9Z9++gmz2Uy3bt0ICQmhQ4cOLFu2rFHrLCLeox4gEWkWSktLSU9Pr3TMx8eHqKgoAD788EMGDRrE8OHDWbBgAWvWrOHNN98EYMqUKcyaNYupU6fy2GOPcfjwYW6//XauueYaYmJiAHjsscf405/+RHR0NBdccAH5+fn89NNP3H777Y37QUWkUSgAiUizsGTJEuLi4iod69atG1u3bgWcK7Q++OADbr31VuLi4nj//ffp2bMnAIGBgXz55ZfceeedDB48mMDAQCZOnMjcuXNdZU2dOpWSkhKef/557r33XqKiorjssssa7wOKSKMyGYZheLsSIiLuMJlMfPLJJ4wfP97bVRGRZkJzgERERKTVUQASERGRVkdzgESk2dNIvojUlXqAREREpNVRABIREZFWRwFIREREWh0FIBEREWl1FIBERESk1VEAEhERkVZHAUhERERaHQUgERERaXX+H6CbuoxMkeeIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e19e9916-5d05-451e-a047-655b43303c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_network.save('63_test.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f066cdd-9b61-4ef3-a67a-a81d69926354",
   "metadata": {},
   "source": [
    "### For testing the model\n",
    "\n",
    "Will be deleted before pushing to main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8f3390c-5e30-40db-ae9e-a50afe44866c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 22:15:10.136114: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826749472 exceeds 10% of free system memory.\n",
      "2024-04-14 22:15:10.765473: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826749472 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.4105 - loss: 1.1988 - val_accuracy: 0.4345 - val_loss: 1.0212 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4365 - loss: 1.0301 - val_accuracy: 0.4345 - val_loss: 1.0220 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4405 - loss: 1.0253 - val_accuracy: 0.4345 - val_loss: 1.0177 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4465 - loss: 1.0230 - val_accuracy: 0.4345 - val_loss: 1.0143 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4627 - loss: 1.0093 - val_accuracy: 0.5755 - val_loss: 0.9635 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5176 - loss: 0.9485 - val_accuracy: 0.6105 - val_loss: 0.8086 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5962 - loss: 0.8474 - val_accuracy: 0.6490 - val_loss: 0.7799 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6262 - loss: 0.8082 - val_accuracy: 0.6605 - val_loss: 0.7485 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6361 - loss: 0.7869 - val_accuracy: 0.6590 - val_loss: 0.7363 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6607 - loss: 0.7546 - val_accuracy: 0.6790 - val_loss: 0.7134 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6707 - loss: 0.7312 - val_accuracy: 0.6865 - val_loss: 0.7051 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6793 - loss: 0.7190 - val_accuracy: 0.6935 - val_loss: 0.7032 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6843 - loss: 0.7051 - val_accuracy: 0.6935 - val_loss: 0.6986 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6939 - loss: 0.6926 - val_accuracy: 0.6900 - val_loss: 0.6980 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6917 - loss: 0.6908 - val_accuracy: 0.7005 - val_loss: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6969 - loss: 0.6791 - val_accuracy: 0.7000 - val_loss: 0.6930 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7054 - loss: 0.6702 - val_accuracy: 0.7020 - val_loss: 0.6925 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7062 - loss: 0.6605 - val_accuracy: 0.6990 - val_loss: 0.6935 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7084 - loss: 0.6621 - val_accuracy: 0.7020 - val_loss: 0.6905 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7177 - loss: 0.6513 - val_accuracy: 0.7010 - val_loss: 0.6920 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7164 - loss: 0.6449 - val_accuracy: 0.7035 - val_loss: 0.6914 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7203 - loss: 0.6376 - val_accuracy: 0.7040 - val_loss: 0.6921 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7269 - loss: 0.6319 - val_accuracy: 0.7055 - val_loss: 0.6918 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7244 - loss: 0.6389 - val_accuracy: 0.7065 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6429 - loss: 0.8225\n",
      "1 0.6372517347335815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 22:15:42.842376: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826749472 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.4081 - loss: 1.2132 - val_accuracy: 0.4345 - val_loss: 1.0233 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4366 - loss: 1.0329 - val_accuracy: 0.4345 - val_loss: 1.0209 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4446 - loss: 1.0235 - val_accuracy: 0.4345 - val_loss: 1.0199 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4513 - loss: 1.0223 - val_accuracy: 0.4345 - val_loss: 1.0181 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4511 - loss: 1.0190 - val_accuracy: 0.4345 - val_loss: 1.0117 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4623 - loss: 1.0099 - val_accuracy: 0.5875 - val_loss: 0.9387 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5470 - loss: 0.9258 - val_accuracy: 0.6195 - val_loss: 0.8065 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6048 - loss: 0.8457 - val_accuracy: 0.6510 - val_loss: 0.7610 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6247 - loss: 0.8108 - val_accuracy: 0.6630 - val_loss: 0.7377 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6503 - loss: 0.7688 - val_accuracy: 0.6725 - val_loss: 0.7273 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6624 - loss: 0.7448 - val_accuracy: 0.6795 - val_loss: 0.7114 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6706 - loss: 0.7260 - val_accuracy: 0.6900 - val_loss: 0.7036 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6786 - loss: 0.7157 - val_accuracy: 0.6885 - val_loss: 0.7009 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6814 - loss: 0.7028 - val_accuracy: 0.6950 - val_loss: 0.6994 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6918 - loss: 0.6961 - val_accuracy: 0.6940 - val_loss: 0.6959 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7004 - loss: 0.6778 - val_accuracy: 0.6980 - val_loss: 0.6938 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6939 - loss: 0.6795 - val_accuracy: 0.7000 - val_loss: 0.6923 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7085 - loss: 0.6615 - val_accuracy: 0.7050 - val_loss: 0.6916 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7128 - loss: 0.6610 - val_accuracy: 0.7020 - val_loss: 0.6913 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7122 - loss: 0.6558 - val_accuracy: 0.7070 - val_loss: 0.6903 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7118 - loss: 0.6549 - val_accuracy: 0.7005 - val_loss: 0.6899 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7142 - loss: 0.6459 - val_accuracy: 0.7035 - val_loss: 0.6901 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7209 - loss: 0.6394 - val_accuracy: 0.7030 - val_loss: 0.6913 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7199 - loss: 0.6424 - val_accuracy: 0.7050 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7236 - loss: 0.6347 - val_accuracy: 0.7045 - val_loss: 0.6890 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7217 - loss: 0.6353 - val_accuracy: 0.7055 - val_loss: 0.6891 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7230 - loss: 0.6361 - val_accuracy: 0.7075 - val_loss: 0.6891 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7226 - loss: 0.6350 - val_accuracy: 0.7075 - val_loss: 0.6907 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7280 - loss: 0.6283 - val_accuracy: 0.7025 - val_loss: 0.6899 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7270 - loss: 0.6275 - val_accuracy: 0.7060 - val_loss: 0.6898 - learning_rate: 1.0000e-04\n",
      "Epoch 30: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6466 - loss: 0.8120\n",
      "2 0.6407521963119507\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.4150 - loss: 1.1707 - val_accuracy: 0.4345 - val_loss: 1.0215 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4400 - loss: 1.0257 - val_accuracy: 0.4345 - val_loss: 1.0220 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4450 - loss: 1.0208 - val_accuracy: 0.4345 - val_loss: 1.0209 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4471 - loss: 1.0206 - val_accuracy: 0.4345 - val_loss: 1.0106 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4611 - loss: 1.0096 - val_accuracy: 0.5855 - val_loss: 0.9485 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5296 - loss: 0.9356 - val_accuracy: 0.6120 - val_loss: 0.8013 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5957 - loss: 0.8509 - val_accuracy: 0.6440 - val_loss: 0.7729 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6244 - loss: 0.8112 - val_accuracy: 0.6595 - val_loss: 0.7463 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6388 - loss: 0.7842 - val_accuracy: 0.6595 - val_loss: 0.7377 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6582 - loss: 0.7532 - val_accuracy: 0.6800 - val_loss: 0.7150 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6778 - loss: 0.7206 - val_accuracy: 0.6900 - val_loss: 0.7068 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6740 - loss: 0.7144 - val_accuracy: 0.6905 - val_loss: 0.7036 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6859 - loss: 0.7001 - val_accuracy: 0.6915 - val_loss: 0.7000 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6933 - loss: 0.6884 - val_accuracy: 0.6930 - val_loss: 0.7004 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6959 - loss: 0.6890 - val_accuracy: 0.6990 - val_loss: 0.6951 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7040 - loss: 0.6737 - val_accuracy: 0.6995 - val_loss: 0.6936 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7058 - loss: 0.6689 - val_accuracy: 0.6985 - val_loss: 0.6928 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7111 - loss: 0.6543 - val_accuracy: 0.6990 - val_loss: 0.6907 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7113 - loss: 0.6566 - val_accuracy: 0.7020 - val_loss: 0.6910 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7130 - loss: 0.6538 - val_accuracy: 0.7020 - val_loss: 0.6902 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7191 - loss: 0.6430 - val_accuracy: 0.7035 - val_loss: 0.6911 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7216 - loss: 0.6369 - val_accuracy: 0.7040 - val_loss: 0.6925 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7236 - loss: 0.6336 - val_accuracy: 0.7040 - val_loss: 0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7234 - loss: 0.6360 - val_accuracy: 0.7050 - val_loss: 0.6904 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7273 - loss: 0.6307 - val_accuracy: 0.7080 - val_loss: 0.6902 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7242 - loss: 0.6330 - val_accuracy: 0.7040 - val_loss: 0.6914 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7298 - loss: 0.6270 - val_accuracy: 0.7045 - val_loss: 0.6907 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7247 - loss: 0.6305 - val_accuracy: 0.7055 - val_loss: 0.6930 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7257 - loss: 0.6249 - val_accuracy: 0.7020 - val_loss: 0.6919 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7265 - loss: 0.6241 - val_accuracy: 0.7045 - val_loss: 0.6915 - learning_rate: 1.0000e-04\n",
      "Epoch 30: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6427 - loss: 0.8315\n",
      "3 0.638065755367279\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.4013 - loss: 1.2252 - val_accuracy: 0.4345 - val_loss: 1.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4340 - loss: 1.0323 - val_accuracy: 0.4345 - val_loss: 1.0202 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4418 - loss: 1.0257 - val_accuracy: 0.4345 - val_loss: 1.0200 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4460 - loss: 1.0233 - val_accuracy: 0.4345 - val_loss: 1.0148 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4534 - loss: 1.0166 - val_accuracy: 0.4520 - val_loss: 0.9966 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5048 - loss: 0.9779 - val_accuracy: 0.6055 - val_loss: 0.8226 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5886 - loss: 0.8658 - val_accuracy: 0.6320 - val_loss: 0.7819 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6217 - loss: 0.8167 - val_accuracy: 0.6595 - val_loss: 0.7499 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6389 - loss: 0.7878 - val_accuracy: 0.6685 - val_loss: 0.7307 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6524 - loss: 0.7640 - val_accuracy: 0.6815 - val_loss: 0.7143 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6633 - loss: 0.7420 - val_accuracy: 0.6880 - val_loss: 0.7091 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6760 - loss: 0.7227 - val_accuracy: 0.6940 - val_loss: 0.7062 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6833 - loss: 0.7135 - val_accuracy: 0.6900 - val_loss: 0.7014 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6878 - loss: 0.7017 - val_accuracy: 0.6890 - val_loss: 0.6997 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6965 - loss: 0.6887 - val_accuracy: 0.7000 - val_loss: 0.6967 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7001 - loss: 0.6827 - val_accuracy: 0.6990 - val_loss: 0.6949 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7061 - loss: 0.6708 - val_accuracy: 0.6990 - val_loss: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7079 - loss: 0.6651 - val_accuracy: 0.7045 - val_loss: 0.6931 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7095 - loss: 0.6566 - val_accuracy: 0.7015 - val_loss: 0.6915 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7173 - loss: 0.6484 - val_accuracy: 0.7055 - val_loss: 0.6905 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7203 - loss: 0.6496 - val_accuracy: 0.7055 - val_loss: 0.6906 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7229 - loss: 0.6434 - val_accuracy: 0.7060 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7189 - loss: 0.6461 - val_accuracy: 0.7080 - val_loss: 0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7215 - loss: 0.6392 - val_accuracy: 0.7080 - val_loss: 0.6904 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7255 - loss: 0.6352 - val_accuracy: 0.7100 - val_loss: 0.6914 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7217 - loss: 0.6354 - val_accuracy: 0.7100 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7235 - loss: 0.6325 - val_accuracy: 0.7105 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7251 - loss: 0.6312 - val_accuracy: 0.7070 - val_loss: 0.6900 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7234 - loss: 0.6343 - val_accuracy: 0.7090 - val_loss: 0.6907 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7249 - loss: 0.6286 - val_accuracy: 0.7090 - val_loss: 0.6900 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7273 - loss: 0.6255 - val_accuracy: 0.7120 - val_loss: 0.6906 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7292 - loss: 0.6245 - val_accuracy: 0.7110 - val_loss: 0.6901 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7307 - loss: 0.6208 - val_accuracy: 0.7115 - val_loss: 0.6910 - learning_rate: 1.0000e-04\n",
      "Epoch 33: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6451 - loss: 0.8165\n",
      "4 0.6382285952568054\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.4088 - loss: 1.2138 - val_accuracy: 0.4345 - val_loss: 1.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4343 - loss: 1.0326 - val_accuracy: 0.4345 - val_loss: 1.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4403 - loss: 1.0261 - val_accuracy: 0.4345 - val_loss: 1.0195 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4464 - loss: 1.0213 - val_accuracy: 0.4345 - val_loss: 1.0162 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4557 - loss: 1.0119 - val_accuracy: 0.5635 - val_loss: 0.9813 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5033 - loss: 0.9682 - val_accuracy: 0.6060 - val_loss: 0.8379 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5919 - loss: 0.8661 - val_accuracy: 0.6370 - val_loss: 0.7808 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6192 - loss: 0.8199 - val_accuracy: 0.6560 - val_loss: 0.7561 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6360 - loss: 0.7831 - val_accuracy: 0.6690 - val_loss: 0.7376 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6562 - loss: 0.7590 - val_accuracy: 0.6770 - val_loss: 0.7176 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6672 - loss: 0.7348 - val_accuracy: 0.6795 - val_loss: 0.7104 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6735 - loss: 0.7211 - val_accuracy: 0.6865 - val_loss: 0.7057 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6822 - loss: 0.7115 - val_accuracy: 0.6910 - val_loss: 0.7027 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6878 - loss: 0.6989 - val_accuracy: 0.6900 - val_loss: 0.7023 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6941 - loss: 0.6859 - val_accuracy: 0.6960 - val_loss: 0.6978 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6969 - loss: 0.6793 - val_accuracy: 0.6935 - val_loss: 0.6990 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7066 - loss: 0.6674 - val_accuracy: 0.7015 - val_loss: 0.6932 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7031 - loss: 0.6643 - val_accuracy: 0.6990 - val_loss: 0.6932 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7138 - loss: 0.6509 - val_accuracy: 0.7030 - val_loss: 0.6907 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7149 - loss: 0.6513 - val_accuracy: 0.7015 - val_loss: 0.6913 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7183 - loss: 0.6440 - val_accuracy: 0.7055 - val_loss: 0.6919 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7211 - loss: 0.6446 - val_accuracy: 0.7050 - val_loss: 0.6918 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7193 - loss: 0.6413 - val_accuracy: 0.7055 - val_loss: 0.6925 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7229 - loss: 0.6402 - val_accuracy: 0.7065 - val_loss: 0.6914 - learning_rate: 1.0000e-04\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6442 - loss: 0.8147\n",
      "5 0.6403451561927795\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.4214 - loss: 1.1636 - val_accuracy: 0.4345 - val_loss: 1.0215 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4387 - loss: 1.0287 - val_accuracy: 0.4345 - val_loss: 1.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4437 - loss: 1.0230 - val_accuracy: 0.4345 - val_loss: 1.0185 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4526 - loss: 1.0177 - val_accuracy: 0.4350 - val_loss: 1.0003 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4774 - loss: 0.9885 - val_accuracy: 0.6000 - val_loss: 0.8299 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5779 - loss: 0.8729 - val_accuracy: 0.6305 - val_loss: 0.7848 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6136 - loss: 0.8265 - val_accuracy: 0.6565 - val_loss: 0.7656 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6303 - loss: 0.7976 - val_accuracy: 0.6600 - val_loss: 0.7445 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6471 - loss: 0.7705 - val_accuracy: 0.6635 - val_loss: 0.7304 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6549 - loss: 0.7536 - val_accuracy: 0.6715 - val_loss: 0.7154 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6742 - loss: 0.7255 - val_accuracy: 0.6850 - val_loss: 0.7080 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6783 - loss: 0.7121 - val_accuracy: 0.6910 - val_loss: 0.7043 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6812 - loss: 0.7077 - val_accuracy: 0.6895 - val_loss: 0.7012 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6906 - loss: 0.6913 - val_accuracy: 0.6915 - val_loss: 0.6998 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6912 - loss: 0.6853 - val_accuracy: 0.6960 - val_loss: 0.6993 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7030 - loss: 0.6733 - val_accuracy: 0.6915 - val_loss: 0.6980 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7069 - loss: 0.6656 - val_accuracy: 0.6965 - val_loss: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7110 - loss: 0.6542 - val_accuracy: 0.6975 - val_loss: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7121 - loss: 0.6547 - val_accuracy: 0.7055 - val_loss: 0.6921 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7156 - loss: 0.6485 - val_accuracy: 0.7040 - val_loss: 0.6961 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7148 - loss: 0.6420 - val_accuracy: 0.7040 - val_loss: 0.6922 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7206 - loss: 0.6387 - val_accuracy: 0.7030 - val_loss: 0.6933 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7233 - loss: 0.6371 - val_accuracy: 0.7020 - val_loss: 0.6921 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7175 - loss: 0.6378 - val_accuracy: 0.7040 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6420 - loss: 0.8228\n",
      "6 0.6369260549545288\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.4102 - loss: 1.1734 - val_accuracy: 0.4345 - val_loss: 1.0218 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4369 - loss: 1.0318 - val_accuracy: 0.4345 - val_loss: 1.0196 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4444 - loss: 1.0231 - val_accuracy: 0.4345 - val_loss: 1.0190 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4452 - loss: 1.0205 - val_accuracy: 0.4345 - val_loss: 1.0165 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4497 - loss: 1.0187 - val_accuracy: 0.4415 - val_loss: 0.9965 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4897 - loss: 0.9853 - val_accuracy: 0.6010 - val_loss: 0.8352 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5865 - loss: 0.8694 - val_accuracy: 0.6440 - val_loss: 0.7877 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6237 - loss: 0.8161 - val_accuracy: 0.6545 - val_loss: 0.7518 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6362 - loss: 0.7924 - val_accuracy: 0.6675 - val_loss: 0.7342 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6509 - loss: 0.7603 - val_accuracy: 0.6625 - val_loss: 0.7230 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6641 - loss: 0.7394 - val_accuracy: 0.6805 - val_loss: 0.7088 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6751 - loss: 0.7158 - val_accuracy: 0.6845 - val_loss: 0.7037 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6827 - loss: 0.7117 - val_accuracy: 0.6890 - val_loss: 0.7003 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6872 - loss: 0.7006 - val_accuracy: 0.6955 - val_loss: 0.6963 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6936 - loss: 0.6879 - val_accuracy: 0.6980 - val_loss: 0.6946 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6949 - loss: 0.6819 - val_accuracy: 0.7000 - val_loss: 0.6924 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7037 - loss: 0.6729 - val_accuracy: 0.7035 - val_loss: 0.6922 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7095 - loss: 0.6591 - val_accuracy: 0.7010 - val_loss: 0.6896 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7095 - loss: 0.6584 - val_accuracy: 0.6985 - val_loss: 0.6907 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7161 - loss: 0.6505 - val_accuracy: 0.6965 - val_loss: 0.6922 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 0.6381 - val_accuracy: 0.7000 - val_loss: 0.6911 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7213 - loss: 0.6389 - val_accuracy: 0.6985 - val_loss: 0.6925 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7187 - loss: 0.6413 - val_accuracy: 0.6990 - val_loss: 0.6918 - learning_rate: 1.0000e-04\n",
      "Epoch 23: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6450 - loss: 0.8181\n",
      "7 0.6386356353759766\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.4093 - loss: 1.1739 - val_accuracy: 0.4345 - val_loss: 1.0199 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4401 - loss: 1.0315 - val_accuracy: 0.4345 - val_loss: 1.0193 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4419 - loss: 1.0229 - val_accuracy: 0.4345 - val_loss: 1.0173 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4474 - loss: 1.0182 - val_accuracy: 0.4350 - val_loss: 1.0008 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4805 - loss: 0.9926 - val_accuracy: 0.6005 - val_loss: 0.8306 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5811 - loss: 0.8700 - val_accuracy: 0.6345 - val_loss: 0.7939 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6086 - loss: 0.8290 - val_accuracy: 0.6545 - val_loss: 0.7579 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6331 - loss: 0.7979 - val_accuracy: 0.6680 - val_loss: 0.7414 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6432 - loss: 0.7798 - val_accuracy: 0.6645 - val_loss: 0.7268 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6626 - loss: 0.7446 - val_accuracy: 0.6760 - val_loss: 0.7143 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6755 - loss: 0.7217 - val_accuracy: 0.6880 - val_loss: 0.7057 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6802 - loss: 0.7154 - val_accuracy: 0.6925 - val_loss: 0.7019 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6860 - loss: 0.7021 - val_accuracy: 0.6895 - val_loss: 0.7007 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6928 - loss: 0.6937 - val_accuracy: 0.6930 - val_loss: 0.6972 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6974 - loss: 0.6861 - val_accuracy: 0.6970 - val_loss: 0.6960 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7026 - loss: 0.6753 - val_accuracy: 0.6990 - val_loss: 0.6949 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7044 - loss: 0.6711 - val_accuracy: 0.6965 - val_loss: 0.6929 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7057 - loss: 0.6628 - val_accuracy: 0.6940 - val_loss: 0.6979 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7107 - loss: 0.6535 - val_accuracy: 0.7060 - val_loss: 0.6935 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7154 - loss: 0.6496 - val_accuracy: 0.7045 - val_loss: 0.6924 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7186 - loss: 0.6411 - val_accuracy: 0.7040 - val_loss: 0.6921 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7198 - loss: 0.6383 - val_accuracy: 0.7030 - val_loss: 0.6923 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7218 - loss: 0.6391 - val_accuracy: 0.7055 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7243 - loss: 0.6304 - val_accuracy: 0.7010 - val_loss: 0.6916 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7257 - loss: 0.6316 - val_accuracy: 0.7040 - val_loss: 0.6930 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7281 - loss: 0.6251 - val_accuracy: 0.7040 - val_loss: 0.6927 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7245 - loss: 0.6312 - val_accuracy: 0.7030 - val_loss: 0.6929 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7280 - loss: 0.6270 - val_accuracy: 0.7040 - val_loss: 0.6941 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7257 - loss: 0.6273 - val_accuracy: 0.7040 - val_loss: 0.6933 - learning_rate: 1.0000e-04\n",
      "Epoch 29: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6464 - loss: 0.8210\n",
      "8 0.6396939158439636\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.4092 - loss: 1.2303 - val_accuracy: 0.4345 - val_loss: 1.0203 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4370 - loss: 1.0334 - val_accuracy: 0.4345 - val_loss: 1.0228 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4356 - loss: 1.0279 - val_accuracy: 0.4345 - val_loss: 1.0205 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4456 - loss: 1.0241 - val_accuracy: 0.4345 - val_loss: 1.0170 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4488 - loss: 1.0216 - val_accuracy: 0.4345 - val_loss: 1.0084 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4606 - loss: 1.0069 - val_accuracy: 0.5965 - val_loss: 0.9125 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5589 - loss: 0.9068 - val_accuracy: 0.6125 - val_loss: 0.8103 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6076 - loss: 0.8395 - val_accuracy: 0.6405 - val_loss: 0.7788 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6266 - loss: 0.8058 - val_accuracy: 0.6615 - val_loss: 0.7433 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6434 - loss: 0.7796 - val_accuracy: 0.6735 - val_loss: 0.7262 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6580 - loss: 0.7555 - val_accuracy: 0.6805 - val_loss: 0.7143 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6663 - loss: 0.7386 - val_accuracy: 0.6805 - val_loss: 0.7118 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6728 - loss: 0.7232 - val_accuracy: 0.6785 - val_loss: 0.7082 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6842 - loss: 0.7076 - val_accuracy: 0.6845 - val_loss: 0.7032 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6894 - loss: 0.6985 - val_accuracy: 0.6835 - val_loss: 0.7003 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6933 - loss: 0.6908 - val_accuracy: 0.6970 - val_loss: 0.6949 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6970 - loss: 0.6814 - val_accuracy: 0.6980 - val_loss: 0.6928 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6973 - loss: 0.6800 - val_accuracy: 0.6940 - val_loss: 0.6923 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7061 - loss: 0.6628 - val_accuracy: 0.7040 - val_loss: 0.6892 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7134 - loss: 0.6588 - val_accuracy: 0.7030 - val_loss: 0.6899 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7141 - loss: 0.6480 - val_accuracy: 0.7020 - val_loss: 0.6882 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7214 - loss: 0.6418 - val_accuracy: 0.7030 - val_loss: 0.6896 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7172 - loss: 0.6493 - val_accuracy: 0.7030 - val_loss: 0.6887 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7248 - loss: 0.6383 - val_accuracy: 0.7045 - val_loss: 0.6880 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7223 - loss: 0.6382 - val_accuracy: 0.7045 - val_loss: 0.6879 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7221 - loss: 0.6432 - val_accuracy: 0.7015 - val_loss: 0.6896 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7200 - loss: 0.6356 - val_accuracy: 0.7020 - val_loss: 0.6888 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7249 - loss: 0.6375 - val_accuracy: 0.7045 - val_loss: 0.6887 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7220 - loss: 0.6383 - val_accuracy: 0.7050 - val_loss: 0.6876 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7293 - loss: 0.6261 - val_accuracy: 0.7070 - val_loss: 0.6876 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7259 - loss: 0.6320 - val_accuracy: 0.7065 - val_loss: 0.6886 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7283 - loss: 0.6266 - val_accuracy: 0.7100 - val_loss: 0.6888 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7311 - loss: 0.6262 - val_accuracy: 0.7080 - val_loss: 0.6891 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7283 - loss: 0.6237 - val_accuracy: 0.7090 - val_loss: 0.6886 - learning_rate: 1.0000e-04\n",
      "Epoch 34: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6429 - loss: 0.8205\n",
      "9 0.638065755367279\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.4064 - loss: 1.2270 - val_accuracy: 0.4345 - val_loss: 1.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4377 - loss: 1.0343 - val_accuracy: 0.4345 - val_loss: 1.0218 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4421 - loss: 1.0265 - val_accuracy: 0.4345 - val_loss: 1.0201 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4453 - loss: 1.0196 - val_accuracy: 0.4345 - val_loss: 1.0174 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4497 - loss: 1.0169 - val_accuracy: 0.4375 - val_loss: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4822 - loss: 0.9888 - val_accuracy: 0.6060 - val_loss: 0.8356 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5823 - loss: 0.8800 - val_accuracy: 0.6250 - val_loss: 0.7798 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6158 - loss: 0.8273 - val_accuracy: 0.6435 - val_loss: 0.7626 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6311 - loss: 0.7945 - val_accuracy: 0.6660 - val_loss: 0.7315 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6503 - loss: 0.7664 - val_accuracy: 0.6770 - val_loss: 0.7177 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6696 - loss: 0.7384 - val_accuracy: 0.6880 - val_loss: 0.7090 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6716 - loss: 0.7208 - val_accuracy: 0.6790 - val_loss: 0.7071 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6784 - loss: 0.7132 - val_accuracy: 0.6910 - val_loss: 0.7021 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6908 - loss: 0.6975 - val_accuracy: 0.6935 - val_loss: 0.7014 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6924 - loss: 0.6897 - val_accuracy: 0.6970 - val_loss: 0.6970 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7030 - loss: 0.6776 - val_accuracy: 0.6975 - val_loss: 0.6952 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6993 - loss: 0.6774 - val_accuracy: 0.7000 - val_loss: 0.6941 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7071 - loss: 0.6680 - val_accuracy: 0.6950 - val_loss: 0.6975 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7097 - loss: 0.6613 - val_accuracy: 0.7015 - val_loss: 0.6908 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7129 - loss: 0.6612 - val_accuracy: 0.7050 - val_loss: 0.6923 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7205 - loss: 0.6454 - val_accuracy: 0.7020 - val_loss: 0.6910 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7153 - loss: 0.6473 - val_accuracy: 0.7020 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7217 - loss: 0.6409 - val_accuracy: 0.7035 - val_loss: 0.6929 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7180 - loss: 0.6402 - val_accuracy: 0.7010 - val_loss: 0.6913 - learning_rate: 1.0000e-04\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6451 - loss: 0.8156\n",
      "10 0.6394497156143188\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    input_layer = tf.keras.layers.Input(shape=(train_vectorized.shape[1],))\n",
    "    neural_network = tf.keras.models.Sequential(\n",
    "        [\n",
    "            input_layer,\n",
    "            tf.keras.layers.Dense(2048, activation=activation_function),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(512, activation=activation_function),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(128, activation=activation_function),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(3, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    neural_network.compile(\n",
    "        optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, mode=\"min\", verbose=1\n",
    "    )\n",
    "    with tf.device(device_name):\n",
    "        history = neural_network.fit(\n",
    "            train_vectorized,\n",
    "            train_label_one_hot,\n",
    "            validation_data=(validation_vectorized, validation_label_one_hot),\n",
    "            epochs=200,\n",
    "            batch_size=512,\n",
    "            callbacks=[early_stopping, rate_scheduler],\n",
    "        )\n",
    "    test_loss, test_accuracy = neural_network.evaluate(test_vectorized, test_label_one_hot)\n",
    "    print(i+1, test_accuracy)\n",
    "    accuracy_list.append(test_accuracy)\n",
    "    #if test_accuracy >= 0.641:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3ae4d3-cdf0-40bc-bd6b-93a94ee41299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6372517347335815, 0.6407521963119507, 0.638065755367279, 0.6382285952568054, 0.6403451561927795, 0.6369260549545288, 0.6386356353759766, 0.6396939158439636, 0.638065755367279, 0.6394497156143188]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edb26f8d-0581-464d-a80d-70db54f3e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_network.save('64_test.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
