{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d182dc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb147de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# For Docker image tensorflow/tensorflow:2.14.0-gpu-juptyer\n",
    "!pip install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a959c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 14:05:43.100928: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61904ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available, using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 14:05:44.494105: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 14:05:44.507289: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 14:05:44.507348: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# The device_name will be used in model.fit()\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpu_devices:\n",
    "    print(\"GPU available, using GPU\")\n",
    "    tf.config.experimental.set_visible_devices(gpu_devices[0], \"GPU\")\n",
    "    device_name = \"/GPU:0\"\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    device_name = \"/CPU:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3f7e8",
   "metadata": {},
   "source": [
    "### Function for loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c7661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file(file_path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Load a text file and return an array of lines from the file.\n",
    "\n",
    "    Args:\n",
    "        file_path: str: The path to the file to load.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: An array of lines from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "\n",
    "def load_slang_sd(path: str) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Load a slang sentiment dictionary from a file.\n",
    "\n",
    "    Args:\n",
    "        path: str: The path to the file to load.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, int]: A dictionary of slang words and their sentiment values.\n",
    "    \"\"\"\n",
    "    slang_sd = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            word, sentiment = line.strip().split(\"\\t\")\n",
    "            slang_sd[word] = int(sentiment)\n",
    "    return slang_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4751e373",
   "metadata": {},
   "source": [
    "### Load the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819ff3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_path: str = \"../dataset/train_text.txt\"\n",
    "train_label_path: str = \"../dataset/train_labels.txt\"\n",
    "\n",
    "test_text_path: str = \"../dataset/test_text.txt\"\n",
    "test_label_path: str = \"../dataset/test_labels.txt\"\n",
    "\n",
    "validationt_text_path: str = \"../dataset/val_text.txt\"\n",
    "validationt_label_path: str = \"../dataset/val_labels.txt\"\n",
    "\n",
    "train_text: list[str] = load_text_file(train_text_path)\n",
    "train_label: list[str] = load_text_file(train_label_path)\n",
    "\n",
    "test_text: list[str] = load_text_file(test_text_path)\n",
    "test_label: list[str] = load_text_file(test_label_path)\n",
    "\n",
    "validation_text: list[str] = load_text_file(validationt_text_path)\n",
    "validation_label: list[str] = load_text_file(validationt_label_path)\n",
    "\n",
    "# SlangSD from http://liangwu.me/slangsd/\n",
    "slang_sd_path: str = \"../SlangSD/SlangSD.txt\"\n",
    "slang_sd: dict[str, int] = load_slang_sd(slang_sd_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd336c",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da2e83",
   "metadata": {},
   "source": [
    "#### Download the NLTK resources and declere global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc75d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stopwords\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "nltk.download(\"omw-1.4\", quiet=True)\n",
    "nltk.download(\"vader_lexicon\", quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Declare a dict of emojis and their corresponding sentiment\n",
    "# 0: Negative; 1: Neutral; 2: Positive\n",
    "emoji_dict = {\n",
    "    \"😊\": 2,\n",
    "    \"😂\": 2,\n",
    "    \"😭\": 0,\n",
    "    \"😍\": 2,\n",
    "    \"😘\": 2,\n",
    "    \"😁\": 2,\n",
    "    \"😩\": 0,\n",
    "    \"😏\": 2,\n",
    "    \"😉\": 2,\n",
    "    \"😎\": 2,\n",
    "    \"😢\": 0,\n",
    "    \"😅\": 2,\n",
    "    \"😱\": 0,\n",
    "    \"😆\": 2,\n",
    "    \"😋\": 2,\n",
    "    \"😷\": 0,\n",
    "    \"😔\": 0,\n",
    "    \"😒\": 0,\n",
    "    \"😡\": 0,\n",
    "    \"😪\": 0,\n",
    "    \"😤\": 0,\n",
    "    \"😝\": 2,\n",
    "    \"😓\": 0,\n",
    "    \"😖\": 0,\n",
    "    \"😣\": 0,\n",
    "    \"😞\": 0,\n",
    "    \"😐\": 1,\n",
    "    \"😕\": 0,\n",
    "    \"😫\": 0,\n",
    "    \"😨\": 0,\n",
    "    \"😌\": 2,\n",
    "    \"😜\": 2,\n",
    "    \"😑\": 1,\n",
    "    \"😬\": 0,\n",
    "    \"😈\": 0,\n",
    "    \"😯\": 0,\n",
    "    \"😳\": 0,\n",
    "    \"😇\": 2,\n",
    "    \"😷\": 0,\n",
    "    \"😴\": 0,\n",
    "    \"😲\": 0,\n",
    "    \"😵\": 0,\n",
    "    \"😦\": 0,\n",
    "    \"😢\": 0,\n",
    "    \"😮\": 0,\n",
    "    \"😟\": 0,\n",
    "    \"😥\": 0,\n",
    "    \"😧\": 0,\n",
    "    \"😰\": 0,\n",
    "    \"😓\": 0,\n",
    "    \"😩\": 0,\n",
    "    \"😿\": 0,\n",
    "    \"😾\": 0,\n",
    "    \"🙀\": 0,\n",
    "    \"🙅\": 0,\n",
    "    \"🙆\": 0,\n",
    "    \"🙇\": 0,\n",
    "    \"🙈\": 0,\n",
    "    \"🙉\": 0,\n",
    "    \"🙊\": 0,\n",
    "    \"🙋\": 0,\n",
    "    \"🙌\": 0,\n",
    "    \"🙍\": 0,\n",
    "    \"🙎\": 0,\n",
    "    \"🙏\": 0,\n",
    "    \":)\": 2,\n",
    "    \":(\": 0,\n",
    "    \"❤️\": 2,\n",
    "    \"👍\": 2,\n",
    "    \"✌🏼️\": 2,\n",
    "    \"☹️\": 0,\n",
    "    \"🙃\": 0,\n",
    "    \"👎\": 0,\n",
    "    \"💙\": 2,\n",
    "    \"💗\": 2,\n",
    "    \"🎉\": 2,\n",
    "    \"😄\": 2,\n",
    "    \"🤗\": 2,\n",
    "    \":D\": 2,\n",
    "    \"🎄\": 2,\n",
    "    \"🎁\": 2,\n",
    "    \":/\": 0,\n",
    "    \"?!\": 0,\n",
    "    \":P\": 2,\n",
    "    \":p\": 2,\n",
    "}\n",
    "\n",
    "# For saving the slang scores before processing\n",
    "slang_sd_score_train: list[int] = []\n",
    "slang_sd_score_test: list[int] = []\n",
    "slang_sd_score_validation: list[int] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4ecc5",
   "metadata": {},
   "source": [
    "### Functions for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14f5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text: list[str], data: str) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Process text data:\n",
    "    - Remove '@user'\n",
    "    - Remove hashtags\n",
    "    - Remove '-'\n",
    "    - Remove URLs\n",
    "    - Replace emojis with their corresponding sentiment.\n",
    "    - Replace punctuation marks.\n",
    "    - Tokenize the text.\n",
    "    - Normalize the text with nltk.\n",
    "    - Lowercase the text.\n",
    "    - Get the slang_sd score\n",
    "    # Length of the line is added after vectorization.\n",
    "\n",
    "    Args:\n",
    "        text: list[str]: A list of text data.\n",
    "        data: str: The type of data (train, test, validation).\n",
    "\n",
    "    Returns:\n",
    "        list[list[str]]: A list of list of processed text data.\n",
    "    \"\"\"\n",
    "    processed_text = []\n",
    "    for line in text:\n",
    "        # Remove '@user'\n",
    "        line = line.replace(\"@user\", \" \")\n",
    "        # Remove hashtags\n",
    "        line = line.replace(\"#\", \" \")\n",
    "        # Remove '-'\n",
    "        line = line.replace(\"-\", \" \")\n",
    "        # Remove URLs (http, https, www)\n",
    "        line = \" \".join([word for word in line.split() if \"http\" not in word])\n",
    "        line = \" \".join([word for word in line.split() if \"www\" not in word])\n",
    "        # Replace emojis with their corresponding sentiment\n",
    "        line = replace_emojis(line)\n",
    "        # Replace punctuation marks\n",
    "        line = punctuation_replacement(line)\n",
    "        # Tokenize the text.\n",
    "        tokens = nltk.word_tokenize(line)\n",
    "        # Normalize the text using WordNetLemmatizer and tokenize the text\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        # Lowercase the text\n",
    "        tokens = [str(word).lower() for word in tokens]\n",
    "        # Get the slang_sd score\n",
    "        if data == \"train\":\n",
    "            slang_sd_score_train.append(get_slang_sd_score(line))\n",
    "        elif data == \"test\":\n",
    "            slang_sd_score_test.append(get_slang_sd_score(line))\n",
    "        elif data == \"validation\":\n",
    "            slang_sd_score_validation.append(get_slang_sd_score(line))\n",
    "        processed_text.append(tokens)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def get_slang_sd_score(line: str) -> int:\n",
    "    \"\"\"\n",
    "    Get the sentiment score of the input text data from the slang sentiment dictionary.\n",
    "    The score is calculated by summing the sentiment values of all slang words in the line.\n",
    "    If no slang words are found, the score is 0.\n",
    "\n",
    "    Args:\n",
    "        line: str: The input line.\n",
    "\n",
    "    Returns:\n",
    "        int: The sentiment score of the input text data.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    for word in line.split():\n",
    "        if word in slang_sd:\n",
    "            score += slang_sd[word]\n",
    "    return score\n",
    "\n",
    "\n",
    "def vectorize_text(\n",
    "    input: list[list[str]], vocabulary: list[str]\n",
    ") -> ndarray[ndarray[float]]:\n",
    "    \"\"\"\n",
    "    Vectorize the text data.\n",
    "\n",
    "    Args:\n",
    "        input: list[list[str]]: A list of list of text data (Full *_text).\n",
    "        vocabulary: list[str]: The list of most common words.\n",
    "\n",
    "    Returns:\n",
    "        ndarray[ndarray[float]]: A numpy array of vectorized text data.\n",
    "    \"\"\"\n",
    "    vectorized_text = np.zeros((len(input), len(vocabulary)))\n",
    "    for i, line in enumerate(input):\n",
    "        for word in line:\n",
    "            if word in vocabulary:\n",
    "                vectorized_text[i, vocabulary.index(word)] += 1\n",
    "    return vectorized_text\n",
    "\n",
    "\n",
    "def map_emoji_sentiment(input: int) -> str:\n",
    "    \"\"\"\n",
    "    Map the emoji sentiment to a string.\n",
    "\n",
    "    Args:\n",
    "        input: int: The emoji sentiment.\n",
    "\n",
    "    Returns:\n",
    "        str: The string sentiment.\n",
    "    \"\"\"\n",
    "    if input == 0:\n",
    "        return \" bad \"\n",
    "    elif input == 1:\n",
    "        return \" neutral \"\n",
    "    elif input == 2:\n",
    "        return \" good \"\n",
    "    else:\n",
    "        return \" neutral \"\n",
    "\n",
    "\n",
    "def replace_emojis(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace emojis with their corresponding sentiment.\n",
    "    If the emoji is 0, replace it with 'bad'.\n",
    "    If the emoji is 1, replace it with 'neutral'.\n",
    "    If the emoji is 2, replace it with 'good'.\n",
    "    If the emoji is not in the emoji_dict, replace it with 'neutral'.\n",
    "\n",
    "    Args:\n",
    "        input: str: The input text data (line).\n",
    "\n",
    "    Returns:\n",
    "        str: The text data with emojis replaced with their corresponding sentiment.\n",
    "    \"\"\"\n",
    "    for emoji in emoji_dict:\n",
    "        if emoji in input:\n",
    "            input = input.replace(emoji, map_emoji_sentiment(emoji_dict[emoji]))\n",
    "    return input\n",
    "\n",
    "\n",
    "def get_sentiment_score(line: list[str]) -> list[float]:\n",
    "    \"\"\"\n",
    "    Get the sentiment score of the input text data from SentimentIntensityAnalyzer.\n",
    "\n",
    "    Args:\n",
    "        line: list[str]: The input line.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: The compound score of 10 words in the sentence which has\n",
    "        the most significant score (far from 0). If the sentence has less than\n",
    "        10 words, the value of the remaining elements will be 0.\n",
    "        After that, the score for the whole line is added to the list.\n",
    "    \"\"\"\n",
    "    scores: list[float] = []\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    for string in line:\n",
    "        score = analyzer.polarity_scores(string)[\"compound\"]\n",
    "        scores.append(score)\n",
    "    line_score = analyzer.polarity_scores(\" \".join(line))[\"compound\"]\n",
    "\n",
    "    # Get the 10 most significant scores and add the line score\n",
    "    if len(scores) > 10:\n",
    "        scores.sort(key=lambda x: abs(x), reverse=True)\n",
    "        result = scores[:10]\n",
    "        result.append(line_score)\n",
    "    else:\n",
    "        result = scores\n",
    "        result += [0] * (10 - len(scores))\n",
    "        result.append(line_score)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def learning_rate_scheduler(epoch: int) -> float:\n",
    "    \"\"\"\n",
    "    Learning rate scheduler, to decrease the learning rate when epoch increases.\n",
    "\n",
    "    Args:\n",
    "        epoch: int: The current epoch.\n",
    "\n",
    "    Returns:\n",
    "        float: The new learning rate.\n",
    "    \"\"\"\n",
    "    if epoch < 10:\n",
    "        return 0.0005\n",
    "    elif epoch < 20:\n",
    "        return 0.0003\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "\n",
    "def punctuation_replacement(line: Union[str, list[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Check if there are repeated (>= 2) punctuation marks ['.' '!', '?'] in the line.\n",
    "    If there are, no matter how many times the punctuation mark is repeated,\n",
    "    replace it with ['MultiDot', 'MultiExclamation', 'MultiQuestion']\n",
    "    respectively.\n",
    "\n",
    "    Replace ['.' '!', '?'] with ['Dot', 'Exclamation', 'Question'] respectively.\n",
    "    If they are not repeated in the line, keep them as they are.\n",
    "\n",
    "    Args:\n",
    "        line: Union[str, list[str]]: The input line, which can be a string or a list of words.\n",
    "\n",
    "    Returns:\n",
    "        str: The line with punctuation marks replaced.\n",
    "    \"\"\"\n",
    "    # Split the line into words if it is a string\n",
    "    if type(line) is str:\n",
    "        line = line.split()\n",
    "    # Replace punctuation marks\n",
    "    for_append = []\n",
    "    for i, word in enumerate(line):\n",
    "        if word.count(\".\") >= 2:\n",
    "            line[i] = line[i].replace(\".\", \"\")\n",
    "            for_append.append(\"MultiDot\")\n",
    "        elif word.count(\"!\") >= 2:\n",
    "            line[i] = line[i].replace(\"!\", \"\")\n",
    "            for_append.append(\"MultiExclamation\")\n",
    "        elif word.count(\"?\") >= 2:\n",
    "            line[i] = line[i].replace(\"?\", \"\")\n",
    "            for_append.append(\"MultiQuestion\")\n",
    "        elif word.count(\".\") == 1:\n",
    "            line[i] = line[i].replace(\".\", \"\")\n",
    "            for_append.append(\"Dot\")\n",
    "        elif word.count(\"!\") == 1:\n",
    "            line[i] = line[i].replace(\"!\", \"\")\n",
    "            for_append.append(\"Exclamation\")\n",
    "        elif word.count(\"?\") == 1:\n",
    "            line[i] = line[i].replace(\"?\", \"\")\n",
    "            for_append.append(\"Question\")\n",
    "\n",
    "    line += for_append\n",
    "\n",
    "    # Join back the line\n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e97dc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train text: 211440 words in slang_sd\n",
      "Test text: 37782 words in slang_sd\n",
      "Validation text: 9492 words in slang_sd\n"
     ]
    }
   ],
   "source": [
    "# Check how many words from train_text, test_text, and validation_text are in the slang_sd\n",
    "train_slang_count = 0\n",
    "test_slang_count = 0\n",
    "validation_slang_count = 0\n",
    "\n",
    "for line in train_text:\n",
    "    for word in line.split():\n",
    "        if word in slang_sd:\n",
    "            train_slang_count += 1\n",
    "\n",
    "for line in test_text:\n",
    "    for word in line.split():\n",
    "        if word in slang_sd:\n",
    "            test_slang_count += 1\n",
    "\n",
    "for line in validation_text:\n",
    "    for word in line.split():\n",
    "        if word in slang_sd:\n",
    "            validation_slang_count += 1\n",
    "\n",
    "print(f\"Train text: {train_slang_count} words in slang_sd\")\n",
    "print(f\"Test text: {test_slang_count} words in slang_sd\")\n",
    "print(f\"Validation text: {validation_slang_count} words in slang_sd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed5bf3",
   "metadata": {},
   "source": [
    "### Process the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba10fa",
   "metadata": {},
   "source": [
    "#### Process all text data\n",
    "\n",
    "See function docstring from text_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1634a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text: list[list[str]] = text_processing(train_text, \"train\")\n",
    "test_text: list[list[str]] = text_processing(test_text, \"test\")\n",
    "validation_text: list[list[str]] = text_processing(validation_text, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "345724bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train text: 297815 words in slang_sd\n",
      "Test text: 58515 words in slang_sd\n",
      "Validation text: 13349 words in slang_sd\n"
     ]
    }
   ],
   "source": [
    "# Check how many words from train_text, test_text, and validation_text are in the slang_sd after processing\n",
    "train_slang_count = 0\n",
    "test_slang_count = 0\n",
    "validation_slang_count = 0\n",
    "\n",
    "for line in train_text:\n",
    "    for word in line:\n",
    "        if word in slang_sd:\n",
    "            train_slang_count += 1\n",
    "\n",
    "for line in test_text:\n",
    "    for word in line:\n",
    "        if word in slang_sd:\n",
    "            test_slang_count += 1\n",
    "\n",
    "for line in validation_text:\n",
    "    for word in line:\n",
    "        if word in slang_sd:\n",
    "            validation_slang_count += 1\n",
    "\n",
    "print(f\"Train text: {train_slang_count} words in slang_sd\")\n",
    "print(f\"Test text: {test_slang_count} words in slang_sd\")\n",
    "print(f\"Validation text: {validation_slang_count} words in slang_sd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5734a099",
   "metadata": {},
   "source": [
    "#### Get the length of each input line\n",
    "\n",
    "Will be added as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0677b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_len: list[int] = [len(line) for line in train_text]\n",
    "test_text_len: list[int] = [len(line) for line in test_text]\n",
    "validation_text_len: list[int] = [len(line) for line in validation_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d2450",
   "metadata": {},
   "source": [
    "#### Remove empty lines after processing\n",
    "\n",
    "As there may exist lines with 0 words after removing words like stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb6fd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index of lists in train_text and validation_text that are empty\n",
    "empty_index_train: list[int] = [i for i, x in enumerate(train_text) if not x]\n",
    "\n",
    "# Remove empty lists from train_text and validation_text, and corresponding labels\n",
    "train_text: list[list[str]] = [\n",
    "    train_text[i] for i in range(len(train_text)) if i not in empty_index_train\n",
    "]\n",
    "train_label: list[list[str]] = [\n",
    "    train_label[i] for i in range(len(train_label)) if i not in empty_index_train\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde05ecd",
   "metadata": {},
   "source": [
    "#### Find the most common words in the training data\n",
    "\n",
    "Will be used for vectorizing the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "680dad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency: dict[str, int] = {}\n",
    "for line in train_text:\n",
    "    for word in line:\n",
    "        if word in word_frequency:\n",
    "            word_frequency[word] += 1\n",
    "        else:\n",
    "            word_frequency[word] = 1\n",
    "\n",
    "vocabulary: list[str] = [\n",
    "    word\n",
    "    for word, _ in sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)[\n",
    "        :10000\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d1eb8",
   "metadata": {},
   "source": [
    "#### Get the sentiment score of the text data\n",
    "\n",
    "Will be used as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf84bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment_score: ndarray[ndarray[float]] = np.array(\n",
    "    [get_sentiment_score(line) for line in train_text]\n",
    ")\n",
    "test_sentiment_score: ndarray[ndarray[float]] = np.array(\n",
    "    [get_sentiment_score(line) for line in test_text]\n",
    ")\n",
    "validation_sentiment_score: ndarray[ndarray[float]] = np.array(\n",
    "    [get_sentiment_score(line) for line in validation_text]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41216d7",
   "metadata": {},
   "source": [
    "##### Convert the labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e846af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label: list[int] = [int(label) for label in train_label]\n",
    "test_label: list[int] = [int(label) for label in test_label]\n",
    "validation_label: list[int] = [int(label) for label in validation_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e8593",
   "metadata": {},
   "source": [
    "### Vectorize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26c2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "train_vectorized: ndarray[ndarray[float]] = vectorize_text(train_text, vocabulary)\n",
    "test_vectorized: ndarray[ndarray[float]] = vectorize_text(test_text, vocabulary)\n",
    "validation_vectorized: ndarray[ndarray[float]] = vectorize_text(\n",
    "    validation_text, vocabulary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b0aaf",
   "metadata": {},
   "source": [
    "#### Remove entries with all 0 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28e7c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data size: 45615\n",
      "Processed training data size: 45614\n"
     ]
    }
   ],
   "source": [
    "# Find the entries with all zeros in the vectorized data\n",
    "zero_index_train: ndarray[int] = np.where(~train_vectorized.any(axis=1))[0]\n",
    "\n",
    "print(\"Original training data size:\", len(train_vectorized))\n",
    "\n",
    "# Remove entries with all zeros in the vectorized data, and corresponding labels\n",
    "train_vectorized: ndarray[ndarray[float]] = np.delete(\n",
    "    train_vectorized, zero_index_train, axis=0\n",
    ")\n",
    "train_label: list[int] = [\n",
    "    train_label[i] for i in range(len(train_label)) if i not in zero_index_train\n",
    "]\n",
    "\n",
    "# Remove entries with all zeros in the sentiment score data\n",
    "train_sentiment_score: ndarray[ndarray[float]] = np.delete(\n",
    "    train_sentiment_score, zero_index_train, axis=0\n",
    ")\n",
    "\n",
    "# Convert the list of text lengths to numpy array\n",
    "train_text_len: ndarray[int] = np.array(train_text_len)\n",
    "\n",
    "# Remove entries with all zeros in the text length data\n",
    "train_text_len: ndarray[int] = np.delete(train_text_len, zero_index_train)\n",
    "\n",
    "# Convert the list of slang_sd scores to numpy array\n",
    "slang_sd_score_train: ndarray[int] = np.array(slang_sd_score_train)\n",
    "\n",
    "# Remove entries with all zeros in the slang_sd score data\n",
    "slang_sd_score_train: ndarray[int] = np.delete(slang_sd_score_train, zero_index_train)\n",
    "\n",
    "print(\"Processed training data size:\", len(train_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00348677",
   "metadata": {},
   "source": [
    "#### Add remaining feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52144176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the length of the text data to the vectorized data\n",
    "train_vectorized: ndarray[ndarray[float]] = np.column_stack(\n",
    "    (train_vectorized, train_text_len)\n",
    ")\n",
    "test_vectorized: ndarray[ndarray[float]] = np.column_stack(\n",
    "    (test_vectorized, test_text_len)\n",
    ")\n",
    "validation_vectorized: ndarray[ndarray[float]] = np.column_stack(\n",
    "    (validation_vectorized, validation_text_len)\n",
    ")\n",
    "\n",
    "# Add sentiment score to each entry in the vectorized data\n",
    "train_vectorized: ndarray[ndarray[float]] = np.concatenate(\n",
    "    (train_vectorized, train_sentiment_score), axis=1\n",
    ")\n",
    "test_vectorized: ndarray[ndarray[float]] = np.concatenate(\n",
    "    (test_vectorized, test_sentiment_score), axis=1\n",
    ")\n",
    "validation_vectorized: ndarray[ndarray[float]] = np.concatenate(\n",
    "    (validation_vectorized, validation_sentiment_score), axis=1\n",
    ")\n",
    "\n",
    "# Add slang_sd score to each entry in the vectorized data\n",
    "train_vectorized: ndarray[ndarray[float]] = np.column_stack(\n",
    "    (train_vectorized, slang_sd_score_train)\n",
    ")\n",
    "test_vectorized: ndarray[ndarray[float]] = np.column_stack(\n",
    "    (test_vectorized, slang_sd_score_test)\n",
    ")\n",
    "validation_vectorized: ndarray[ndarray[float]] = np.column_stack(\n",
    "    (validation_vectorized, slang_sd_score_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e326d3a",
   "metadata": {},
   "source": [
    "#### Convert labels to one-hot encoding\n",
    "\n",
    "For fitting into the neural network and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72bea674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 14:10:09.158575: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 14:10:09.158646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 14:10:09.158662: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 14:10:09.264056: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 14:10:09.264107: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 14:10:09.264114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-14 14:10:09.264143: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 14:10:09.264166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_label_one_hot: ndarray[ndarray[float]] = tf.one_hot(train_label, 3)\n",
    "validation_label_one_hot: ndarray[ndarray[float]] = tf.one_hot(validation_label, 3)\n",
    "test_label_one_hot: ndarray[ndarray[float]] = tf.one_hot(test_label, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435cdbc",
   "metadata": {},
   "source": [
    "#### Final shape of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "711ac065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (45614, 10013)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18faae",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bdb1ad",
   "metadata": {},
   "source": [
    "#### Setup the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32fea4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Input layer\n",
    "input_layer = tf.keras.layers.Input(shape=(train_vectorized.shape[1],))\n",
    "\n",
    "dropout_rate = 0.7\n",
    "activation_function = \"sigmoid\"\n",
    "\n",
    "#tf.random.set_seed(2024)\n",
    "\n",
    "# Define the model\n",
    "neural_network = tf.keras.models.Sequential(\n",
    "    [\n",
    "        input_layer,\n",
    "        tf.keras.layers.Dense(2048, activation=activation_function),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(512, activation=activation_function),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(128, activation=activation_function),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, mode=\"min\", verbose=1\n",
    ")\n",
    "\n",
    "# Add parameters to Adam optimizer if needed\n",
    "modified_adam = tf.keras.optimizers.Adam()\n",
    "\n",
    "neural_network.compile(\n",
    "    optimizer=modified_adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "rate_scheduler = tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff0a3c4",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e30804f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 14:10:10.171088: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826931928 exceeds 10% of free system memory.\n",
      "2024-04-14 14:10:10.872927: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826931928 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713103812.087721   43849 service.cc:145] XLA service 0x7f14b4003f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1713103812.087771   43849 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-04-14 14:10:12.109782: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-14 14:10:12.202952: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/90\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3909 - loss: 1.3948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713103815.680027   43849 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4027 - loss: 1.2156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713103820.811943   43992 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 456 bytes spill stores, 408 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103821.523819   43993 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 464 bytes spill stores, 412 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103821.858452   43994 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 252 bytes spill stores, 252 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103823.807204   44077 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103824.217103   44074 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103824.321261   44073 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 516 bytes spill stores, 308 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103824.666993   44078 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 28 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103824.703388   44070 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 480 bytes spill stores, 376 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103824.872768   44079 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 524 bytes spill stores, 312 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103825.199141   44069 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 28 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103825.222397   44070 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_53', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103825.246881   44068 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 116ms/step - accuracy: 0.4028 - loss: 1.2145 - val_accuracy: 0.4345 - val_loss: 1.0219 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4395 - loss: 1.0310 - val_accuracy: 0.4345 - val_loss: 1.0232 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4433 - loss: 1.0305 - val_accuracy: 0.4345 - val_loss: 1.0203 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4446 - loss: 1.0231 - val_accuracy: 0.4345 - val_loss: 1.0179 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4487 - loss: 1.0221 - val_accuracy: 0.4345 - val_loss: 1.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4711 - loss: 1.0006 - val_accuracy: 0.5955 - val_loss: 0.8510 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5710 - loss: 0.8882 - val_accuracy: 0.6305 - val_loss: 0.7853 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6069 - loss: 0.8391 - val_accuracy: 0.6550 - val_loss: 0.7618 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6294 - loss: 0.8017 - val_accuracy: 0.6635 - val_loss: 0.7440 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6476 - loss: 0.7738 - val_accuracy: 0.6795 - val_loss: 0.7215 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6642 - loss: 0.7370 - val_accuracy: 0.6810 - val_loss: 0.7112 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6715 - loss: 0.7230 - val_accuracy: 0.6810 - val_loss: 0.7068 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6759 - loss: 0.7151 - val_accuracy: 0.6915 - val_loss: 0.7022 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6839 - loss: 0.7039 - val_accuracy: 0.6920 - val_loss: 0.6991 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6878 - loss: 0.6937 - val_accuracy: 0.6980 - val_loss: 0.6985 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6967 - loss: 0.6848 - val_accuracy: 0.7015 - val_loss: 0.6962 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7010 - loss: 0.6741 - val_accuracy: 0.7000 - val_loss: 0.6929 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7041 - loss: 0.6661 - val_accuracy: 0.7040 - val_loss: 0.6912 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7060 - loss: 0.6635 - val_accuracy: 0.7040 - val_loss: 0.6902 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7117 - loss: 0.6610 - val_accuracy: 0.7045 - val_loss: 0.6898 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7159 - loss: 0.6441 - val_accuracy: 0.7030 - val_loss: 0.6920 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7178 - loss: 0.6439 - val_accuracy: 0.7040 - val_loss: 0.6906 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7209 - loss: 0.6440 - val_accuracy: 0.7050 - val_loss: 0.6904 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7216 - loss: 0.6433 - val_accuracy: 0.7075 - val_loss: 0.6909 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7183 - loss: 0.6442 - val_accuracy: 0.7055 - val_loss: 0.6909 - learning_rate: 1.0000e-04\n",
      "Epoch 25: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device(device_name):\n",
    "    history = neural_network.fit(\n",
    "        train_vectorized,\n",
    "        train_label_one_hot,\n",
    "        validation_data=(validation_vectorized, validation_label_one_hot),\n",
    "        epochs=200,\n",
    "        batch_size=512,\n",
    "        callbacks=[early_stopping, rate_scheduler],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa720ba6",
   "metadata": {},
   "source": [
    "#### Evaluate the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff0da235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713103850.347355   44939 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 252 bytes spill stores, 252 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6411 - loss: 0.8284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713103853.753311   45011 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1713103853.758484   45003 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_48', 512 bytes spill stores, 392 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6408 - loss: 0.8290\n",
      "Test loss: 0.8376511931419373\n",
      "Test accuracy: 0.636681854724884\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = neural_network.evaluate(test_vectorized, test_label_one_hot)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04851f07",
   "metadata": {},
   "source": [
    "#### Plot graphs about loss and accuracy during epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e422f370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAGwCAYAAACnyRH2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABq90lEQVR4nO3dd3xUVf7/8dfMpIc0CKlA6J0AUgKKFRBFWRF3FWQVUXFVsLGuigUEXdnFFVHXla/+xI6wuhZWXBSj2KiCofcWIAUCpJNkMnN/f0wyEhIgZZKb8n4+HvPIzJ07dz5zGMibc8+5x2IYhoGIiIhIE2c1uwARERGR+kChSERERASFIhERERFAoUhEREQEUCgSERERARSKRERERACFIhEREREAvMwuoD5yOp2kpKQQFBSExWIxuxwRERGpBMMwyMnJISYmBqu16v0+CkUVSElJoXXr1maXISIiItVw6NAhWrVqVeXXKRRVICgoCHA1anBwsEePbbfb+frrr7nyyivx9vb26LHl7NTudU9tbg61uznU7uY4s92zs7Np3bq1+/d4VSkUVaD0lFlwcHCthKKAgACCg4P1F6cOqd3rntrcHGp3c6jdzXG2dq/u0BcNtBYRERFBoUhEREQEUCgSERERARSKRERERACFIhERERFAoUhEREQEUCgSERERARSKRERERACFIhERERFAoUhEREQEUCgSERERARSKRERERAAtCCsiIiJnUexwUlDspNDuoLDYiQFYAKvFgtXieuC6b3Fvt1hP38eCxQKWkv3c+1iqv2hrbVIoEhERaSTsDifHcgpJyy4gLct1yykopqDYQYHdQYH9t4BTYHeUbC+5X/r8aduKnUat1XrPZR149KqutXb86lAoEhERaQByC4tJyyogvTTwnPYzPbuA1KwCMnILMWopx3jbLFgsFgzDwDDAaRgYUO33s9a/jiKFIhERETM5nQYn8ovcPTup2QWkZ7lCTnp2SejJKiCnsLhSx/OyWogM9iMqxI+oYD9CArzx87Lh623Fz8uGn7cVP+/ffvpW+FzJ/ZLnfL1s2M6SYkpDkoErKDlLHxtgYOAsDVAGZQKVn7fNg63oGQpFIiIitaT0dFZq1um9O6dIyy4kLesUqVkFHM0upMjhrNTxgny9iAzxIzrEzxV8gv1cj0tCUGSwHy0CfbDWYTeMpWSMEICNetj9UwUKRSIiIjVwMq+IXw5k8M0RC798sZ30nCL36axjlTydZbFAeDNfok7r4Snzs+R+oK9+bdcmta6IiEgl2R1Odqbl8GvySX5NzuTXQ5nsz8gredYGyYfKvab0dFZ0SNlenaiSHp+oEH8ignzxtukqOWZTKBIRETmLtKwCfk0+SdKhTH5NzmTTkUwK7OVPdbVrEUAYuQzs0YHYsICSEORPVEjdn86S6lMoEhERAQrsDrYcySrpAXL1BKVmFZTbL8jPiz6tQ+nbJoy+bULp0yqUZj4WvvzyS0YO74S3t7cJ1YsnKBSJiEiTlFtYTOL2dNYfdPUEbUvJLnddHqsFukQF07dNKH1LglD78MByPT92u70uS5daolAkIiJNyv6MPN5ddYCPfzlcbpp7eDNfLmgTSp82ofRtHUZ8qxANbm5C9CctIiKNntNp8MPuY7yz8gDf7Tzm3t4uPJDLu0S4eoLahBIb6l8vl5+QuqFQJCIijVZOgZ3/rD/Mu6sOss89Swwu79KSCRe25ZJOLTUIWtwUikREpNHZdyyXd1cd5OP1h8ktOUUW5OvF7/u34tbBbWkXHmhyhVIfKRSJiEij4HQafL/rGG+vPMD3u347RdahZSATLmzLmAta0Uzjg6ruVCYc3wuZB8A3GEJauW6+QWZX5nH6doiISIOWXWDn418O8+6qAxw4ng+4rhB9RZcIbruoLUM6hmuc0PkU5cGJfXB8jysAHd8LJ/a6Hucfr/g1fiEQ0vq3kBTSquzjZlFga1gxo2FVKyIiUmLP0VzeXXWA/6w/TF6RA3CdIrtxQGtuHRxHXAudIiujuBBOHigJPXtKQk/JLSfl3K9tFgVhbV3hKesQFGRCQZbrlr6l4tdYbBAcc0ZoOi04hbapd71NCkUiItIgZBfYSck8xd6jeSxal8yPuzPcz3WMaOY6RdY3tnJT6B3F4CgEh911SsjawJbYcBRDYbYrlBRmQ0F2xT8LsyHzkCsEZR0C4xwLz/o3hxYdoHkHaNERWrR3/Wzevnx4KcyBrCOQddh13KzDp90OQfYRcBaXPFd+6RMABv4JRs7xXJt4gEKRiIjUHocd0jZB8hrIzzjrbsVOg7zCYnIKisktKCa30E5Ooet+6c/SleQtGAzBwTBvO21DvekW7k1Lf7DsL4LdBVBcBMUFrtBTfNrt9MeG47c3t1ghIByaRUBgOARGQGBLaNbS9TOwZHuzku1evjVvk4JsKMw6e5g5X9ix51fvvX2anRF8OvwWfAKaV/44vkEQ0dV1q4jTAblHzx6asg67eovqGYUiERHxnMIcOLwOkldD8io4/EulfoF7ASEltwpZqPg3Vk7JrSYMJ+Qddd0qwzfktJDkClFW/+a0P3oE649bwZ537lBTfKqGBZ/GO8DV0+UX7PrpG/Tbfb8Q18+gqJIA1NFVc12Mr7LaIDjadWs9oOJ9DKPi7SaqF6Ho1Vdf5fnnnyctLY3evXvzyiuvMHDgwAr3veyyy/j+++/LbR85ciRLly4FwDAMZsyYwRtvvEFmZiYXXXQRr732Gp06darVzyEi0uRkp8Kh1b+FoLTN5U7RZNOMdY5OJBsR5zyU1Wqhma8Xgb5eBPrYXD99vWjmU7LN1/bbSvI2b7D5gpcfePm4ftp8znjs6+rVqXCfkucsNjh1EvKOlQSjDFcPR96x3265JdvzjoHT7urhKcxyjckpYQN6ARypQtt5B54WYCr6GXKO50NcAcjWgNdZq4eD300PRYsXL2bq1KnMnz+fhIQE5s2bx4gRI9i5cycREeX/An3yyScUFRW5Hx8/fpzevXvzhz/8wb1tzpw5vPzyy7zzzju0a9eOp556ihEjRrBt2zb8/Pzq5HOJiNSZ4iI4uhVSfsV26Bcu3LsB28eLISiy5PRPya309E9gS9cv1ar+UjIMyNjlCj+lIejkgXK7HaElaxxd+MXZhXXOLuwxYjCwEhnsS0yoPzGh/sSG+hMd4ud6HOJPTKgfzQN9zJkl5l3So3E+huEaYJx7rFyIcuSkk3pgJ9FtO2PzDz1/qPENbnAzs5oC0/9E5s6dy6RJk5g4cSIA8+fPZ+nSpSxYsIDHHnus3P7Nm5c957lo0SICAgLcocgwDObNm8eTTz7JddddB8C7775LZGQkn332GWPHjq3lTyQiUoscxZCxE1J+hSMbXD/Tt4DD9Z9FK9ASYOf2cx/H5lMSkM4zhqYo/7SeoNVw6kSZwzixsN3ZhnVOVwj6xdmZNFrg720jvk0Iw+PCeLRkNfkWzWo4FsdsFgv4h7luLTuXecppt7P+yy8ZOXIkNu8G3HvTxJkaioqKili/fj3Tpk1zb7NarQwbNoxVq1ZV6hhvvvkmY8eOJTDQNfVy//79pKWlMWzYMPc+ISEhJCQksGrVqgpDUWFhIYWFhe7H2dnZgGvVY0+vfFx6PK2oXLfU7nVPbe4BhhNO7MWSmoQlJcn1M30zlgrG6Bj+YRjRfXBE9GJTaiG9OrfFduo45GdgyTsGeRlY8o66HhfmuEJU9hHXrQpO4UOSoyPrjM784uzCr85O5BBAq1A/+rQO5a6S1eS7RDX77VRXicb8XdD33RxntntN29/UUJSRkYHD4SAyMrLM9sjISHbs2HHe169du5YtW7bw5ptvurelpaW5j3HmMUufO9Ps2bOZOXNmue1ff/01AQEB562jOpYvX14rx5VzU7vXPbV5JRkGAUUZhObvJzR/X8nPA3g7yw/KtVv9yAxoR2ZAWzID2pMZ0I58n5aunoxCoDkczgCIdb0goOTW0vXQ6izCtzgbX3u262dxlvu+rSgbozAbL3s2AY5snAZscHZy9wRtNdritNho0wzaNjP4Q5BB26BiQnxygVw4cZjkE5C8sU5ard7R990cpe2en1/NWXklTD99VhNvvvkmvXr1Ouug7MqaNm0aU6dOdT/Ozs6mdevWXHnllQQHB9e0zDLsdjvLly9n+PDheKuLtc6o3eue2rwSDCeW5FVYtv4H664vsVQwZd3w8sOI7IUR0xcjug9GdF9o0YFQi5XQCg5Z1XbPzLfzy8GTrD1wkrUHTrD9aA7OMyYFRQb50rdNKFe3DuHxNqF0jw7G16uBXdenlun7bo4z2730TE91mRqKwsPDsdlspKenl9menp5OVFTUOV+bl5fHokWLmDVrVpntpa9LT08nOvq3gXPp6en06dOnwmP5+vri61v+XLe3t3etfblr89hydmr3uqc2P4NhuK7bs/kj2PJJ2dNXVm+I7AGxF0BMX4i5AEvLrliqMSD3bO1+PLeQtftPsGb/CVbvO87O9JxyM6PbtgggoV0LEto3Z2C75sSG+muZjErS990cpe1e07Y3NRT5+PjQr18/EhMTGT16NABOp5PExESmTJlyztd+9NFHFBYW8sc//rHM9nbt2hEVFUViYqI7BGVnZ7NmzRruueee2vgYIiLnd3wvbPmPKwxl7Pptu28IdB8FPX8PcRfW/MKAZziWU8ia/cdZs+8Ea/YfZ1d6brl9OrQMJKF9CxLaNSehXQuiQjRLV5om00+fTZ06lQkTJtC/f38GDhzIvHnzyMvLc89Gu/XWW4mNjWX27NllXvfmm28yevRoWrRoUWa7xWLhwQcf5Nlnn6VTp07uKfkxMTHu4CUiUidy0mHrJ64gdGT9b9u9/KDzCOj1B+g4HLw9F0JyCuysz7Cw8vNtrDt4kn3H8srt0zmyWZmeoIgghSARqAeh6KabbuLYsWNMnz6dtLQ0+vTpw7Jly9wDpZOTk7GesSbNzp07+emnn/j6668rPOYjjzxCXl4ed911F5mZmQwZMoRly5bpGkUiUvsKsmD7f11BaP8Pv13I0GKF9pe7glDXa1zXq/EQwzDYdDiLhWuSWbLxCKfsNuCw620t0CUyiEHtWzCofXMGtG3e8KfGi9QS00MRwJQpU856umzFihXltnXp0gXjHJcHt1gszJo1q9x4IxGRWmE/Bbu/dgWhXV+71tgq1WqgKwj1GO267o8H5RYWsyQphQ/WHGRrym8DTCP9DUb2bcvgDuEMbNec0AAfj76vSGNVL0KRiEi9YRiu1b3LLCJ6+iKjRb89LsyGPd+4eoYKT5v10rKrKwj1vAGat/N4iVuOZLFwbTKf/3qEvCLXwqY+XlZG9ozixn6xHN26imuu7qIBvyJVpFAkIk1H7jFYMRtSk869kvoZa3dVSkhrVwjq9QfXDDIPz9bKLyrmi42pfLDmIBsPZ7m3tw8P5OaENtxwQSvCAn2w2+18uc2jby3SZCgUiUjj53TChnfgm6dda1dVhdXrLIuNlvyM6uUKQq0TwOr5a/fsSMtm4ZpkPt1whJzCYgC8bRZG9IhifEIcg9o313R5EQ9RKBKRxi1tM3zxEBxe53oc1QuGPAR+oWVXS3evqH7GY6utzksusDtYusnVK7QhOdO9Pa5FAOMGtuH3/VoRrsHSIh6nUCQijVNhDnw3G9bMB8MBPs3g8idg4F31dnXyPUdz+GBNMp9sOELWKdcaTl5WC1f2iOTmgXFc2KEFVqt6hURqS/38l0FEpLoMA7Yvgf89Bjkprm3dR8NVsyE4xtTSzpSeXcDGQ5lsPpLFqr3H+eXgSfdzrcL8GTewDX/o30rXERKpIwpFItJ4nNgPX/4F9pQsyhnWFka+AJ2GmVoWuJbX2HQki02Hsth8JJNNh7M4mlNYZh+b1cLQrhHcnNCGSzq1VK+QSB1TKBKRhq+4EFa+DD/8wzWjzOoNQx6Ei/8M3v51Xk5Wvp3NR7LYdCSzJARlcSSz/Gr3NquFThHNiG8VQq9WoQzvFqklNkRMpFAkIg3b/h/gi6lwfLfrcbtL4Jq5EN6pTt4+t7CYLUey2Hw4i01Hsth8OJMDx/PL7WexuKbPx7cKJb5VCPGtQugeHYK/T90P5BaRiikUiUjDlHsUvn4SNi12PQ5sCSOec02Pr+Up6lmn7Hy64TD//uUw29Oyy60yD66ZYr1iQ0oCUCg9YoIJ8tPFFEXqM4UiEWlYnE7Y8HbJNYeyAAv0vx2GPgX+YbX61psPZ/H+6oMs2ZjCKbvDvT021J9esSH0KukB6hUboqU1RBoghSIRaThSN7pOlR35xfU4Kh6unQet+tXaW54qcvDfTSl8sLrslaQ7Rzbjj4PiuLpnNC2DdM0gkcZAoUhEPMswoCgXslIJzduL5ch68KrhPzWGAVs/KbnmkBN8guCKJ2HAnbV2zaE9R3NZuCaZj9cfIrvAdSVpH5uVq3u5riQ9oG2YriQt0sgoFInI+TkdkH8C8o5B3lHIy3CN6Sn3OMO1rfgU3sClALs8XEuPMa6xQ8HRHj4w2B1Ovt6azvurD7Jq33H39tbN/bl5YBx/6K8rSYs0ZgpFIvKbgixY9S84vqck8GS4Qk/+8Sovkmp4B3IKP/wDm+GR/pTAlnD5NOjo+WsOpWSe4sO1ySxad4hjJdcOslrgiq4RjB8Ux6W6ZpBIk6BQJCIuucfg/TGQtuns+/g3h2YRroBSemtWej+izONiiw/Lv/ySkSNH4u1d/2ZdOZ0G3+8+xgerk/l2RzrOkhlkLYN8GTugNWMHtiE2tO6vcSQi5lEoEhHIOgzvXufqIQoIh4vuh2aRJSGnJOwEtABbFcKN3V579dZARm4hH/1ymIVrD3LoxG8XVBzcvgV/HBTHlT0i8bZ5frV7Ean/FIpEmrqMPfDeaMg6BMGt4NbPIbyj2VV51Mm8Ir7amsYXm1JZte84jpJuoWA/L27o14rxCXF0jGhmcpUiYjaFIpGmLG0zvHe9a/xQi45wy2cQ2trsqjwiM7+Ir7em88XmVH7ek+EOQgC9W4cyfmAbRvWO0RWlRcRNoUikqUpeAwv/4BpcHdUL/vipazxQA5aVb+frbWks3ZzKT7szKD4tCPWICeaa+Giu6RVNXItAE6sUkfpKoUikKdr7LSwaD/Z8aD0Ibl4M/qFmV1Ut2QV2vtmWzhebUvlx9zHsjt+CULfoYK6Nj2Zkr2jahSsIici5KRSJNDXblsB/7gBHEXQYCje9Bz4NKzDkFNhJ3H6ULzal8sOuYxQ5frtcQJfIIK4pCUIaJyQiVaFQJNKU/PoBLJniuuZQ9+tgzP8Dr4axRlduYTGJ29NZuimVFbuOUVT8WxDqGNGMa0tOjXWKDDKxShFpyBSKRJqK1a/Bssdc9/v+EUa9DNb6Pcj4VJGDxB3pfLExle92HqXwtCDUvmUg18bHcG18NJ0VhETEAxSKRBo7w4Dv58CK51yPB02GEX+FerpuV4HdwYqdx/hiUwqJ24+WWY2+XXgg1/SK5pr4aLpGBWntMRHxKIUikcbM6YSvn4DV/3I9vvwJuOQv9S4QFRU7+WnPMb7YmMrX29LJLSx2P9e6uT/XxsdwTa9oesQEKwiJSK1RKBJprBzF8N8HIOl91+Or/g6D7ja3ptMUO5ys3HucLzal8NXWdLJO/XYF7JgQP66Jj+ba+BjiW4UoCIlInVAoEmmMigvhP3fC9iVgscJ1/4I+48yuCofTYM3+43yxKZVlW9I4kVfkfq5lkC/X9IpmVO9o+rYO0wKsIlLnFIpEGpuiPFj8R9e1iGw+8PsF0G2UaeU4nQa/HDjBfzem8OWWNPcq9ADNA324umcU18bHMLBdc2wKQiJiIoUikcbkVCYsvBEOrQHvABi7EDpcbkopR3MK+fSAldkv/EBa9m9BKMTfm6t6RHFt72gGt2+BlxZfFZF6QqFIpLHIPQrvj3GtZ+YXAuM/htYDTSllQ/JJ7n5vPUdzrEAhQb5eDO8Ryaj4GC7qGI6Pl4KQiNQ/CkUijUHmIXj3OjixFwIj4JZPIaqnKaV8vP4wj3+ymSKHk2h/g+nX9+XyblH4edfvayKJiCgUiTRkxUWu2WUr/g65aRDSGm79HFp0qPtSHE5m/28Hb/60H4Dh3SIYFpTCsG4ReCsQiUgDoFAk0hAVF8Kv78OPcyH7sGtbeGdXD1FIqzovJyvfzpQPN/Dj7gwA7h/aicmXtGXZspQ6r0VEpLoUikQakuJC+PW9kjB0xLWtWRQMeQj6TQBv/zovac/RHO585xcOHM/H39vG3Bt7c3WvaOx2+/lfLCJSjygUiTQExYWw4V346cXfwlBQNAyZChfcCt5+ppSVuD2dBxYlkVtYTGyoP2/c2p/uMcGm1CIiUlMKRSL1mb3gt56hnJJTUUExcPFU6HuLaWHIMAz+tWIv//h6J4YBCe2a86/xF9Cima8p9YiIeIJCkUh9ZC+ADe+4eoZyUl3bgmNdp8lMDEPgWrn+kf9s4r8bXSHtj4PaMGNUD7x1vSERaeAUikTqE/spWP8O/DzvtDDUCi4uCUNe5vbEpGSe4q73fmHLkWy8rBZmXteD8QlxptYkIuIpCkUi9YH9FKx/G36a55paDyVhaCr0/aPpYQjglwMnuPv99WTkFtE80IfXxl9AQvsWZpclIuIxCkUiZrKfgl/ecvUM5aa7toW0doWhPuPrRRgCWLQ2mac+34LdYdAtOpjXb+lH6+YBZpclIuJRCkUiZtm4CJZPPy0MtTktDPmYW1sJu8PJs19s451VBwEY2SuKf/yhNwE++qdDRBof/csmYoYDP8OndwMGhLaBix+G3uPqTRgCOJlXxL0fbGDVvuMATB3emfuu6IjFopXsRaRxUigSqWsFWb8Fovix8LtX6lUYAtiRls2kd3/h0IlTBPrYmHtTH0b0iDK7LBGRWmX6HNpXX32Vtm3b4ufnR0JCAmvXrj3n/pmZmUyePJno6Gh8fX3p3LkzX375pfv5p59+GovFUubWtWvX2v4YIpX3v8cgKxlC4+Caf9S7QLRsSxpj/rWSQydO0bq5P5/ce5ECkYg0Cab2FC1evJipU6cyf/58EhISmDdvHiNGjGDnzp1ERESU27+oqIjhw4cTERHBxx9/TGxsLAcPHiQ0NLTMfj169OCbb75xP/byUoeY1BPbPoeNC8FihTGvg2+Q2RWV8fH6wzz80UYALuzQgldvvoCwwPoV2kREaoupaWHu3LlMmjSJiRMnAjB//nyWLl3KggULeOyxx8rtv2DBAk6cOMHKlSvx9vYGoG3btuX28/LyIipK/7OVeiYnDf77gOv+kIegzSBz6znDip1HefQ/mwAYn9CGp3+nCzKKSNNiWigqKipi/fr1TJs2zb3NarUybNgwVq1aVeFrlixZwuDBg5k8eTKff/45LVu25Oabb+bRRx/FZrO599u9ezcxMTH4+fkxePBgZs+eTZs2bc5aS2FhIYWFhe7H2dnZANjtdo8vall6PC2WWbdMb3fDwPbpvVhPncSIiqf4oj9DPfoObDmSzb0fbMDhNLiudzTTR3YBpwO701HtY5re5k2U2t0candznNnuNW1/i2EYRo2rqoaUlBRiY2NZuXIlgwcPdm9/5JFH+P7771mzZk2513Tt2pUDBw4wfvx47r33Xvbs2cO9997L/fffz4wZMwD43//+R25uLl26dCE1NZWZM2dy5MgRtmzZQlBQxacqnn76aWbOnFlu+8KFCwkI0LVYpObaHvuG3offxWHx5vsus8jxjzW7JLeMAnhxi41cu4XOIU7+1NWJlzqIRKQBys/P5+abbyYrK4vg4KovTt2gQlHnzp0pKChg//797p6huXPn8vzzz5Oamlrh+2RmZhIXF8fcuXO54447Ktynop6i1q1bk5GRUa1GPRe73c7y5csZPny4+xSg1D5T2/34brz+3xVYik/huPI5nAPuqtv3P4fjeUWMfWMtB47n0y0qiA/uGECQn2c6kPVdN4fa3Rxqd3Oc2e7Z2dmEh4dXOxSZdvosPDwcm81Genp6me3p6elnHQ8UHR2Nt7d3mVNl3bp1Iy0tjaKiInx8yg8IDQ0NpXPnzuzZs+estfj6+uLrW/7Kwd7e3rX25a7NY8vZ1Xm7O+yw5F4oPgXtL8c26B5s1vrRDZNfVMyfPkjiwPF8YkP9eef2gTQP8vxCs/qum0Ptbg61uzlK272mbW/av84+Pj7069ePxMRE9zan00liYmKZnqPTXXTRRezZswen0+netmvXLqKjoysMRAC5ubns3buX6Ohoz34Akcr44XlI+RX8QmH0v6CeBKJih5P7Fv7KxkOZhAZ4887tA4kI9nwgEhFpSEz9F3rq1Km88cYbvPPOO2zfvp177rmHvLw892y0W2+9tcxA7HvuuYcTJ07wwAMPsGvXLpYuXcpzzz3H5MmT3fs8/PDDfP/99xw4cICVK1dy/fXXY7PZGDduXJ1/PmniDq2DH/7hun/tXAiOMbeeEoZh8NTnW0jccRRfLytvTuhPx4hmZpclImI6U6fk33TTTRw7dozp06eTlpZGnz59WLZsGZGRkQAkJydjPe1/1q1bt+arr77ioYceIj4+ntjYWB544AEeffRR9z6HDx9m3LhxHD9+nJYtWzJkyBBWr15Ny5Yt6/zzSRNWmAuf3gWGA3rdCD1vMLsit5cT9/Dh2kNYLfDyuL70i2tudkkiIvWC6Vc1nDJlClOmTKnwuRUrVpTbNnjwYFavXn3W4y1atMhTpYlU39dPwIl9ENwKRj5vdjVui9cl8+I3uwCYdV1PXalaROQ09WOAg0hjsnMZrH/bdf/618A/1Mxq3L7dkc7jn24BYPLlHfjjoDiTKxIRqV8UikQ8KfcYLCnp+Rw8BdpdYm49JZIOZTL5g19xOA3GXBDLw1d2MbskEZF6R6FIxFMMw7WMR94xiOgOVzxldkUAHMjI4/a313HK7uCSzi35+w3xWCwWs8sSEal3FIpEPOXX92DnUrB6uxZ79TZ/intGbiET3lrLibwiesYG86/xF2g9MxGRs9C/jiKecGIf/K9kEeMrnoSoXubWA+QVFnP72+s4eDyf1s39WXDbAJr5mj63QkSk3lIoEqkppwM+vRvseRB3EVx4n9kVYXc4mbxwA5sOZxEW4M07EwcSUQtXqxYRaUwUikRq6qcX4dAa8AmC0a+B1Xb+19QiwzB44tPNrNh5DD9vK2/eNoD2LXVxRhGR81EoEqmJlCRYMdt1f+TzEGb+NPcXv9nNv385jNUC/xx3ARe0CTO7JBGRBkGhSKS67Kfgk7vAWQzdfge9x5pdEQvXJPNy4m4Anh3di2HdI02uSESk4VAoEqmub56GjJ3QLBKunQcmT3P/Zls6T362GYD7h3bi5oQ2ptYjItLQKBSJVMfeb2HNfNf96/4FgS1MLWdD8kmmfLgBpwE39m/FQ8M6mVqPiEhDpFAkUlX5J+Cze133B9wJnYaZWk7y8XzueHsdBXYnl3dpyV+v76WLM4qIVINCkUhVGAYsnQo5qdCiIwx/xtRycguLufPddZzMt9MrNoR/3qyLM4qIVJf+9RSpis0fwdZPwWJzXbXaJ8C0UpxOg4cWJ7ErPZeIIF/euLU/gbo4o4hItSkUiVSWvQCWT3fdv/QRiO1najkvfrOL5dvS8fGy8n+39CMqRBdnFBGpCYUikcpKet912iwoBoY8ZGopX2xK4ZVv9wAw+/pe9NW1iEREakyhSKQyHHb4aZ7r/kUPgJevaaVsOZLFwx9tBGDSxe24oV8r02oREWlMFIpEKmPjIsg6BIER0G+CaWVk5BZy17u/UGB3cknnljx2dTfTahERaWwUikTOx1EMP77gun/hfeDtb0oZRcVO7nl/PSlZBbQPD+SVcX2xWTX1XkTEUxSKRM5ny3/g5H7wbw79bzelBMMwmLFkC+sOnCTI14s3JvQnxN/blFpERBorhSKRc3E64Md/uO4Pngy+5qw2/97qg3y49hAWC7x8c186aNV7ERGPUygSOZdtn0PGLvALgYF3mVLCyj0ZzPzvNgAeu6orl3eJMKUOEZHGTqFI5GycTvihpJco4R7wC67zEpKP53Pvwg04nAbX943lrkva13kNIiJNhUKRyNns/BKObgWfIBh0d52/fekSHpn5dnq3CmH2GK1pJiJSmxSKRCpiGPDD8677AyeBf91eHPHMJTz+75b++Hnb6rQGEZGmRqFIpCJ7voHUJPAOcA2wrmNawkNEpO4pFImcyTDg+zmu+/1vh8DwOn17LeEhImIOhSKRM+3/Hg6vBZuv62KNdUhLeIiImEehSORM35eMJeo3AYKi6uxtj+VoCQ8RETMpFImc7uBKOPgTWL1dC7/WES3hISJiPoUikdOVjiXqOx5C6ubUlWEYTP98C78c1BIeIiJmUigSKXX4F9j3HVhsMOShOnvbd1cdZNE6LeEhImI2hSKRUqW9RL3HQljbOnnLlXsymPWFlvAQEakPFIpEAFI3wu6vwGKFi/9cJ2+pJTxEROoXhSIR+O3q1T1vgBYdav3t7A4nf3p/vZbwEBGpRxSKRNK3wfb/Aha4+OE6ecv3Vh1ke2o2YQHeWsJDRKSeUCgS+fEfrp/dfwcRXWv97TJyC3nxm10A/GVEVy3hISJSTygUSdOWsRu2fOK6f8lf6uQtn1+2k5yCYnrGBnPTgNZ18p4iInJ+CkXStP34AmBAl5EQ1avW327joUz+vf4QADN/10MXaBQRqUcUiqTpOrEfNv3bdf+S2h9L5HQazFiyFcOAMX1j6RfXvNbfU0REKk+hSJqun+aC4YAOQyG2X62/3Se/HiHpUCaBPjYeu7r2xy6JiEjVKBRJ05R5CJI+dN2/9JFaf7vsAjt/+98OAO4f2omIYA2uFhGpbxSKpGn6+SVw2qHtxdBmUK2/3SuJu8nILaR9eCATL2pX6+8nIiJVp1AkTU9OGmx413W/DnqJ9hzN4a2fDwAwfVR3fLz0105EpD4y/V/nV199lbZt2+Ln50dCQgJr16495/6ZmZlMnjyZ6OhofH196dy5M19++WWNjilNzM8vg6MQWg9y9RTVIsMwmPnfbRQ7DYZ1i+AyrW0mIlJvmRqKFi9ezNSpU5kxYwYbNmygd+/ejBgxgqNHj1a4f1FREcOHD+fAgQN8/PHH7Ny5kzfeeIPY2NhqH1OamLxj8MsC1/1L/wK1vLTG19vS+XF3Bj42K09d271W30tERGrG1FA0d+5cJk2axMSJE+nevTvz588nICCABQsWVLj/ggULOHHiBJ999hkXXXQRbdu25dJLL6V3797VPqY0LdY1r0HxKYi5wDXrrBYV2B0888U2ACZd0o64FoG1+n4iIlIzXma9cVFREevXr2fatGnubVarlWHDhrFq1aoKX7NkyRIGDx7M5MmT+fzzz2nZsiU333wzjz76KDabrVrHBCgsLKSwsND9ODs7GwC73Y7dbq/pRy2j9HiePq6cm91ux7s4B+svbwJQfNFUjOLiWn3P177by+GTp4gM9uWuIXFN7s9c33VzqN3NoXY3x5ntXtP2Ny0UZWRk4HA4iIyMLLM9MjKSHTt2VPiaffv28e233zJ+/Hi+/PJL9uzZw7333ovdbmfGjBnVOibA7NmzmTlzZrntX3/9NQEBAdX4dOe3fPnyWjmunF3XY19jseeR6d+G73c7YM+X539RNZ0ohH8l2QALV0Xms+Kbr2vtveo7fdfNoXY3h9rdHKXtnp+fX6PjmBaKqsPpdBIREcHrr7+OzWajX79+HDlyhOeff54ZM2ZU+7jTpk1j6tSp7sfZ2dm0bt2aK6+8kuDgYE+U7ma321m+fDnDhw/H29vbo8eWs7PnHsf7n3cD0GzkTEZ2vaZW3+/+RRuxO9MZ0DaMJ27pj6WWxy7VR/qum0Ptbg61uznObPfSMz3VZVooCg8Px2azkZ6eXmZ7eno6UVFRFb4mOjoab29vbDabe1u3bt1IS0ujqKioWscE8PX1xdfXt9x2b2/vWvty1+axpTxr0jvYHPkYLbvi1WM0WGtvON3KvRn8b2s6VgvM/F1PfHx8au29GgJ9182hdjeH2t0cpe1e07Y3baC1j48P/fr1IzEx0b3N6XSSmJjI4MGDK3zNRRddxJ49e3A6ne5tu3btIjo6Gh8fn2odU5qAwlysa+cD4LjooVoNRMUOJzOXuAZX/3FQHN1jPNvTKCIitcfU2WdTp07ljTfe4J133mH79u3cc8895OXlMXHiRABuvfXWMoOm77nnHk6cOMEDDzzArl27WLp0Kc899xyTJ0+u9DGlCUpaiOXUCXJ9ozC6ja7Vt3p/9UF2pucQFuDN1OGda/W9RETEs0wdU3TTTTdx7Ngxpk+fTlpaGn369GHZsmXugdLJyclYT/tffevWrfnqq6946KGHiI+PJzY2lgceeIBHH3200seUJih9CwCHwwbRwWo7z87Vdzy3kLnLdwHw8IguhAY07dNmIiINjekDradMmcKUKVMqfG7FihXltg0ePJjVq1dX+5jSBGWnAHDKp0Wtvs0/vt5JdkExPWKCGTugTa2+l4iIeJ7py3yI1LqcVAAKvMNq7S02Hc5k0bpDAMz8XQ9s1qY320xEpKGrcihq27Yts2bNIjk5uTbqEfG80p6iWgpFTqfB00u2Yhgwuk8M/ds2r5X3ERGR2lXlUPTggw/yySef0L59e4YPH86iRYvKXA1apF6xF8CpE0Dt9RR9+usRNiRnEuBjY9rIbrXyHiIiUvuqFYqSkpJYu3Yt3bp147777iM6OpopU6awYcOG2qhRpPpKTp0ZXn7YbZ5feyynwM7flrmuln7fFZ2IDPbz+HuIiEjdqPaYogsuuICXX36ZlJQUZsyYwf/7f/+PAQMG0KdPHxYsWIBhGJ6sU6R6SkIRQdFQC1eVfuXbPRzLKaRdeCC3D2nr8eOLiEjdqfbsM7vdzqeffspbb73F8uXLGTRoEHfccQeHDx/m8ccf55tvvmHhwoWerFWk6krGExlB0R4/9J6juSz4aT8A06/tjq9X7U33FxGR2lflULRhwwbeeustPvzwQ6xWK7feeisvvvgiXbt2de9z/fXXM2DAAI8WKlItJaEID4ciwzCY9cU2ip0GQ7tGcHnXCI8eX0RE6l6VQ9GAAQMYPnw4r732GqNHj65wnZF27doxduxYjxQoUiOlY4qCosGD8wG+2X6UH3Ydw8dm5alru3vuwCIiYpoqh6J9+/YRFxd3zn0CAwN56623ql2UiMec3lPkoVBUYHfwzBeu9c3uvLgdbcM9P4BbRETqXpUHWh89epQ1a9aU275mzRp++eUXjxQl4jGn9xR5yP/7cR/JJ/KJCvZj8uUdPXZcERExV5VD0eTJkzl06FC57UeOHCmzMKtIvZB92uwzD0jJPMWr3+0FYNrIrgT6mr5SjoiIeEiVQ9G2bdu44IILym3v27cv27Zt80hRIh7hdP7WUxQc45FDzvtmF6fsDga2bc7venvmmCIiUj9UORT5+vqSnp5ebntqaipeXvpfs9Qj+RngtAMWCPTM7LCf9xwH4L6hHbHUwnWPRETEPFUORVdeeSXTpk0jKyvLvS0zM5PHH3+c4cOHe7Q4kRopHWTdLAJs5WdJVlVmfhFHMk8BEN8qtMbHExGR+qXKXTv/+Mc/uOSSS4iLi6Nv374AJCUlERkZyXvvvefxAkWqLcez44m2pWQD0KZ5ACH+NQ9ZIiJSv1Q5FMXGxrJp0yY++OADNm7ciL+/PxMnTmTcuHEVXrNIxDSlPUUeGk+0JcXVO9ojJtgjxxMRkfqlWoOAAgMDueuuuzxdi4hnebinaGtJT5FCkYhI41TtkdHbtm0jOTmZoqKiMtt/97vf1bgoEY8onY7voZ4idyiKDfHI8UREpH6p1hWtr7/+ejZv3ozFYsEwDAD3TByHw+HZCkWqK8dzp8/yi4rZeywXUE+RiEhjVeXZZw888ADt2rXj6NGjBAQEsHXrVn744Qf69+/PihUraqFEkWry4GKw21NzMAxoGeRLRJBfjY8nIiL1T5V7ilatWsW3335LeHg4VqsVq9XKkCFDmD17Nvfffz+//vprbdQpUnUePH22tWSQdU/1EomINFpV7ilyOBwEBQUBEB4eTkqK63/jcXFx7Ny507PViVRXUR4UllxLywM9RVuPlA6y1ngiEZHGqso9RT179mTjxo20a9eOhIQE5syZg4+PD6+//jrt27evjRpFqq60l8inGfgFg91eo8NtTdV0fBGRxq7KoejJJ58kLy8PgFmzZnHttddy8cUX06JFCxYvXuzxAkWqJcdz44mKip3sTMsBoKdmnomINFpVDkUjRoxw3+/YsSM7duzgxIkThIWFaS0oqT88OJ5o99Ec7A6DYD8vWoX51/h4IiJSP1VpTJHdbsfLy4stW7aU2d68eXMFIqlfso+4fnpkkPVv44n0PRcRabyqFIq8vb1p06aNrkUk9Z8Hr2a99YjGE4mINAVVnn32xBNP8Pjjj3PixInaqEfEMzy47tlvV7JWKBIRacyqPKbon//8J3v27CEmJoa4uDgCAwPLPL9hwwaPFSdSbR7qKXI6DbalukJRT03HFxFp1KocikaPHl0LZYh4mHugdc1C0f7jeeQXOfDzttK+ZTMPFCYiIvVVlUPRjBkzaqMOEc9xOiA33XU/qGanz0pPnXWNCsZm1SBrEZHGrMpjikTqvdyjYDjAYoNmETU6VOkg654aTyQi0uhVuafIarWec1qyZqaJ6dwLwUaB1VajQ50+HV9ERBq3KoeiTz/9tMxju93Or7/+yjvvvMPMmTM9VphItXnoataGYbgXgtV0fBGRxq/Koei6664rt+33v/89PXr0YPHixdxxxx0eKUyk2jw0yDolq4CT+Xa8rBY6RwZ5oDAREanPPDamaNCgQSQmJnrqcCLV5+4pquEg65LxRB0jmuHnXbPTcCIiUv95JBSdOnWKl19+mdjYWE8cTqRmPNRTVDqeSIvAiog0DVU+fXbmwq+GYZCTk0NAQADvv/++R4sTqZbSnqLgmoV0jScSEWlaqhyKXnzxxTKhyGq10rJlSxISEggLC/NocSLVku2ZgdaaeSYi0rRUORTddttttVCGiIcYxmmnz6o/puh4biGpWQUAdFdPkYhIk1DlMUVvvfUWH330UbntH330Ee+8845HihKptsJssOe57tegp6i0l6hdeCDNfKv8fwcREWmAqhyKZs+eTXh4eLntERERPPfccx4pSqTaSnuJ/ELAJ6DahykNReolEhFpOqocipKTk2nXrl257XFxcSQnJ3ukKJFq89B0/C0lg6x7ajyRiEiTUeVQFBERwaZNm8pt37hxIy1atPBIUSLV5qHp+Nvcg6zVUyQi0lRUORSNGzeO+++/n++++w6Hw4HD4eDbb7/lgQceYOzYsdUq4tVXX6Vt27b4+fmRkJDA2rVrz7rv22+/jcViKXPz8/Mrs89tt91Wbp+rrrqqWrVJA+Oejl/9nqKcAjv7M1zjkhSKRESajiqPIH3mmWc4cOAAQ4cOxcvL9XKn08mtt95arTFFixcvZurUqcyfP5+EhATmzZvHiBEj2LlzJxERFa9wHhwczM6dO92PK1qg9qqrruKtt95yP/b19a1ybdIAZdf89Nn21BwAokP8aNFM3xsRkaaiyqHIx8eHxYsX8+yzz5KUlIS/vz+9evUiLi6uWgXMnTuXSZMmMXHiRADmz5/P0qVLWbBgAY899liFr7FYLERFRZ3zuL6+vufdRxohD5w+00UbRUSapmrPNe7UqROdOnWq0ZsXFRWxfv16pk2b5t5mtVoZNmwYq1atOuvrcnNziYuLw+l0csEFF/Dcc8/Ro0ePMvusWLGCiIgIwsLCuOKKK3j22WfPOuapsLCQwsJC9+PsbNd4Ervdjt1ur8lHLKf0eJ4+rrh4ZR/BAhQHRGCc1sZVaffNhzMB6BrZTH9ONaDvujnU7uZQu5vjzHavaftbDMMwqvKCG264gYEDB/Loo4+W2T5nzhzWrVtX4TWMziYlJYXY2FhWrlzJ4MGD3dsfeeQRvv/+e9asWVPuNatWrWL37t3Ex8eTlZXFP/7xD3744Qe2bt1Kq1atAFi0aBEBAQG0a9eOvXv38vjjj9OsWTNWrVqFzVZ+Yc+nn36amTNnltu+cOFCAgKqP61b6t6IzffhV5zFii6zyApoW61j/H2jjZR8C3d2cdCreZX+eoiIiIny8/O5+eabycrKIji46r39VQ5FLVu25Ntvv6VXr15ltm/evJlhw4aRnp5e6WNVJxSdyW63061bN8aNG8czzzxT4T779u2jQ4cOfPPNNwwdOrTc8xX1FLVu3ZqMjIxqNer56l2+fDnDhw/H29vbo8du8hx2vP4WgwUD+4PbIbCl+6nKtnthsZM+zyRS7DT4/s8XExPqXxeVN0r6rptD7W4Otbs5zmz37OxswsPDqx2Kqnz6LDc3Fx8fn3LbS4upivDwcGw2W7kglZ6eXunxQN7e3vTt25c9e/acdZ/27dsTHh7Onj17KgxFvr6+FQ7E9vb2rrUvd20eu8nKSwMMsHrjHRwF1vKTK8/X7jvSsyh2GoQFeNMmPKjCQfxSNfqum0Ptbg61uzlK272mbV/lKfm9evVi8eLF5bYvWrSI7t27V+lYPj4+9OvXj8TERPc2p9NJYmJimZ6jc3E4HGzevJno6LMPrD18+DDHjx8/5z7SCJTOPAuOrjAQVcYW9yDrEAUiEZEmpso9RU899RRjxoxh7969XHHFFQAkJiaycOFCPv744yoXMHXqVCZMmED//v0ZOHAg8+bNIy8vzz0b7dZbbyU2NpbZs2cDMGvWLAYNGkTHjh3JzMzk+eef5+DBg9x5552Aqydr5syZ3HDDDURFRbF3714eeeQROnbsyIgRI6pcnzQgHriatWaeiYg0XVUORaNGjeKzzz7jueee4+OPP8bf35/evXvz7bff0rx58yoXcNNNN3Hs2DGmT59OWloaffr0YdmyZURGRgKuZUWsp/2v/+TJk0yaNIm0tDTCwsLo168fK1eudPdS2Ww2Nm3axDvvvENmZiYxMTFceeWVPPPMM7pWUWPngen4W46UXMk6Vst7iIg0NdWakn/NNddwzTXXAK5ByR9++CEPP/ww69evx+FwVPl4U6ZMYcqUKRU+t2LFijKPX3zxRV588cWzHsvf35+vvvqqyjVII1DDniKH02BHmpb3EBFpqqo38AL44YcfmDBhAjExMbzwwgtcccUVrF692pO1iVRNDXuK9h3LpcDuJMDHRrsWgR4sTEREGoIq9RSlpaXx9ttv8+abb5Kdnc2NN95IYWEhn332WZUHWYt4XE5JKAqqXigqHWTdPToYq1WDrEVEmppK9xSNGjWKLl26sGnTJubNm0dKSgqvvPJKbdYmUjXu2Wex1Xr51iM6dSYi0pRVuqfof//7H/fffz/33HNPjZf3EPE4wyg7Jb8atqaUhiINshYRaYoq3VP0008/kZOTQ79+/UhISOCf//wnGRkZtVmbSOWdOgmOkquSV+P0mWEYv03Hj1VPkYhIU1TpUDRo0CDeeOMNUlNT+dOf/sSiRYuIiYnB6XSyfPlycnJyarNOkXMr7SUKaAFeVb/0wuGTp8guKMbbZqFTRJCHixMRkYagyrPPAgMDuf322/npp5/YvHkzf/7zn/nb3/5GREQEv/vd72qjRpHzcw+yrt50/NJeoi5RQfh4VXtSpoiINGA1+te/S5cuzJkzh8OHD/Phhx96qiaRqqvheCL3RRujNZ5IRKSp8sh/iW02G6NHj2bJkiWeOJxI1dVwOr7GE4mIiM4TSONQ0+n4mnkmItLkKRRJ41CD02dHcwo4mlOIxQLdojXIWkSkqVIoksahBgOtS3uJ2ocHEuBTreUARUSkEVAoksahBj1FW4+4xhP1jNWpMxGRpkyhSBo+ewGcOuG6X42B1r+NJ9IgaxGRpkyhSBq+0lNnXn7gH1bll2uQtYiIgEKRNAanT8e3VG11+6xTdpJP5APqKRIRaeoUiqThq8F0/G0lvUSxof6EBvh4sioREWlgFIqk4avJIOuU0kHW6iUSEWnqFIqk4avB1aw1nkhEREopFEnD5+4pqs41ikqW99B4IhGRJk+hSBq+avYUnSpysOdoLqBrFImIiEKRNAbZJaGoij1FO9KycRoQ3syHiCDfWihMREQaEoUiadiczt96iqoYikrHE3WPCcFSxan8IiLS+CgUScOWnwFOO2CBZpFVeql75pnGE4mICApF0tCVDrJuFgE27yq9VDPPRETkdApF0rBVc5C13eFkR1oOoJlnIiLiolAkDVs1p+PvOZpLUbGTIF8v2jQPqIXCRESkoVEokoatmj1FpafOusUEY7VqkLWIiCgUSUPnno5f1VCkizaKiEhZCkXSsGUfcf2s4mKwW4+4eop6apC1iIiUUCiShq0ap8+cToNtqSUzz7QQrIiIlFAokoatGlezTj6RT25hMb5eVjq2bFZLhYmISEOjUCQNV1EeFLrGBlWlp2hLyXiirlFBeNn0V0BERFz0G0EartJeIp9m4Ff502CnL+8hIiJSSqFIGq6ckmsUVXE6/pYjJct7aDyRiIicRqFIGq5qTMc3DINtWt5DREQqoFAkDVc1puOn5xRyPK8Im9VC16igWipMREQaIoUiabiqMR2/dDxRx5bN8PO21UZVIiLSQCkUScNVjXXPtqVqEVgREamYQpE0XNXoKdpeEoq6KxSJiMgZFIqk4arGQOvS02c9YzXIWkREylIokobJUQy56a77QZU7fZZnh5SsAkA9RSIiUp5CkTRMeUfBcIDFBs0iKvWSw/kWAOJaBBDs512b1YmISAOkUCQNU+mps6AosFZuFtnhXNdPDbIWEZGK1ItQ9Oqrr9K2bVv8/PxISEhg7dq1Z9337bffxmKxlLn5+fmV2ccwDKZPn050dDT+/v4MGzaM3bt31/bHkLpUjatZH85z9RTpoo0iIlIR00PR4sWLmTp1KjNmzGDDhg307t2bESNGcPTo0bO+Jjg4mNTUVPft4MGDZZ6fM2cOL7/8MvPnz2fNmjUEBgYyYsQICgoKavvjSF2pxiDr30KReopERKQ800PR3LlzmTRpEhMnTqR79+7Mnz+fgIAAFixYcNbXWCwWoqKi3LfIyEj3c4ZhMG/ePJ588kmuu+464uPjeffdd0lJSeGzzz6rg08kdcLdU1TJQdaFxRwrycTqKRIRkYp4mfnmRUVFrF+/nmnTprm3Wa1Whg0bxqpVq876utzcXOLi4nA6nVxwwQU899xz9OjRA4D9+/eTlpbGsGHD3PuHhISQkJDAqlWrGDt2bLnjFRYWUlhY6H6cne2atm2327Hb7TX+nKcrPZ6nj9vU2LKOYAUcgZE4K9GWW49kYmChZTMfQv2sav86oO+6OdTu5lC7m+PMdq9p+5saijIyMnA4HGV6egAiIyPZsWNHha/p0qULCxYsID4+nqysLP7xj39w4YUXsnXrVlq1akVaWpr7GGces/S5M82ePZuZM2eW2/71118TEBBQnY92XsuXL6+V4zYVF+7fQksgaV86hzO/PO/+P6RaABstvQr48svz7y+eo++6OdTu5lC7m6O03fPz82t0HFNDUXUMHjyYwYMHux9feOGFdOvWjf/7v//jmWeeqdYxp02bxtSpU92Ps7Ozad26NVdeeSXBwZ4df2K321m+fDnDhw/H21vTwqvL6zVXiO198dXExw057/7f/2czkMolvdox8soutVydgL7rZlG7m0Ptbo4z2730TE91mRqKwsPDsdlspKenl9menp5OVFRUpY7h7e1N37592bNnD4D7denp6URH/zYINz09nT59+lR4DF9fX3x9fSs8dm19uWvz2I2eYUCOq9fPK6wNVKIdd6S75uP3jA1Vu9cxfdfNoXY3h9rdHKXtXtO2N3WgtY+PD/369SMxMdG9zel0kpiYWKY36FwcDgebN292B6B27doRFRVV5pjZ2dmsWbOm0seUeq4wG+x5rvuVmJJfVOxk91FXKNLMMxERORvTT59NnTqVCRMm0L9/fwYOHMi8efPIy8tj4sSJANx6663ExsYye/ZsAGbNmsWgQYPo2LEjmZmZPP/88xw8eJA777wTcM1Me/DBB3n22Wfp1KkT7dq146mnniImJobRo0eb9THFk0qn4/uFgM/5x3ztSs/B7jAIsBnEhvqdd38REWmaTA9FN910E8eOHWP69OmkpaXRp08fli1b5h4onZycjNX6W4fWyZMnmTRpEmlpaYSFhdGvXz9WrlxJ9+7d3fs88sgj5OXlcdddd5GZmcmQIUNYtmxZuYs8SgNVxen420oWgY0NNLBYLLVVlYiINHCmhyKAKVOmMGXKlAqfW7FiRZnHL774Ii+++OI5j2exWJg1axazZs3yVIlSn1Txwo0rdrkuBNqmWW0VJCIijYHpF28UqbIq9BQdzSng662ugfz9wp21WZWIiDRwCkXS8GSXhKLg84eij345TLHToE/rEGIDa7kuERFp0BSKpOGp5Okzp9Ng0bpkAMb2b1XbVYmISAOnUCQNTyVPn/24J4NDJ04R5OfFyJ6Vu+6ViIg0XQpF0vBUsqdo4ZqDANxwQSv8fWy1XZWIiDRwCkXSsDjskHfMdf8cPUXp2QV8s9016+zmhDZ1UZmIiDRwCkXSsOSkAQZYvSGgxVl3+/e6QzicBv3jwugcGVR39YmISIOlUCQNi3vmWTRYK/76OpwGi9YdAtRLJCIiladQJA1LJQZZ/7DrGEcyTxHi783IXpW7wKOIiIhCkTQslRhk/cEa1zT8Gy5ohZ+3BliLiEjlKBRJw3KenqLUrFN8u8N1BeubE1rXVVUiItIIKBRJw3KenqLF6w7hNGBgu+Z0jNAAaxERqTyFImlYckpCUVD5UFTscLK4ZID1eA2wFhGRKlIokoblHOuerdh5jNSsAsICvLlKV7AWEZEqUiiShsMwzhmKFq51DbD+fb9W+HppgLWIiFSNQpE0HKdOgqPQdf+M02eHT+bz3U7XFazHDdSpMxERqTqFImk4SnuJAlqAl2+ZpxavO4RhwOD2LWjfspkJxYmISEOnUCQNh3uQddlTZ/bTB1gPUi+RiIhUj0KRNBynL/FxmsTtRzmaU0h4Mx+u7K4B1iIiUj0KRdJwnGU6/m8DrFvj46WvtIiIVI9+g0jDkX3E9fO0mWeHTuTz4+5jAIwbqCtYi4hI9SkUScPhvpr1b6How7XJGAZc3CmcuBaBJhUmIiKNgUKRNBxnDLS2O5z8+5fDANysafgiIlJDCkXScJwx0Hr5tnQycgtpGeTLsO6RJhYmIiKNgUKRNAz2Ajh1wnW/ZKD1wjWuAdY39m+Ft01fZRERqRn9JpGGofTUmZcf+IdxICOPn/ZkYLHA2AE6dSYiIjWnUCQNw+nT8S0WPlzn6iW6pFNLWjcPMLEwERFpLBSKpGFwjyeKpajYycelA6wT1EskIiKeoVAkDcNpg6y/2prG8bwiIoN9Gdo1wty6RESk0VAokobhtNNnpQOsb+rfGi8NsBYREQ/RbxRpGEp6ijKsLVi17zhWC9ykaxOJiIgHKRRJw1DSU/R9qhcAl3WJIDbU38yKRESkkVEokoahZImPJfsMQFewFhERz1MokvrP6YQc1+mz3aeCiQ7x47IuLU0uSkREGhuFIqn/8jPAWYwTC0cJZeyANhpgLSIiHqffLFL/lQ6yNkIwrN7cNKC1yQWJiEhjpFAk9V/JIOs0I4wrukYQFeJnckEiItIYKRRJvWc/eQSAdKO5rmAtIiK1RqFI6r29+3YBkOPTkks6aYC1iIjUDoUiqfeOJO8DILp1O2xWi8nViIhIY6VQJPXazrQcvPPSAOjRpZvJ1YiISGOmUCT12sI1B4mynAAgOELjiUREpPYoFEm9darIwSe/HiHKctK1ITjG3IJERKRRUyiSeuu/m1IoLsgl2JLv2hAUbW5BIiLSqNWLUPTqq6/Stm1b/Pz8SEhIYO3atZV63aJFi7BYLIwePbrM9ttuuw2LxVLmdtVVV9VC5VKbFq5J/q2XyKcZ+AWbW5CIiDRqXmYXsHjxYqZOncr8+fNJSEhg3rx5jBgxgp07dxIREXHW1x04cICHH36Yiy++uMLnr7rqKt566y33Y19fX4/XLp5lGAZ7juby4+4Mfth9jKRDmQyxlYQi9RKJiEgtMz0UzZ07l0mTJjFx4kQA5s+fz9KlS1mwYAGPPfZYha9xOByMHz+emTNn8uOPP5KZmVluH19fX6KiomqzdPGA47mF/LQng592Z/Dj7gzSsgvKPP+HzlbYDwQrFImISO0yNRQVFRWxfv16pk2b5t5mtVoZNmwYq1atOuvrZs2aRUREBHfccQc//vhjhfusWLGCiIgIwsLCuOKKK3j22Wdp0aJFhfsWFhZSWFjofpydnQ2A3W7HbrdX56OdVenxPH3chqKw2MmG5JP8tOc4P+89ztaUnDLP+3pZ6R8XxpCOLbioQwu679sG+8HZLBpHDdqsqbe7GdTm5lC7m0Ptbo4z272m7W9qKMrIyMDhcBAZGVlme2RkJDt27KjwNT/99BNvvvkmSUlJZz3uVVddxZgxY2jXrh179+7l8ccf5+qrr2bVqlXYbLZy+8+ePZuZM2eW2/71118TEBBQtQ9VScuXL6+V49Y3hgFpp2BHpoWdWRb2ZFuwO8tegDE2wKBLiEGXUIP2QcX42NIhO539v0KzQ6tpD+w5ms/2L7+scT1Npd3rE7W5OdTu5lC7m6O03fPz82t0HNNPn1VFTk4Ot9xyC2+88Qbh4eFn3W/s2LHu+7169SI+Pp4OHTqwYsUKhg4dWm7/adOmMXXqVPfj7OxsWrduzZVXXklwsGcH99rtdpYvX87w4cPx9vb26LHri+O5hfy89wQ/7T3Oyj3HSc8pLPN8y2Y+7p6gCzu0oGXQ2cd72T5eDBnQoc8Q2vUfWe2amkK71zdqc3Oo3c2hdjfHme1eeqanukwNReHh4dhsNtLT08tsT09Pr3A80N69ezlw4ACjRo1yb3M6nQB4eXmxc+dOOnToUO517du3Jzw8nD179lQYinx9fSsciO3t7V1rX+7aPHZtMgyDE3lFpGYVkJZVQGp2AWlZp357nFXA/oy8Mq/x9bKS0L4Fl3QKZ0incLpEBmGxVHK5jlzX1axtoa2weaC9Gmq7N2Rqc3M0tHY3DIPi4mIcDofZpVSLw+HAy8sLh8OB1VovJnY3SjabDS8vr3K/Q0q/7zX9zpsainx8fOjXrx+JiYnuafVOp5PExESmTJlSbv+uXbuyefPmMtuefPJJcnJyeOmll2jdunWF73P48GGOHz9OdLQG656Lw2mQkVtYEnDKBh1XADpFelYhRQ7neY/VPTqYizuHc0mnlvSLC8PPu/xpy0rJTnX91EBrkUarqKiI1NTUGp/6MJNhGERFRXHo0KHK/6dPqiUgIIDo6Gh8fHw8fmzTT59NnTqVCRMm0L9/fwYOHMi8efPIy8tzz0a79dZbiY2NZfbs2fj5+dGzZ88yrw8NDQVwb8/NzWXmzJnccMMNREVFsXfvXh555BE6duzIiBEj6vSz1XeGYbD+4EneXXWQXw6cID2nEIfTOO/rLBYIb+ZLdIgfUcF+RIW4bq7H/nSKbEZ4Mw9cAsFRDLklvYhBupq1SGPkdDrZv38/NpuNmJgYfHx8GmSocDqd5Obm0qxZM/UU1RLDMCgqKuLYsWPs37+fTp06efw9TA9FN910E8eOHWP69OmkpaXRp08fli1b5h58nZycXKUvmM1mY9OmTbzzzjtkZmYSExPDlVdeyTPPPKNrFZUosDtYsjGFd1YeYGtK2fOvNquFyCBfd9CJCvZ3hZ3S0BPiR0SQHz5edfCXPu8oGA6w2KDZ2a9ZJSINV1FREU6nk9atW9faxJa64HQ6KSoqws/PT6GoFvn7++Pt7c3BgwcpKiqqcPJUTZgeigCmTJlS4ekycE2tP5e33367zGN/f3+++uorD1XWuBw+mc/7q5NZvC6Zk/muaYu+XlZG94llzAWxtA0PJLyZLzZrPflfWumps6AosHr2iy8i9YuChFRWbX5X6kUoktpjGAar9h7nnVUHWL4tndKzY7Gh/twyOI6b+rcmLNDz52U9IifF9VNXsxYRkTqgUNRI5RcV88mGI7y76gC70nPd2y/q2IIJg9sytFtk/ekROhsNshYRkTqkUNTIHMjI473VB/n3L4fIKSgGIMDHxpgLYpkwuC2dIoNMrrAK3D1FGmQtIiK1T6GoEXA6DX7YfYx3Vh5gxa5jGCWnyNq2CODWwW35ff9WBPs1nOuVuKmnSERE6pBCUQOWXWDnP+sP8+6qg2UumHhZl5ZMuLAtl3ZqibW+nyI7F/UUiYhUid1ub1AX7axvNNy/gfpkw2EGP5fIzP9uY39GHkG+Xtx+UTtWPHwZb08cyOVdIhp2IALILglFwQpFIk2JYRjkFxWbcjOM81+r7XTLli1jyJAhNG/enPbt2zNq1Cj27t3rfv7w4cOMGzeO5s2bExgYSP/+/VmzZo37+f/+978MGDAAPz8/wsPDuf76693PWSwWPvvsszLvFxoa6p51feDAASwWC4sXL+bSSy/Fz8+PDz74gOPHjzNu3DhiY2MJCAigV69efPjhh2WO43Q6mTNnDh07dsTX15c2bdrw17/+FYArrrii3IzwY8eO4ePjQ2JiYpXap6FRT1EDtOVIFo/9ZzNFDiedIppx64VtGdM3lkDfRvTHaRinnT5TKBJpSk7ZHXSfbs6lVbbNGkGAT+X/Lc3Ly2Pq1Kn07NmT9PR05syZw/XXX09SUhL5+flceumlxMbGsmTJEqKiotiwYYN7eaqlS5dy/fXX88QTT/Duu+9SVFTEl9VY+Pqxxx7jhRdeoG/fvvj5+VFQUEC/fv149NFHCQ4OZunSpdxyyy106NCBgQMHAq41P9944w1efPFFhgwZQmpqqnsh9jvvvJMpU6bwwgsvuK/v9/777xMbG8sVV1xR5foakkb0W7RpyCss5v4Pf6XI4WR490hev6Vfg7z663kVZoO95JSgpuSLSD11ww03AK6el4iICN58800iIyPZtm0bK1eu5NixY6xbt47mzZsD0LFjR/dr//rXvzJ27Fhmzpzp3ta7d+8q1/Dggw8yZsyYMtsefvhh9/377ruPr776in//+98MHDjQvTTWP//5TyZMmABAhw4dGDJkCABjxoxhypQpfP7559x4442A65qAt912W+P8fXMahaK65CiG4kKsTjsUF4Ll/GuInWnWZ5s4nJFJm2A/5lzXBYujqBYKrQcyk10//ULAp+Fe5VZEqs7f28a2WeYsy+RfxXUad+/ezfTp01mzZg0ZGRnuXqDk5GSSkpLo27evOxCdKSkpiUmTJtW45v79+5d57HA4eO655/j3v//NkSNHKCoqorCw0H3F8O3bt1NYWFjhAukAfn5+3HLLLSxYsIAbb7yRDRs2sGXLFpYsWVLjWus7haK6tPJlvBNnMgpgY/UO8Xfg735AEfCixyqrvzTIWqTJsVgsVTqFZaZRo0YRFxfH//3f/xEcHExAQADx8fEUFRXh7+9/ztee73mLxVJujJPdbi+3X2BgYJnHzz//PC+99BLz5s2jV69eBAYG8uCDD1JUVFSp9wXXKbQ+ffpw+PBh3nrrLa644gri4uLO+7qGTgOtpX7rcrXZFYiIVOj48ePs3LmTJ598kqFDh9KlSxdOnjzpfj4+Pp6kpCROnDhR4evj4+PPOXC5ZcuWpKamuh/v3r2b/Pz889b1888/c9111/HHP/6R3r170759e3bt2uV+vlOnTvj7+5/zvXv16kX//v154403WLhwIbfffvt537cxaBhRvLEYdC/2PhP4evnXXDn8Sry9K9f8RcVObl2wlq0p2VzQJow3J/TDy9YE8qzFCr4N6GKTItKkhIWF0aJFC15//XUiIyPZsWMHzz77rPv5cePG8dxzzzF69Ghmz55NdHQ0v/76KzExMQwePJgZM2YwdOhQOnTowNixYykuLubLL7/k0UcfBVyzwP75z38yePBgHA4Hjz76aKWm23fq1ImPP/6YlStXEhYWxty5c0lPT6d79+6A6/TYo48+yiOPPIKPjw8XXXQRx44dY+vWrdxxxx3u45QOuA4MDCwzK64xUyiqS95+gI1iWwD4BUMlryXxwpfbWZ1STIh/CLNvvgivwPN3fYqISO2yWq0sWrSI+++/n/j4eDp27Mgrr7zinqHl4+PD119/zZ///GdGjhxJcXEx3bt359VXXwXgsssu46OPPuKZZ57hb3/7G8HBwVxyySXu47/wwgtMnDiRiy++mJiYGF566SXWr19/3rqefPJJ9u3bx4gRIwgICOCuu+5i9OjRZGVlufd56qmn8PLyYvr06aSkpBAdHc3dd99d5jjjxo3jwQcfZNy4cfj5+Xmiyeo9haJ67vtdx/i/H/YBMOf38cSEKhCJiNQXw4YNY9u2bTidTrKzswkODi4zDiguLo6PP/74rK8fM2ZMuZljpWJiYvjqq7KXJsjMzHTfb9u2bYXXVWrevHm56xudyWq18sQTT/DEE0+cdZ+MjAwKCgrK9B41dgpF9djRnAL+/O8kAG4ZFMeIHlHmFiQiIo2e3W7n+PHjPPnkkwwaNIgLLrjA7JLqTBMYmNIwOZ0Gf/73RjJyi+gaFcQT13QzuyQREWkCfv75Z6Kjo1m3bh3z5883u5w6pZ6ieur1H/fx4+4M/Lyt/PPmvvhV8doZIiIi1XHZZZdVebmTxkI9RfXQr8kn+cdXOwF4elQPOkZoBpaIiEhtUyiqZ7IL7Ny/6FeKnQbXxEdz04DWZpckIiLSJCgU1SOGYfDEp1s4dOIUsaH+PHd9r0a/zoyIiEh9oVBUj3z0y2H+uzEFm9XCy+P6EuJfuesYiYiISM0pFNUTe47mMGPJVgCmDu9Mv7gwkysSERFpWhSK6oECu4MpC3/llN3BRR1bcM+lHcwuSUREpMlRKKoH/va/HexIy6FFoA8v3tgHq1XjiEREGru2bdsyb948s8uQ0ygUmWz5tnTeXnkAgH/c2JuI4KaxvoyIiEh9o1BkotSsU/zl440A3DmkHZd3iTC5IhERkfNzOBw4nU6zy/A4hSKTOJwGDy5KIjPfTq/YEB65qqvZJYmI1A+GAUV55twqeSXn119/nZiYmHLBYPTo0dx+++3s3buX6667jsjISJo1a8aAAQP45ptvqt0kc+fOpVevXgQGBtK6dWvuvfdecnNzy+zz888/c9lllxEQEEBYWBgjRozg5MmTADidTubMmUPHjh3x9fWlTZs2/PWvfwVgxYoVWCyWMovNJiUlYbFYOHDgAABvv/02oaGhLFmyhO7du+Pr60tycjLr1q1j+PDhhIeHExISwqWXXsqGDRvK1JWZmcmf/vQnIiMj8fPzo2fPnnzxxRfk5eURHBxcbsHczz77jMDAQHJycqrdXtWlZT5M8q/v97Fm/wkCfWy8PK4vPl7KpyIiANjz4bkYc9778RTwCTzvbn/4wx+47777+O677xg6dCgAJ0+e5KuvvuLLL78kNzeXkSNH8te//hVfX1/effddRo0axc6dO2nTpk2Vy7Jarbz88su0a9eOffv2ce+99/LII4/wr3/9C3CFmKFDh3L77bfz0ksv4eXlxXfffYfD4QBg2rRpvPHGG7z44osMGTKE1NRUduzYUaUa8vPz+fvf/87/+3//jxYtWhAREcG+ffuYMGECr7zyCoZh8MILLzBy5Eh2795NUFAQTqeTq6++mpycHN5//306dOjAtm3bsNlsBAYGMnbsWN566y1+//vfu9+n9HFQUN2v5qBQZIK92fDP1XsBeGZ0T9qFn/8voIiI1B9hYWFcffXVLFy40B2KPv/8c8LDw7n88suxWq307t3bvf8zzzzDp59+ypIlS5gyZUqV3+/BBx9032/bti3PPvssd999tzsUzZkzh/79+7sfA/To0QOAnJwcXnrpJf75z38yYcIEADp06MCQIUOqVIPdbudf//pXmc91xRVXlNnn9ddfJzQ0lO+//55rr72Wb775hrVr17J9+3Y6d+4MQPv27d3733nnnVx44YWkpqYSHR3N0aNH+fLLL2vUq1YTCkV1LDPfzru7bTgNGNM3ljEXtDK7JBGR+sU7wNVjY9Z7V9L48eOZNGkS//rXv/D29uajjz7ipptuwmq1kpuby9NPP83SpUtJTU2luLiYU6dOkZycXK2yvvnmG2bPns2OHTvIzs6muLiYgoIC8vPzCQgIICkpiT/84Q8Vvnb79u0UFha6w1t1+fj4EB8fX2Zbeno6Tz75JCtWrODo0aM4HA7y8/PdnzMpKYlWrVq5A9GZBg4cSI8ePXjnnXd47LHHeP/994mLi+OSSy6pUa3VpXM2dcgwDB7/bCuZRRbimgcwa3RPs0sSEal/LBbXKSwzblVYWmnUqFEYhsHSpUs5dOgQq1at4uabbwbg4Ycf5tNPP+W5557jxx9/JCkpiV69elFUVFTl5jhw4ADXXnst8fHx/Oc//2H9+vW8+uqrAO7j+fv7n/X153oOXKfmwPU7qpTdbq/wOGcuPTVhwgSSkpJ46aWXWLlyJUlJSbRo0aJSdZW68847efvttwHXqbOJEyeatsSVQlEden/1QZZvP4rNYjDvxnia+aqjTkSkofLz82PMmDF88MEHLFq0iE6dOnHBBRcArkHPt912G9dffz29evUiKirKPWi5qtavX4/T6eSFF15g0KBBdO7cmZSUsj1p8fHxJCYmVvj6Tp064e/vf9bnW7ZsCUBqaqp7W1JSUqVq+/nnn7n//vsZOXIkPXr0wNfXl4yMjDJ1HT58mF27dp31GH/84x85ePAgL7/8Mtu2bXOf4jODQlFdsljwtlkY1cZJz9hgs6sREZEaGj9+PEuXLuWtt94qc/qqU6dOfPLJJyQlJbFx40Zuvvnmak9h79ixI3a7nVdeeYV9+/bx3nvvMX/+/DL7TJs2jXXr1nHvvfeyadMmduzYwWuvvUZGRgZ+fn48+uijPPLII7z77rvs3buX1atX8+abb7qP37p1a55++ml2797N0qVLeeGFFypVW6dOnXjvvffYvn07a9asYfz48WV6hy699FIuueQSbrjhBpYvX87+/fv53//+x7Jly9z7hIWFMWbMGP7yl79w5ZVX0qqVecNKFIrq0C2D4lg65UIui67clE8REanfrrjiCpo3b87OnTvLzKCaO3cuYWFhXHjhhYwaNYoRI0a4e5Gqqnfv3sydO5e///3v9OzZkw8++IDZs2eX2adz5858/fXXbNy4kYEDBzJ48GA+//xzvLxcZySeeuop/vznPzN9+nS6devGTTfdxNGjRwHw9vbmww8/ZMeOHcTHx/P3v/+dZ599tlK1vfnmm5w8eZILLriAW265hfvvv5+IiLLX3PvPf/7DgAEDGDduHN27d+eRRx5xz4ordccdd1BUVMTtt99erTbyFIthVPKiDE1IdnY2ISEhZGVlERzs2R4du93Ol19+yciRI/H29vboseXs1O51T21ujobW7gUFBezfv5927drh59dwr+jvdDrJzs4mODjYPUZHKu+9997joYceIiUlBR8fn3Pue/p3xmazlfm+1/T3twa1iIiIiCny8/NJTU3lb3/7G3/605/OG4hqm+KsiIiIiT744AOaNWtW4a30WkON1Zw5c+jatStRUVFMmzbN7HLUUyQiImKm3/3udyQkJFT4XEM4BVoTTz/9NE8//bTZZbgpFImIiJgoKCjIlCUtpDydPhMREdNpzo9UVm1+VxSKRETENKWnh/Lz802uRBqK0u9KbZxa1OkzERExjc1mIzQ01H3NnICAANOWeKgJp9NJUVERBQUFmpJfSwzDID8/n6NHjxIaGorNZqv2BTHPRqFIRERMFRUVBeAORg2RYRicOnWqwvXBxLNCQ0Pd3xlPUygSERFTWSwWoqOjiYiIqHAh0obAbrfzww8/cMkllzT6GWNm8vb2xmaz1drx60UoevXVV3n++edJS0ujd+/evPLKKwwcOPC8r1u0aBHjxo3juuuu47PPPnNvNwyDGTNm8MYbb5CZmclFF13Ea6+9RqdOnWrxU4iISE3YbLZa/YVXm2w2G8XFxfj5+SkUNWCmn/hcvHgxU6dOZcaMGWzYsIHevXszYsSI83ajHjhwgIcffpiLL7643HNz5szh5ZdfZv78+axZs4bAwEBGjBhBQUFBbX0MERERaeBMD0Vz585l0qRJTJw4ke7duzN//nwCAgJYsGDBWV/jcDgYP348M2fOpH379mWeMwyDefPm8eSTT3LdddcRHx/Pu+++S0pKSpneJBEREZHTmXr6rKioiPXr15e5tLfVamXYsGGsWrXqrK+bNWsWERER3HHHHfz4449lntu/fz9paWkMGzbMvS0kJISEhARWrVrF2LFjyx2vsLCQwsJC9+Ps7GzAdY7Y0+e3S4/XUM+bN1Rq97qnNjeH2t0candznNnuNW1/U0NRRkYGDoeDyMjIMtsjIyPZsWNHha/56aefePPNN0lKSqrw+bS0NPcxzjxm6XNnmj17NjNnziy3/bPPPiMgIOB8H6NaPv/881o5rpyb2r3uqc3NoXY3h9rdHKXtXnoNo+pe4LFeDLSurJycHG655RbeeOMNwsPDPXbcadOmMXXqVPfjI0eO0L17d+68806PvYeIiIjUjZycHEJCQqr8OlNDUXh4ODabjfT09DLb09PTK7wGwd69ezlw4ACjRo1ybyu9cJOXlxc7d+50vy49PZ3o6Ogyx+zTp0+Fdfj6+uLr6+t+3KxZMw4dOkRQUJDHrzeRnZ1N69atOXToEMHBwR49tpyd2r3uqc3NoXY3h9rdHGe2u2EY5OTkEBMTU63jmRqKfHx86NevH4mJiYwePRpwhZzExESmTJlSbv+uXbuyefPmMtuefPJJcnJyeOmll2jdujXe3t5ERUWRmJjoDkHZ2dmsWbOGe+65p1J1Wa1WWrVqVaPPdj7BwcH6i2MCtXvdU5ubQ+1uDrW7OU5v9+r0EJUy/fTZ1KlTmTBhAv3792fgwIHMmzePvLw8Jk6cCMCtt95KbGwss2fPxs/Pj549e5Z5fWhoKECZ7Q8++CDPPvssnTp1ol27djz11FPExMS4g5eIiIjImUwPRTfddBPHjh1j+vTppKWl0adPH5YtW+YeKJ2cnFzldWQeeeQR8vLyuOuuu8jMzGTIkCEsW7YMPz+/2vgIIiIi0giYHooApkyZUuHpMoAVK1ac87Vvv/12uW0Wi4VZs2Yxa9YsD1TnWb6+vsyYMaPMGCapfWr3uqc2N4fa3Rxqd3N4ut0tRnXnrYmIiIg0IqZf0VpERESkPlAoEhEREUGhSERERARQKBIREREBFIrq1Kuvvkrbtm3x8/MjISGBtWvXml1So/b0009jsVjK3Lp27Wp2WY3ODz/8wKhRo4iJicFisfDZZ5+Ved4wDKZPn050dDT+/v4MGzaM3bt3m1NsI3K+dr/tttvKff+vuuoqc4ptRGbPns2AAQMICgoiIiKC0aNHs3PnzjL7FBQUMHnyZFq0aEGzZs244YYbyq3cIFVTmXa/7LLLyn3n77777iq9j0JRHVm8eDFTp05lxowZbNiwgd69ezNixAiOHj1qdmmNWo8ePUhNTXXffvrpJ7NLanTy8vLo3bs3r776aoXPz5kzh5dffpn58+ezZs0aAgMDGTFiBAUFBXVcaeNyvnYHuOqqq8p8/z/88MM6rLBx+v7775k8eTKrV69m+fLl2O12rrzySvLy8tz7PPTQQ/z3v//lo48+4vvvvyclJYUxY8aYWHXDV5l2B5g0aVKZ7/ycOXOq9kaG1ImBAwcakydPdj92OBxGTEyMMXv2bBOratxmzJhh9O7d2+wymhTA+PTTT92PnU6nERUVZTz//PPubZmZmYavr6/x4YcfmlBh43RmuxuGYUyYMMG47rrrTKmnKTl69KgBGN9//71hGK7vt7e3t/HRRx+599m+fbsBGKtWrTKrzEbnzHY3DMO49NJLjQceeKBGx1VPUR0oKipi/fr1DBs2zL3NarUybNgwVq1aZWJljd/u3buJiYmhffv2jB8/nuTkZLNLalL2799PWlpame9+SEgICQkJ+u7XgRUrVhAREUGXLl245557OH78uNklNTpZWVkANG/eHID169djt9vLfOe7du1KmzZt9J33oDPbvdQHH3xAeHg4PXv2ZNq0aeTn51fpuPXiitaNXUZGBg6Hw710SanIyEh27NhhUlWNX0JCAm+//TZdunQhNTWVmTNncvHFF7NlyxaCgoLMLq9JSEtLA6jwu1/6nNSOq666ijFjxtCuXTv27t3L448/ztVXX82qVauw2Wxml9coOJ1OHnzwQS666CL3+ptpaWn4+Pi41+Uspe+851TU7gA333wzcXFxxMTEsGnTJh599FF27tzJJ598UuljKxRJo3X11Ve778fHx5OQkEBcXBz//ve/ueOOO0ysTKT2jR071n2/V69exMfH06FDB1asWMHQoUNNrKzxmDx5Mlu2bNFYxTp2tna/66673Pd79epFdHQ0Q4cOZe/evXTo0KFSx9bpszoQHh6OzWYrN/sgPT2dqKgok6pqekJDQ+ncuTN79uwxu5Qmo/T7re+++dq3b094eLi+/x4yZcoUvvjiC7777jtatWrl3h4VFUVRURGZmZll9td33jPO1u4VSUhIAKjSd16hqA74+PjQr18/EhMT3ducTieJiYkMHjzYxMqaltzcXPbu3Ut0dLTZpTQZ7dq1Iyoqqsx3Pzs7mzVr1ui7X8cOHz7M8ePH9f2vIcMwmDJlCp9++inffvst7dq1K/N8v3798Pb2LvOd37lzJ8nJyfrO18D52r0iSUlJAFX6zuv0WR2ZOnUqEyZMoH///gwcOJB58+aRl5fHxIkTzS6t0Xr44YcZNWoUcXFxpKSkMGPGDGw2G+PGjTO7tEYlNze3zP/E9u/fT1JSEs2bN6dNmzY8+OCDPPvss3Tq1Il27drx1FNPERMTw+jRo80ruhE4V7s3b96cmTNncsMNNxAVFcXevXt55JFH6NixIyNGjDCx6oZv8uTJLFy4kM8//5ygoCD3OKGQkBD8/f0JCQnhjjvuYOrUqTRv3pzg4GDuu+8+Bg8ezKBBg0yuvuE6X7vv3buXhQsXMnLkSFq0aMGmTZt46KGHuOSSS4iPj6/8G9Vo7ppUySuvvGK0adPG8PHxMQYOHGisXr3a7JIatZtuusmIjo42fHx8jNjYWOOmm24y9uzZY3ZZjc53331nAOVuEyZMMAzDNS3/qaeeMiIjIw1fX19j6NChxs6dO80tuhE4V7vn5+cbV155pdGyZUvD29vbiIuLMyZNmmSkpaWZXXaDV1GbA8Zbb73l3ufUqVPGvffea4SFhRkBAQHG9ddfb6SmpppXdCNwvnZPTk42LrnkEqN58+aGr6+v0bFjR+Mvf/mLkZWVVaX3sZS8mYiIiEiTpjFFIiIiIigUiYiIiAAKRSIiIiKAQpGIiIgIoFAkIiIiAigUiYiIiAAKRSIiIiKAQpGIiIgIoFAkIlIpFouFzz77zOwyRKQWKRSJSL132223YbFYyt2uuuoqs0sTkUZEC8KKSINw1VVX8dZbb5XZ5uvra1I1ItIYqadIRBoEX19foqKiytzCwsIA16mt1157jauvvhp/f3/at2/Pxx9/XOb1mzdv5oorrsDf358WLVpw1113kZubW2afBQsW0KNHD3x9fYmOjmbKlCllns/IyOD6668nICCATp06sWTJktr90CJSpxSKRKRReOqpp7jhhhvYuHEj48ePZ+zYsWzfvh2AvLw8RowYQVhYGOvWreOjjz7im2++KRN6XnvtNSZPnsxdd93F5s2bWbJkCR07dizzHjNnzuTGG29k06ZNjBw5kvHjx3PixIk6/ZwiUosMEZF6bsKECYbNZjMCAwPL3P76178ahmEYgHH33XeXeU1CQoJxzz33GIZhGK+//roRFhZm5Obmup9funSpYbVajbS0NMMwDCMmJsZ44oknzloDYDz55JPux7m5uQZg/O9///PY5xQRc2lMkYg0CJdffjmvvfZamW3Nmzd33x88eHCZ5wYPHkxSUhIA27dvp3fv3gQGBrqfv+iii3A6nezcuROLxUJKSgpDhw49Zw3x8fHu+4GBgQQHB3P06NHqfiQRqWcUikSkQQgMDCx3OstT/P39K7Wft7d3mccWiwWn01kbJYmICTSmSEQahdWrV5d73K1bNwC6devGxo0bycvLcz//888/Y7Va6dKlC0FBQbRt25bExMQ6rVlE6hf1FIlIg1BYWEhaWlqZbV5eXoSHhwPw0Ucf0b9/f4YMGcIHH3zA2rVrefPNNwEYP348M2bMYMKECTz99NMcO3aM++67j1tuuYXIyEgAnn76ae6++24iIiK4+uqrycnJ4eeff+a+++6r2w8qIqZRKBKRBmHZsmVER0eX2dalSxd27NgBuGaGLVq0iHvvvZfo6Gg+/PBDunfvDkBAQABfffUVDzzwAAMGDCAgIIAbbriBuXPnuo81YcIECgoKePHFF3n44YcJDw/n97//fd19QBExncUwDMPsIkREasJisfDpp58yevRos0sRkQZMY4pEREREUCgSERERATSmSEQaAY0CEBFPUE+RiIiICApFIiIiIoBCkYiIiAigUCQiIiICKBSJiIiIAApFIiIiIoBCkYiIiAigUCQiIiICwP8HgeIhqJiJ8dgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e19e9916-5d05-451e-a047-655b43303c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_network.save('63_test.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f066cdd-9b61-4ef3-a67a-a81d69926354",
   "metadata": {},
   "source": [
    "### For testing the model\n",
    "\n",
    "Will be deleted before pushing to main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8f3390c-5e30-40db-ae9e-a50afe44866c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 14:10:55.187703: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826931928 exceeds 10% of free system memory.\n",
      "2024-04-14 14:10:56.006167: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826931928 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.4031 - loss: 1.2171 - val_accuracy: 0.4345 - val_loss: 1.0190 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4325 - loss: 1.0309 - val_accuracy: 0.4345 - val_loss: 1.0210 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4421 - loss: 1.0282 - val_accuracy: 0.4345 - val_loss: 1.0184 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4438 - loss: 1.0235 - val_accuracy: 0.4345 - val_loss: 1.0120 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4610 - loss: 1.0130 - val_accuracy: 0.5805 - val_loss: 0.9628 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5322 - loss: 0.9460 - val_accuracy: 0.6160 - val_loss: 0.8085 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5996 - loss: 0.8581 - val_accuracy: 0.6335 - val_loss: 0.7777 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6212 - loss: 0.8181 - val_accuracy: 0.6555 - val_loss: 0.7641 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6335 - loss: 0.7954 - val_accuracy: 0.6645 - val_loss: 0.7431 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6557 - loss: 0.7598 - val_accuracy: 0.6630 - val_loss: 0.7264 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6647 - loss: 0.7391 - val_accuracy: 0.6790 - val_loss: 0.7144 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6780 - loss: 0.7225 - val_accuracy: 0.6870 - val_loss: 0.7055 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6849 - loss: 0.7089 - val_accuracy: 0.6930 - val_loss: 0.7017 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6828 - loss: 0.7035 - val_accuracy: 0.6975 - val_loss: 0.6975 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6953 - loss: 0.6902 - val_accuracy: 0.7015 - val_loss: 0.6967 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6973 - loss: 0.6843 - val_accuracy: 0.7010 - val_loss: 0.6941 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7002 - loss: 0.6757 - val_accuracy: 0.6985 - val_loss: 0.6925 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7000 - loss: 0.6746 - val_accuracy: 0.6950 - val_loss: 0.6965 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7091 - loss: 0.6647 - val_accuracy: 0.7020 - val_loss: 0.6929 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7135 - loss: 0.6588 - val_accuracy: 0.7075 - val_loss: 0.6898 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7185 - loss: 0.6463 - val_accuracy: 0.7070 - val_loss: 0.6901 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7207 - loss: 0.6448 - val_accuracy: 0.7025 - val_loss: 0.6898 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7173 - loss: 0.6482 - val_accuracy: 0.7045 - val_loss: 0.6898 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7263 - loss: 0.6382 - val_accuracy: 0.7055 - val_loss: 0.6902 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7206 - loss: 0.6435 - val_accuracy: 0.7045 - val_loss: 0.6902 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7263 - loss: 0.6329 - val_accuracy: 0.7055 - val_loss: 0.6906 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7258 - loss: 0.6325 - val_accuracy: 0.7055 - val_loss: 0.6897 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7242 - loss: 0.6344 - val_accuracy: 0.7045 - val_loss: 0.6902 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7257 - loss: 0.6309 - val_accuracy: 0.7045 - val_loss: 0.6899 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7243 - loss: 0.6305 - val_accuracy: 0.7090 - val_loss: 0.6915 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7231 - loss: 0.6352 - val_accuracy: 0.7070 - val_loss: 0.6904 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7299 - loss: 0.6235 - val_accuracy: 0.7110 - val_loss: 0.6913 - learning_rate: 1.0000e-04\n",
      "Epoch 32: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6427 - loss: 0.8240\n",
      "1 0.6377401351928711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 14:11:35.654520: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1826931928 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.4070 - loss: 1.2057 - val_accuracy: 0.4345 - val_loss: 1.0217 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4398 - loss: 1.0280 - val_accuracy: 0.4345 - val_loss: 1.0199 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4454 - loss: 1.0253 - val_accuracy: 0.4345 - val_loss: 1.0179 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4455 - loss: 1.0214 - val_accuracy: 0.4345 - val_loss: 1.0170 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4514 - loss: 1.0157 - val_accuracy: 0.4485 - val_loss: 0.9930 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4971 - loss: 0.9756 - val_accuracy: 0.6050 - val_loss: 0.8341 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5865 - loss: 0.8695 - val_accuracy: 0.6300 - val_loss: 0.7759 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6180 - loss: 0.8212 - val_accuracy: 0.6665 - val_loss: 0.7494 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6348 - loss: 0.7905 - val_accuracy: 0.6660 - val_loss: 0.7295 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6572 - loss: 0.7556 - val_accuracy: 0.6775 - val_loss: 0.7122 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6738 - loss: 0.7296 - val_accuracy: 0.6880 - val_loss: 0.7068 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6808 - loss: 0.7135 - val_accuracy: 0.6850 - val_loss: 0.7032 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6889 - loss: 0.7015 - val_accuracy: 0.6915 - val_loss: 0.6990 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6915 - loss: 0.6959 - val_accuracy: 0.6905 - val_loss: 0.6962 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6974 - loss: 0.6790 - val_accuracy: 0.6945 - val_loss: 0.6940 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6987 - loss: 0.6752 - val_accuracy: 0.6990 - val_loss: 0.6937 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7038 - loss: 0.6707 - val_accuracy: 0.7030 - val_loss: 0.6930 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7051 - loss: 0.6653 - val_accuracy: 0.7025 - val_loss: 0.6930 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7046 - loss: 0.6676 - val_accuracy: 0.7060 - val_loss: 0.6910 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7148 - loss: 0.6520 - val_accuracy: 0.7025 - val_loss: 0.6911 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7220 - loss: 0.6409 - val_accuracy: 0.7045 - val_loss: 0.6890 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7197 - loss: 0.6382 - val_accuracy: 0.7055 - val_loss: 0.6900 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7228 - loss: 0.6321 - val_accuracy: 0.7050 - val_loss: 0.6898 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7207 - loss: 0.6401 - val_accuracy: 0.7060 - val_loss: 0.6902 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7251 - loss: 0.6345 - val_accuracy: 0.7080 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7272 - loss: 0.6328 - val_accuracy: 0.7070 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 26: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6427 - loss: 0.8199\n",
      "2 0.6378215551376343\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.4109 - loss: 1.1644 - val_accuracy: 0.4345 - val_loss: 1.0230 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4409 - loss: 1.0307 - val_accuracy: 0.4345 - val_loss: 1.0199 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4450 - loss: 1.0216 - val_accuracy: 0.4345 - val_loss: 1.0202 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4491 - loss: 1.0217 - val_accuracy: 0.4345 - val_loss: 1.0156 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4557 - loss: 1.0155 - val_accuracy: 0.5215 - val_loss: 0.9742 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5241 - loss: 0.9526 - val_accuracy: 0.6150 - val_loss: 0.8016 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6029 - loss: 0.8474 - val_accuracy: 0.6480 - val_loss: 0.7671 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6275 - loss: 0.8071 - val_accuracy: 0.6595 - val_loss: 0.7419 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6445 - loss: 0.7747 - val_accuracy: 0.6705 - val_loss: 0.7224 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6600 - loss: 0.7472 - val_accuracy: 0.6815 - val_loss: 0.7101 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6785 - loss: 0.7213 - val_accuracy: 0.6845 - val_loss: 0.7038 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6775 - loss: 0.7113 - val_accuracy: 0.6915 - val_loss: 0.7006 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6877 - loss: 0.7006 - val_accuracy: 0.6965 - val_loss: 0.6982 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6914 - loss: 0.6910 - val_accuracy: 0.6970 - val_loss: 0.6953 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7005 - loss: 0.6752 - val_accuracy: 0.6975 - val_loss: 0.6954 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7008 - loss: 0.6732 - val_accuracy: 0.6925 - val_loss: 0.6990 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7057 - loss: 0.6670 - val_accuracy: 0.6995 - val_loss: 0.6937 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7136 - loss: 0.6549 - val_accuracy: 0.7040 - val_loss: 0.6907 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7138 - loss: 0.6524 - val_accuracy: 0.7025 - val_loss: 0.6911 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7194 - loss: 0.6442 - val_accuracy: 0.7060 - val_loss: 0.6899 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7209 - loss: 0.6360 - val_accuracy: 0.7030 - val_loss: 0.6893 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7273 - loss: 0.6340 - val_accuracy: 0.7045 - val_loss: 0.6901 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7258 - loss: 0.6293 - val_accuracy: 0.7055 - val_loss: 0.6915 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7235 - loss: 0.6349 - val_accuracy: 0.7060 - val_loss: 0.6896 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7300 - loss: 0.6213 - val_accuracy: 0.7060 - val_loss: 0.6908 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7239 - loss: 0.6303 - val_accuracy: 0.7080 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 26: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6382 - loss: 0.8341\n",
      "3 0.6332627534866333\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.4111 - loss: 1.2221 - val_accuracy: 0.4345 - val_loss: 1.0208 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4293 - loss: 1.0347 - val_accuracy: 0.4345 - val_loss: 1.0202 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4368 - loss: 1.0284 - val_accuracy: 0.4345 - val_loss: 1.0193 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4472 - loss: 1.0228 - val_accuracy: 0.4345 - val_loss: 1.0175 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4544 - loss: 1.0174 - val_accuracy: 0.4345 - val_loss: 1.0105 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4699 - loss: 1.0022 - val_accuracy: 0.6015 - val_loss: 0.8732 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5638 - loss: 0.9019 - val_accuracy: 0.6230 - val_loss: 0.7919 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6052 - loss: 0.8389 - val_accuracy: 0.6525 - val_loss: 0.7726 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6286 - loss: 0.8063 - val_accuracy: 0.6620 - val_loss: 0.7456 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6468 - loss: 0.7759 - val_accuracy: 0.6750 - val_loss: 0.7239 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6593 - loss: 0.7513 - val_accuracy: 0.6655 - val_loss: 0.7202 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6680 - loss: 0.7325 - val_accuracy: 0.6810 - val_loss: 0.7111 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6785 - loss: 0.7166 - val_accuracy: 0.6780 - val_loss: 0.7087 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6824 - loss: 0.7078 - val_accuracy: 0.6960 - val_loss: 0.7012 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6873 - loss: 0.6982 - val_accuracy: 0.6980 - val_loss: 0.6995 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6965 - loss: 0.6872 - val_accuracy: 0.6995 - val_loss: 0.6980 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7002 - loss: 0.6779 - val_accuracy: 0.6965 - val_loss: 0.6971 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7001 - loss: 0.6781 - val_accuracy: 0.6995 - val_loss: 0.6955 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7021 - loss: 0.6690 - val_accuracy: 0.6995 - val_loss: 0.6933 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7070 - loss: 0.6629 - val_accuracy: 0.7000 - val_loss: 0.6929 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7143 - loss: 0.6498 - val_accuracy: 0.6985 - val_loss: 0.6943 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7169 - loss: 0.6465 - val_accuracy: 0.7020 - val_loss: 0.6915 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7230 - loss: 0.6438 - val_accuracy: 0.7005 - val_loss: 0.6916 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7189 - loss: 0.6482 - val_accuracy: 0.7020 - val_loss: 0.6927 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7249 - loss: 0.6364 - val_accuracy: 0.7005 - val_loss: 0.6915 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7217 - loss: 0.6402 - val_accuracy: 0.7035 - val_loss: 0.6939 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7256 - loss: 0.6268 - val_accuracy: 0.7020 - val_loss: 0.6921 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7198 - loss: 0.6375 - val_accuracy: 0.7040 - val_loss: 0.6919 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7246 - loss: 0.6370 - val_accuracy: 0.7035 - val_loss: 0.6919 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7269 - loss: 0.6300 - val_accuracy: 0.7030 - val_loss: 0.6924 - learning_rate: 1.0000e-04\n",
      "Epoch 30: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6455 - loss: 0.8219\n",
      "4 0.6401009559631348\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.4122 - loss: 1.1788 - val_accuracy: 0.4345 - val_loss: 1.0199 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4352 - loss: 1.0338 - val_accuracy: 0.4345 - val_loss: 1.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4452 - loss: 1.0249 - val_accuracy: 0.4345 - val_loss: 1.0197 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4460 - loss: 1.0243 - val_accuracy: 0.4345 - val_loss: 1.0114 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4559 - loss: 1.0111 - val_accuracy: 0.5805 - val_loss: 0.9507 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5380 - loss: 0.9285 - val_accuracy: 0.6145 - val_loss: 0.8075 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5998 - loss: 0.8447 - val_accuracy: 0.6455 - val_loss: 0.7797 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6203 - loss: 0.8147 - val_accuracy: 0.6595 - val_loss: 0.7568 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6415 - loss: 0.7802 - val_accuracy: 0.6680 - val_loss: 0.7286 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6607 - loss: 0.7537 - val_accuracy: 0.6805 - val_loss: 0.7131 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6736 - loss: 0.7266 - val_accuracy: 0.6815 - val_loss: 0.7092 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6834 - loss: 0.7153 - val_accuracy: 0.6840 - val_loss: 0.7050 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6835 - loss: 0.7026 - val_accuracy: 0.6960 - val_loss: 0.7000 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6915 - loss: 0.6966 - val_accuracy: 0.6990 - val_loss: 0.6984 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6946 - loss: 0.6868 - val_accuracy: 0.6965 - val_loss: 0.6979 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6975 - loss: 0.6821 - val_accuracy: 0.7000 - val_loss: 0.6950 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6973 - loss: 0.6797 - val_accuracy: 0.7015 - val_loss: 0.6930 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7075 - loss: 0.6645 - val_accuracy: 0.7050 - val_loss: 0.6934 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7099 - loss: 0.6547 - val_accuracy: 0.7055 - val_loss: 0.6933 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7145 - loss: 0.6534 - val_accuracy: 0.7020 - val_loss: 0.6939 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7227 - loss: 0.6406 - val_accuracy: 0.7060 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7192 - loss: 0.6403 - val_accuracy: 0.7055 - val_loss: 0.6901 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7202 - loss: 0.6412 - val_accuracy: 0.7075 - val_loss: 0.6923 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7222 - loss: 0.6349 - val_accuracy: 0.7035 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7253 - loss: 0.6334 - val_accuracy: 0.7055 - val_loss: 0.6906 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7225 - loss: 0.6336 - val_accuracy: 0.7050 - val_loss: 0.6926 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7288 - loss: 0.6278 - val_accuracy: 0.7020 - val_loss: 0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 27: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6408 - loss: 0.8300\n",
      "5 0.6358677744865417\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.3968 - loss: 1.2765 - val_accuracy: 0.4345 - val_loss: 1.0189 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4311 - loss: 1.0364 - val_accuracy: 0.4345 - val_loss: 1.0190 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4442 - loss: 1.0237 - val_accuracy: 0.4345 - val_loss: 1.0198 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4451 - loss: 1.0220 - val_accuracy: 0.4345 - val_loss: 1.0180 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4504 - loss: 1.0172 - val_accuracy: 0.4345 - val_loss: 1.0136 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4611 - loss: 1.0111 - val_accuracy: 0.5735 - val_loss: 0.9533 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5430 - loss: 0.9345 - val_accuracy: 0.6145 - val_loss: 0.8012 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6053 - loss: 0.8482 - val_accuracy: 0.6475 - val_loss: 0.7712 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6255 - loss: 0.8115 - val_accuracy: 0.6650 - val_loss: 0.7457 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6384 - loss: 0.7869 - val_accuracy: 0.6705 - val_loss: 0.7239 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6618 - loss: 0.7472 - val_accuracy: 0.6755 - val_loss: 0.7127 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6679 - loss: 0.7353 - val_accuracy: 0.6855 - val_loss: 0.7087 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6780 - loss: 0.7181 - val_accuracy: 0.6835 - val_loss: 0.7057 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6818 - loss: 0.7093 - val_accuracy: 0.6890 - val_loss: 0.7016 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6864 - loss: 0.6996 - val_accuracy: 0.6980 - val_loss: 0.7004 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6921 - loss: 0.6873 - val_accuracy: 0.6945 - val_loss: 0.6973 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6974 - loss: 0.6861 - val_accuracy: 0.6960 - val_loss: 0.6954 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7021 - loss: 0.6733 - val_accuracy: 0.6955 - val_loss: 0.6935 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7068 - loss: 0.6634 - val_accuracy: 0.6980 - val_loss: 0.6925 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7090 - loss: 0.6611 - val_accuracy: 0.6995 - val_loss: 0.6917 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7161 - loss: 0.6521 - val_accuracy: 0.6995 - val_loss: 0.6909 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7144 - loss: 0.6483 - val_accuracy: 0.7005 - val_loss: 0.6918 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7174 - loss: 0.6503 - val_accuracy: 0.7010 - val_loss: 0.6916 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7191 - loss: 0.6449 - val_accuracy: 0.6995 - val_loss: 0.6919 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7223 - loss: 0.6395 - val_accuracy: 0.6995 - val_loss: 0.6907 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7197 - loss: 0.6389 - val_accuracy: 0.6990 - val_loss: 0.6906 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7202 - loss: 0.6396 - val_accuracy: 0.6995 - val_loss: 0.6907 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7229 - loss: 0.6327 - val_accuracy: 0.7020 - val_loss: 0.6908 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7219 - loss: 0.6338 - val_accuracy: 0.7015 - val_loss: 0.6907 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7270 - loss: 0.6278 - val_accuracy: 0.7020 - val_loss: 0.6914 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7266 - loss: 0.6274 - val_accuracy: 0.7020 - val_loss: 0.6908 - learning_rate: 1.0000e-04\n",
      "Epoch 31: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6430 - loss: 0.8181\n",
      "6 0.6390426754951477\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.4095 - loss: 1.1876 - val_accuracy: 0.4345 - val_loss: 1.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4353 - loss: 1.0307 - val_accuracy: 0.4345 - val_loss: 1.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4425 - loss: 1.0269 - val_accuracy: 0.4345 - val_loss: 1.0192 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4481 - loss: 1.0226 - val_accuracy: 0.4345 - val_loss: 1.0176 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4544 - loss: 1.0165 - val_accuracy: 0.4485 - val_loss: 0.9905 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4891 - loss: 0.9793 - val_accuracy: 0.6010 - val_loss: 0.8391 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5885 - loss: 0.8666 - val_accuracy: 0.6380 - val_loss: 0.7843 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6193 - loss: 0.8236 - val_accuracy: 0.6580 - val_loss: 0.7573 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6293 - loss: 0.7973 - val_accuracy: 0.6630 - val_loss: 0.7355 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6505 - loss: 0.7664 - val_accuracy: 0.6675 - val_loss: 0.7229 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6632 - loss: 0.7395 - val_accuracy: 0.6820 - val_loss: 0.7111 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6694 - loss: 0.7264 - val_accuracy: 0.6935 - val_loss: 0.7056 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6814 - loss: 0.7103 - val_accuracy: 0.6890 - val_loss: 0.7039 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6784 - loss: 0.7095 - val_accuracy: 0.6920 - val_loss: 0.7005 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6909 - loss: 0.6935 - val_accuracy: 0.6945 - val_loss: 0.6979 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6989 - loss: 0.6850 - val_accuracy: 0.6960 - val_loss: 0.6983 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7007 - loss: 0.6746 - val_accuracy: 0.6940 - val_loss: 0.6995 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7049 - loss: 0.6703 - val_accuracy: 0.6970 - val_loss: 0.6946 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7072 - loss: 0.6612 - val_accuracy: 0.6990 - val_loss: 0.6938 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7111 - loss: 0.6551 - val_accuracy: 0.7010 - val_loss: 0.6930 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7170 - loss: 0.6454 - val_accuracy: 0.6985 - val_loss: 0.6939 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7183 - loss: 0.6418 - val_accuracy: 0.7030 - val_loss: 0.6947 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7179 - loss: 0.6429 - val_accuracy: 0.7030 - val_loss: 0.6939 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7163 - loss: 0.6395 - val_accuracy: 0.6970 - val_loss: 0.6938 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7261 - loss: 0.6356 - val_accuracy: 0.7060 - val_loss: 0.6942 - learning_rate: 1.0000e-04\n",
      "Epoch 25: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6402 - loss: 0.8246\n",
      "7 0.6360306143760681\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.4014 - loss: 1.2254 - val_accuracy: 0.4345 - val_loss: 1.0197 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4343 - loss: 1.0365 - val_accuracy: 0.4345 - val_loss: 1.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4429 - loss: 1.0279 - val_accuracy: 0.4345 - val_loss: 1.0189 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4455 - loss: 1.0248 - val_accuracy: 0.4345 - val_loss: 1.0158 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4449 - loss: 1.0254 - val_accuracy: 0.4345 - val_loss: 1.0104 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4684 - loss: 1.0044 - val_accuracy: 0.5820 - val_loss: 0.9030 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5550 - loss: 0.9066 - val_accuracy: 0.6240 - val_loss: 0.7992 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6097 - loss: 0.8344 - val_accuracy: 0.6525 - val_loss: 0.7633 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6287 - loss: 0.7991 - val_accuracy: 0.6635 - val_loss: 0.7399 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6490 - loss: 0.7742 - val_accuracy: 0.6810 - val_loss: 0.7195 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6638 - loss: 0.7443 - val_accuracy: 0.6830 - val_loss: 0.7110 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6712 - loss: 0.7293 - val_accuracy: 0.6870 - val_loss: 0.7047 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6829 - loss: 0.7089 - val_accuracy: 0.6925 - val_loss: 0.7008 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6864 - loss: 0.6972 - val_accuracy: 0.6930 - val_loss: 0.6987 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6938 - loss: 0.6919 - val_accuracy: 0.6985 - val_loss: 0.6963 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6953 - loss: 0.6855 - val_accuracy: 0.6975 - val_loss: 0.6947 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7021 - loss: 0.6762 - val_accuracy: 0.7005 - val_loss: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7068 - loss: 0.6728 - val_accuracy: 0.6985 - val_loss: 0.6939 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7138 - loss: 0.6586 - val_accuracy: 0.7030 - val_loss: 0.6909 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7150 - loss: 0.6527 - val_accuracy: 0.7030 - val_loss: 0.6914 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7169 - loss: 0.6474 - val_accuracy: 0.7025 - val_loss: 0.6909 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7140 - loss: 0.6492 - val_accuracy: 0.7035 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7191 - loss: 0.6418 - val_accuracy: 0.7025 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7222 - loss: 0.6379 - val_accuracy: 0.7070 - val_loss: 0.6902 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7200 - loss: 0.6369 - val_accuracy: 0.7055 - val_loss: 0.6922 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7225 - loss: 0.6343 - val_accuracy: 0.7075 - val_loss: 0.6903 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7295 - loss: 0.6300 - val_accuracy: 0.7040 - val_loss: 0.6899 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7215 - loss: 0.6341 - val_accuracy: 0.7040 - val_loss: 0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7256 - loss: 0.6363 - val_accuracy: 0.7065 - val_loss: 0.6915 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7276 - loss: 0.6297 - val_accuracy: 0.7070 - val_loss: 0.6908 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7270 - loss: 0.6264 - val_accuracy: 0.7085 - val_loss: 0.6904 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7296 - loss: 0.6202 - val_accuracy: 0.7100 - val_loss: 0.6917 - learning_rate: 1.0000e-04\n",
      "Epoch 32: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6444 - loss: 0.8291\n",
      "8 0.6382285952568054\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.4003 - loss: 1.2789 - val_accuracy: 0.5565 - val_loss: 1.0173 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4337 - loss: 1.0362 - val_accuracy: 0.4345 - val_loss: 1.0180 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4415 - loss: 1.0258 - val_accuracy: 0.4345 - val_loss: 1.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4507 - loss: 1.0208 - val_accuracy: 0.4345 - val_loss: 1.0182 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4530 - loss: 1.0188 - val_accuracy: 0.4345 - val_loss: 1.0089 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4585 - loss: 1.0080 - val_accuracy: 0.5880 - val_loss: 0.9359 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5388 - loss: 0.9263 - val_accuracy: 0.6190 - val_loss: 0.7966 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5985 - loss: 0.8468 - val_accuracy: 0.6480 - val_loss: 0.7775 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6240 - loss: 0.8086 - val_accuracy: 0.6625 - val_loss: 0.7419 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6420 - loss: 0.7754 - val_accuracy: 0.6685 - val_loss: 0.7276 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6583 - loss: 0.7470 - val_accuracy: 0.6785 - val_loss: 0.7150 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6697 - loss: 0.7301 - val_accuracy: 0.6840 - val_loss: 0.7091 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6706 - loss: 0.7215 - val_accuracy: 0.6880 - val_loss: 0.7051 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6822 - loss: 0.7092 - val_accuracy: 0.6910 - val_loss: 0.7008 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6847 - loss: 0.7014 - val_accuracy: 0.6935 - val_loss: 0.6975 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6957 - loss: 0.6919 - val_accuracy: 0.6980 - val_loss: 0.6954 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6979 - loss: 0.6830 - val_accuracy: 0.6925 - val_loss: 0.6954 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6998 - loss: 0.6795 - val_accuracy: 0.7000 - val_loss: 0.6943 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7068 - loss: 0.6690 - val_accuracy: 0.6990 - val_loss: 0.6936 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7119 - loss: 0.6560 - val_accuracy: 0.7035 - val_loss: 0.6899 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7141 - loss: 0.6530 - val_accuracy: 0.7040 - val_loss: 0.6906 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7175 - loss: 0.6468 - val_accuracy: 0.7055 - val_loss: 0.6900 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7158 - loss: 0.6482 - val_accuracy: 0.7025 - val_loss: 0.6909 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7205 - loss: 0.6423 - val_accuracy: 0.7040 - val_loss: 0.6919 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7214 - loss: 0.6375 - val_accuracy: 0.7040 - val_loss: 0.6897 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7218 - loss: 0.6370 - val_accuracy: 0.7055 - val_loss: 0.6904 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7233 - loss: 0.6378 - val_accuracy: 0.7045 - val_loss: 0.6910 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7170 - loss: 0.6404 - val_accuracy: 0.7050 - val_loss: 0.6904 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7271 - loss: 0.6334 - val_accuracy: 0.7045 - val_loss: 0.6897 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7257 - loss: 0.6304 - val_accuracy: 0.7080 - val_loss: 0.6910 - learning_rate: 1.0000e-04\n",
      "Epoch 30: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6421 - loss: 0.8217\n",
      "9 0.6374959349632263\n",
      "Epoch 1/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.4139 - loss: 1.1791 - val_accuracy: 0.4345 - val_loss: 1.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4366 - loss: 1.0304 - val_accuracy: 0.4345 - val_loss: 1.0227 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4486 - loss: 1.0230 - val_accuracy: 0.4345 - val_loss: 1.0191 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4439 - loss: 1.0210 - val_accuracy: 0.4345 - val_loss: 1.0104 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4670 - loss: 1.0043 - val_accuracy: 0.5820 - val_loss: 0.9075 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5545 - loss: 0.9124 - val_accuracy: 0.6175 - val_loss: 0.7946 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6074 - loss: 0.8393 - val_accuracy: 0.6380 - val_loss: 0.7742 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6223 - loss: 0.8130 - val_accuracy: 0.6630 - val_loss: 0.7477 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6435 - loss: 0.7783 - val_accuracy: 0.6610 - val_loss: 0.7394 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6509 - loss: 0.7574 - val_accuracy: 0.6715 - val_loss: 0.7200 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6696 - loss: 0.7311 - val_accuracy: 0.6840 - val_loss: 0.7083 - learning_rate: 3.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6772 - loss: 0.7152 - val_accuracy: 0.6775 - val_loss: 0.7085 - learning_rate: 3.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6843 - loss: 0.7042 - val_accuracy: 0.6885 - val_loss: 0.7033 - learning_rate: 3.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6883 - loss: 0.7009 - val_accuracy: 0.6945 - val_loss: 0.7016 - learning_rate: 3.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6939 - loss: 0.6898 - val_accuracy: 0.6970 - val_loss: 0.6989 - learning_rate: 3.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6938 - loss: 0.6846 - val_accuracy: 0.7015 - val_loss: 0.6977 - learning_rate: 3.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7004 - loss: 0.6756 - val_accuracy: 0.7035 - val_loss: 0.6961 - learning_rate: 3.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6978 - loss: 0.6700 - val_accuracy: 0.7030 - val_loss: 0.6963 - learning_rate: 3.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7138 - loss: 0.6520 - val_accuracy: 0.7015 - val_loss: 0.6949 - learning_rate: 3.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7142 - loss: 0.6527 - val_accuracy: 0.7020 - val_loss: 0.6941 - learning_rate: 3.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7148 - loss: 0.6431 - val_accuracy: 0.7015 - val_loss: 0.6930 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7223 - loss: 0.6354 - val_accuracy: 0.7020 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7214 - loss: 0.6360 - val_accuracy: 0.7040 - val_loss: 0.6936 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7247 - loss: 0.6307 - val_accuracy: 0.7040 - val_loss: 0.6949 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7214 - loss: 0.6363 - val_accuracy: 0.7030 - val_loss: 0.6938 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7276 - loss: 0.6266 - val_accuracy: 0.7025 - val_loss: 0.6936 - learning_rate: 1.0000e-04\n",
      "Epoch 26: early stopping\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6456 - loss: 0.8156\n",
      "10 0.6387170553207397\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    input_layer = tf.keras.layers.Input(shape=(train_vectorized.shape[1],))\n",
    "    neural_network = tf.keras.models.Sequential(\n",
    "        [\n",
    "            input_layer,\n",
    "            tf.keras.layers.Dense(2048, activation=activation_function),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(512, activation=activation_function),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(128, activation=activation_function),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(3, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    neural_network.compile(\n",
    "        optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, mode=\"min\", verbose=1\n",
    "    )\n",
    "    with tf.device(device_name):\n",
    "        history = neural_network.fit(\n",
    "            train_vectorized,\n",
    "            train_label_one_hot,\n",
    "            validation_data=(validation_vectorized, validation_label_one_hot),\n",
    "            epochs=200,\n",
    "            batch_size=512,\n",
    "            callbacks=[early_stopping, rate_scheduler],\n",
    "        )\n",
    "    test_loss, test_accuracy = neural_network.evaluate(test_vectorized, test_label_one_hot)\n",
    "    print(i+1, test_accuracy)\n",
    "    accuracy_list.append(test_accuracy)\n",
    "    if test_accuracy >= 0.641:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c3ae4d3-cdf0-40bc-bd6b-93a94ee41299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6377401351928711, 0.6378215551376343, 0.6332627534866333, 0.6401009559631348, 0.6358677744865417, 0.6390426754951477, 0.6360306143760681, 0.6382285952568054, 0.6374959349632263, 0.6387170553207397]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edb26f8d-0581-464d-a80d-70db54f3e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_network.save('64_test.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
