{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5b6117-eef5-4c57-8f4f-62d73d2481f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please replace with the correct path to the .h5 file and .json file\n",
    "model_folder = \"./saved_model\"\n",
    "# Please provide a decision boundary, should be stated in the release\n",
    "decision_boundary = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b6cf8c-26e0-48fb-a5e8-26218f822ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# For Docker image tensorflow/tensorflow:2.14.0-gpu-juptyer and latest-gpu-jupyter \n",
    "# About the latest tag: sha256:efc25f8ad0ec337e8f4e2de9e7e8e391e6729481c7a7cae4bdea3137da7822c6\n",
    "!pip install -q emoji\n",
    "!pip install -q nltk\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q transformers\n",
    "!pip install -q tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d0c842-d6a8-4666-8e3f-d26cb8a7cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 12:58:28.790797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "from emoji import demojize, is_emoji\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "import tensorflow as tf\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    TFBertForSequenceClassification,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35cfa82c-10b9-44f2-9062-75e4d6e01315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file(file_path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Load a text file and return an array of lines from the file.\n",
    "\n",
    "    Args:\n",
    "        file_path: str: The path to the file to load.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: An array of lines from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "    return [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed17d29f-f3f5-4b55-9c89-ac037359edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please replace the path to your test dataset\n",
    "test_text_path: str = \"../dataset/test_text.txt\"\n",
    "test_label_path: str = \"../dataset/test_labels.txt\"\n",
    "\n",
    "test_text: list[str] = load_text_file(test_text_path)\n",
    "test_label: list[str] = load_text_file(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3459d79b-88a4-4e0d-bf6f-ce6885676e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def text_processing(text: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Process text data:\n",
    "    - Remove \"@user\"\n",
    "    - Remove \"#\".\n",
    "    - Replace \"’\" and triple dots in one character (…).\n",
    "    - Tokenize and lowercase.\n",
    "    - Normalize the tokens and join the line.\n",
    "    - Replace specific strings.\n",
    "    - Remove excess space after processing.\n",
    "\n",
    "    Args:\n",
    "        text: list[str]: A list of text data.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of processed sentences\n",
    "    \"\"\"\n",
    "    processed_text = []\n",
    "    for line in text:\n",
    "        # Remove @user\n",
    "        line = line.replace(\"@user\", \"\")\n",
    "        # Remove #\n",
    "        line = line.replace(\"#\", \"\")\n",
    "        # Replace \"’\" and triple dots in one character (…)\n",
    "        line = line.replace(\"’\", \"'\").replace(\"…\", \"...\")\n",
    "        # Tokenize and lowercase\n",
    "        tokens = tokenizer.tokenize(line.lower())\n",
    "        # Normalize the tokens and join the line\n",
    "        line = \" \".join([normalize_token(token) for token in tokens])\n",
    "        # Replace specific strings\n",
    "        line = (\n",
    "            line.replace(\"cannot\", \"can not\")\n",
    "            .replace(\"can't\", \"can not\")\n",
    "            .replace(\"n't \", \" not \")\n",
    "            # Handle cases in English, where when \"n't\" is replace with\n",
    "            # \" not \", the meaning of the word will be invalid\n",
    "            .replace(\"wo not \", \"will not \")\n",
    "            .replace(\"sha not\", \"shall not\")\n",
    "            # \"ain't\" can be \"am/is/are not\", so it stays\n",
    "            .replace(\"ai not \", \"ain't \")\n",
    "        )\n",
    "        line = (\n",
    "            line.replace(\"'m \", \" am \")\n",
    "            .replace(\"'re \", \" are \")\n",
    "            .replace(\"'ll \", \" will \")\n",
    "            .replace(\"'ve \", \" have \")\n",
    "            # 's can mean ownership or \"is\"\n",
    "            .replace(\"'s \", \" 's \")\n",
    "            # 'd can mean \"would\" or \"had\"\n",
    "            .replace(\"'d \", \" 'd \")\n",
    "        )\n",
    "        # Remove excess spaces\n",
    "        line = \" \".join(line.split())\n",
    "        processed_text.append(line)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def normalize_token(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize the provided token.\n",
    "    - Replace URLs with \"HTTPURL\".\n",
    "    - Replace emojis with respective string.\n",
    "\n",
    "    Args:\n",
    "        token: str: The string being normalized\n",
    "\n",
    "    Return:\n",
    "        str: The normalized string\n",
    "    \"\"\"\n",
    "    if token.startswith(\"http\") or token.startswith(\"www\"):\n",
    "        return \"HTTPURL\"\n",
    "    elif is_emoji(token):\n",
    "        return demojize(token)\n",
    "    else:\n",
    "        return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80240197-44cf-44cd-a02a-b7f60a6314a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text: list[str] = text_processing(test_text)\n",
    "test_labels = [int(x) for x in test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f4b49f-4035-4542-9709-8339758b9333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 12:58:31.055054: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 12:58:31.059547: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 12:58:31.059586: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 12:58:31.061818: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 12:58:31.061857: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 12:58:31.061877: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 12:58:31.164700: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 12:58:31.164751: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 12:58:31.164760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-05 12:58:31.164782: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 12:58:31.164803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ./saved_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0 (unused)\n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2307      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109484547 (417.65 MB)\n",
      "Trainable params: 109484547 (417.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(model_folder)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d97a897c-9be7-4746-8b72-50cc5df18cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "test_encodings = tokenizer(\n",
    "    test_text, padding=True, truncation=True, return_tensors=\"tf\"\n",
    ")\n",
    "test_labels = tf.convert_to_tensor(tf.one_hot(test_labels, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3de860a-f2c4-43c0-98a6-488320b4add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_decision_boundary(prediction: ndarray[float], boundary: float) -> list[int]:\n",
    "    \"\"\"\n",
    "    Adjust decision method, make the model tend to predict\n",
    "    \"Netural\" more, according to the distribution of the dataset\n",
    "\n",
    "    If either the score of positive or negative class is in the\n",
    "    +-boundary range of the netural score, and the remaining class is\n",
    "    not significant higher that the netural class\n",
    "    It will be classified as netural\n",
    "\n",
    "    Args:\n",
    "        prediction: ndarray[float]: The prediction with socres for each entry.\n",
    "        boundary: float: The boundary, should be between 0 and 1.\n",
    "\n",
    "    Return:\n",
    "        ndarray[int]: The new prediction\n",
    "    \"\"\"\n",
    "    final_result: list[int] = []\n",
    "    for row in prediction:\n",
    "        # If the class with the highest score is netural\n",
    "        if np.max(row) == row[1]:\n",
    "            final_result.append(1)\n",
    "            continue\n",
    "\n",
    "        negative: float = row[0]\n",
    "        netural: float = row[1]\n",
    "        positive: float = row[2]\n",
    "\n",
    "        # Get the netural score range\n",
    "        min_netural: float = netural * (1 - boundary)\n",
    "        max_netural: float = netural * (1 + boundary)\n",
    "\n",
    "        # If score for negative is in netural range and it is the class with highest score\n",
    "        if min_netural <= negative <= max_netural and np.max(row) == negative:\n",
    "            final_result.append(1)\n",
    "        # If score for positive is in netural range and it is the class with highest score\n",
    "        elif min_netural <= positive <= max_netural and np.max(row) == positive:\n",
    "            final_result.append(1)\n",
    "        elif np.max(row) == negative:\n",
    "            final_result.append(0)\n",
    "        elif np.max(row) == positive:\n",
    "            final_result.append(2)\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db92bbaa-98e3-417c-8b75-00d396f7b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 64s 132ms/step\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict(test_encodings)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n",
    "prediction_matrix: ndarray[float] = test_prediction.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1956149-0217-48eb-96f0-a7f65b47238e",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a7a96c-57ad-4d34-a71c-fb8c255f6413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores for each class: [0.72588415 0.67988511 0.68693009]\n",
      "Macro-averaged F1 score: 0.6975664506096498\n"
     ]
    }
   ],
   "source": [
    "final_result = modify_decision_boundary(prediction_matrix, decision_boundary)\n",
    "f1_scores_processed = f1_score(test_labels, final_result, average=None)\n",
    "macro_average_f1_processed = np.mean(f1_scores_processed)\n",
    "\n",
    "print(\"F1 scores for each class:\", f1_scores_processed)\n",
    "print(\"Macro-averaged F1 score:\", macro_average_f1_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787a4a5-3d7d-4da0-bee5-c8c2084d01dd",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c13647a9-0296-46f0-b1cd-0ee98ad200d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for each class: [0.77769386 0.61798888 0.76126316]\n",
      "Macro-averaged recall: 0.7189819660560369\n"
     ]
    }
   ],
   "source": [
    "recall_per_class = recall_score(test_labels, final_result, average=None)\n",
    "macro_average_recall = sum(recall_per_class) / len(recall_per_class)\n",
    "\n",
    "print(\"Recall for each class:\", recall_per_class)\n",
    "print(\"Macro-averaged recall:\", macro_average_recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
